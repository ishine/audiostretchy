Project Structure:
ğŸ“ audiostretchy
â”œâ”€â”€ ğŸ“ .github
â”‚   â”œâ”€â”€ ğŸ“ workflows
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ ci.yml
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ docs.yml
â”‚   â”‚   â””â”€â”€ ğŸ“„ release.yml
â”‚   â””â”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“ audio-stretch
â”œâ”€â”€ ğŸ“ docs
â”‚   â”œâ”€â”€ ğŸ“ _static
â”‚   â”‚   â””â”€â”€ ğŸ“„ .gitignore
â”‚   â”œâ”€â”€ ğŸ“„ authors.md
â”‚   â”œâ”€â”€ ğŸ“„ changelog.md
â”‚   â”œâ”€â”€ ğŸ“„ conf.py
â”‚   â”œâ”€â”€ ğŸ“„ contributing.md
â”‚   â”œâ”€â”€ ğŸ“„ index.md
â”‚   â”œâ”€â”€ ğŸ“„ license.md
â”‚   â”œâ”€â”€ ğŸ“„ Makefile
â”‚   â”œâ”€â”€ ğŸ“„ readme.md
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“ scripts
â”‚   â”œâ”€â”€ ğŸ“„ build.sh
â”‚   â”œâ”€â”€ ğŸ“„ build_local.py
â”‚   â”œâ”€â”€ ğŸ“„ compile_c.py
â”‚   â”œâ”€â”€ ğŸ“„ release.sh
â”‚   â””â”€â”€ ğŸ“„ test.sh
â”œâ”€â”€ ğŸ“ src
â”‚   â”œâ”€â”€ ğŸ“ audiostretchy
â”‚   â”‚   â”œâ”€â”€ ğŸ“ c_interface
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ lib
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ build.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ wrapper.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“ interface
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ linux
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ mac
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ tdhs.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __main__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ core.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ dummy.c
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ py.typed
â”‚   â”‚   â””â”€â”€ ğŸ“„ stretch.py
â”‚   â””â”€â”€ ğŸ“ audiostretchy.egg-info
â”œâ”€â”€ ğŸ“ src_docs
â”‚   â”œâ”€â”€ ğŸ“ md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ 01-installation.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ 02-quick-start.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ 03-cli-usage.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ 04-python-api.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ 05-how-it-works.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ 06-core-architecture.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ 07-parameters-reference.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ 08-contributing.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ 09-api-reference.md
â”‚   â”‚   â””â”€â”€ ğŸ“„ index.md
â”‚   â””â”€â”€ ğŸ“„ mkdocs.yml
â”œâ”€â”€ ğŸ“ test_env
â”‚   â””â”€â”€ ğŸ“ bin
â”œâ”€â”€ ğŸ“ tests
â”‚   â”œâ”€â”€ ğŸ“„ conftest.py
â”‚   â”œâ”€â”€ ğŸ“„ test_cli.py
â”‚   â”œâ”€â”€ ğŸ“„ test_core.py
â”‚   â”œâ”€â”€ ğŸ“„ test_mono_audio.py
â”‚   â”œâ”€â”€ ğŸ“„ test_performance.py
â”‚   â””â”€â”€ ğŸ“„ test_stretch.py
â”œâ”€â”€ ğŸ“ vendors
â”‚   â””â”€â”€ ğŸ“ stretch
â”‚       â”œâ”€â”€ ğŸ“ samples
â”‚       â”‚   â””â”€â”€ ğŸ“„ README
â”‚       â”œâ”€â”€ ğŸ“„ .gitignore
â”‚       â”œâ”€â”€ ğŸ“„ build.sh
â”‚       â”œâ”€â”€ ğŸ“„ license.txt
â”‚       â”œâ”€â”€ ğŸ“„ main.c
â”‚       â”œâ”€â”€ ğŸ“„ README
â”‚       â”œâ”€â”€ ğŸ“„ stretch.c
â”‚       â”œâ”€â”€ ğŸ“„ stretch.h
â”‚       â””â”€â”€ ğŸ“„ test.sh
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ AUTHORS.md
â”œâ”€â”€ ğŸ“„ CHANGELOG.md
â”œâ”€â”€ ğŸ“„ DEVELOPMENT.md
â”œâ”€â”€ ğŸ“„ Dockerfile
â”œâ”€â”€ ğŸ“„ GITHUB_WORKFLOW.md
â”œâ”€â”€ ğŸ“„ LICENSE.txt
â”œâ”€â”€ ğŸ“„ Makefile
â”œâ”€â”€ ğŸ“„ PLAN.md
â”œâ”€â”€ ğŸ“„ pyproject.toml
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ SEMVER_GUIDE.md
â”œâ”€â”€ ğŸ“„ setup.py
â”œâ”€â”€ ğŸ“„ TODO.md
â””â”€â”€ ğŸ“„ WORK.md


<documents>
<document index="1">
<source>.coveragerc</source>
<document_content>
# .coveragerc to control coverage.py
[run]
branch = True
source = audiostretchy
# omit = bad_file.py

[paths]
source =
    src/
    */site-packages/

[report]
# Regexes for lines to exclude from consideration
exclude_lines =
    # Have to re-enable the standard pragma
    pragma: no cover

    # Don't complain about missing debug-only code:
    def __repr__
    if self\.debug

    # Don't complain if tests don't hit defensive assertion code:
    raise AssertionError
    raise NotImplementedError

    # Don't complain if non-runnable code isn't run:
    if 0:
    if __name__ == .__main__.:

</document_content>
</document>

<document index="2">
<source>.github/README.md</source>
<document_content>
# this_file: _github/README.md

# GitHub Workflows

This directory contains GitHub Actions workflow files for the AudioStretchy project.

## Workflows

### `docs.yml` - Documentation Build and Deploy

**Trigger**: 
- Push to `main` branch (when `src_docs/` changes)
- Pull requests to `main` branch (when `src_docs/` changes)
- Manual workflow dispatch

**Purpose**:
- Builds MkDocs Material documentation from `src_docs/`
- Deploys to GitHub Pages on push to main
- Validates documentation builds on pull requests

**Requirements**:
- GitHub Pages must be enabled in repository settings
- Source set to "GitHub Actions" in Pages settings

### `ci.yml` - Continuous Integration

**Trigger**:
- Push to `main` or `develop` branches
- Pull requests to `main` or `develop` branches  
- Manual workflow dispatch

**Purpose**:
- Tests on multiple OS (Ubuntu, Windows, macOS)
- Tests multiple Python versions (3.8 - 3.12)
- Runs linting with flake8
- Runs tests with pytest and coverage
- Builds distribution packages

### `release.yml` - Release and PyPI Publishing

**Trigger**:
- Push of version tags (e.g., `v1.2.3`)

**Purpose**:
- Runs full test suite on release
- Builds distribution packages for all platforms
- Creates GitHub release with artifacts
- Publishes to PyPI automatically

**Requirements**:
- `PYPI_API_TOKEN` secret must be configured
- Release environment may need approval settings

## Setup Instructions

To activate these workflows:

1. **Copy to `.github/` directory**:
   ```bash
   cp -r _github/ .github/
   ```

2. **Configure GitHub Pages**:
   - Go to repository Settings â†’ Pages
   - Set Source to "GitHub Actions"
   - The documentation will be available at `https://username.github.io/audiostretchy/`

3. **Configure PyPI Publishing**:
   - Create PyPI API token at https://pypi.org/manage/account/token/
   - Add token as `PYPI_API_TOKEN` secret in repository settings
   - Optionally configure release environment with approval requirements

4. **Test Workflows**:
   - Create a pull request to test CI
   - Push to main to test documentation build
   - Create a tag like `v1.0.0-test` to test release workflow

## Customization

### Documentation Workflow

Edit `workflows/docs.yml` to customize:
- **Trigger conditions**: Modify `on.push.paths` to change which files trigger builds
- **Python version**: Change in `setup-python` step
- **Additional dependencies**: Add to pip install step
- **Build directory**: Modify `mkdocs build` command and upload path

### CI Workflow

Edit `workflows/ci.yml` to customize:
- **OS matrix**: Add/remove operating systems
- **Python versions**: Modify version matrix
- **Test commands**: Change pytest configuration
- **Linting rules**: Modify flake8 parameters

### Release Workflow

Edit `workflows/release.yml` to customize:
- **Tag pattern**: Change `tags` filter
- **Release notes**: Modify `generate_release_notes` setting
- **PyPI repository**: Add `repository-url` for test PyPI

## Security Considerations

- **Secrets**: Never commit API tokens or sensitive data
- **Permissions**: Use minimal required permissions in workflows
- **Environment protection**: Consider requiring reviews for release environment
- **Token scoping**: Use scoped tokens with minimal required permissions

## Troubleshooting

### Documentation Build Fails

1. Check MkDocs configuration in `src_docs/mkdocs.yml`
2. Verify all referenced files exist
3. Check Python package dependencies
4. Review workflow logs for specific errors

### CI Failures

1. Check test failures in pytest output
2. Verify system dependencies are installed
3. Check Python version compatibility
4. Review linting errors from flake8

### Release Failures

1. Verify PyPI token is configured correctly
2. Check package version conflicts
3. Ensure all tests pass before release
4. Review build artifact generation

For more information, see the [GitHub Actions documentation](https://docs.github.com/en/actions).
</document_content>
</document>

<document index="3">
<source>.github/workflows/ci.yml</source>
<document_content>
# this_file: _github/workflows/ci.yml

name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.8', '3.9', '3.10', '3.11', '3.12']

    steps:
    - uses: actions/checkout@v4
      with:
        submodules: recursive

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install system dependencies (Ubuntu)
      if: matrix.os == 'ubuntu-latest'
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg

    - name: Install system dependencies (macOS)
      if: matrix.os == 'macos-latest'
      run: |
        brew install ffmpeg

    - name: Install system dependencies (Windows)
      if: matrix.os == 'windows-latest'
      run: |
        # FFmpeg installation for Windows
        choco install ffmpeg

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[testing]

    - name: Lint with flake8
      run: |
        flake8 src tests --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 src tests --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Test with pytest
      run: |
        pytest tests/ -v --cov=src/audiostretchy --cov-report=xml

    - name: Upload coverage to Codecov
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  build:
    needs: test
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]

    steps:
    - uses: actions/checkout@v4
      with:
        submodules: recursive

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build wheel

    - name: Build package
      run: |
        python -m build

    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: dist-${{ matrix.os }}
        path: dist/
</document_content>
</document>

<document index="4">
<source>.github/workflows/docs.yml</source>
<document_content>
# this_file: _github/workflows/docs.yml

name: Build and Deploy Documentation

on:
  push:
    branches: [ main ]
    paths:
      - 'src_docs/**'
      - '_github/workflows/docs.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'src_docs/**'
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install MkDocs and dependencies
        run: |
          pip install --upgrade pip
          pip install mkdocs-material
          pip install mkdocs-minify-plugin
          
      - name: Build documentation
        run: |
          cd src_docs
          mkdocs build --verbose --clean
          
      - name: Upload documentation artifact
        uses: actions/upload-pages-artifact@v2
        with:
          path: ./docs

  deploy:
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v2
</document_content>
</document>

<document index="5">
<source>.github/workflows/release.yml</source>
<document_content>
# this_file: _github/workflows/release.yml

name: Release

on:
  push:
    tags:
      - 'v*'

permissions:
  contents: write

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.8', '3.11']

    steps:
    - uses: actions/checkout@v4
      with:
        submodules: recursive

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install system dependencies (Ubuntu)
      if: matrix.os == 'ubuntu-latest'
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg

    - name: Install system dependencies (macOS)
      if: matrix.os == 'macos-latest'
      run: |
        brew install ffmpeg

    - name: Install system dependencies (Windows)
      if: matrix.os == 'windows-latest'
      run: |
        choco install ffmpeg

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[testing]

    - name: Test with pytest
      run: |
        pytest tests/ -v

  build:
    needs: test
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]

    steps:
    - uses: actions/checkout@v4
      with:
        submodules: recursive

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build wheel twine

    - name: Build package
      run: |
        python -m build

    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: dist-${{ matrix.os }}
        path: dist/

  release:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: release
      url: https://pypi.org/project/audiostretchy/

    steps:
    - uses: actions/checkout@v4

    - name: Download all artifacts
      uses: actions/download-artifact@v3

    - name: Combine artifacts
      run: |
        mkdir -p dist/
        cp dist-*/* dist/ || true

    - name: Create GitHub Release
      uses: softprops/action-gh-release@v1
      with:
        files: dist/*
        generate_release_notes: true
        draft: false
        prerelease: ${{ contains(github.ref, '-') }}

    - name: Publish to PyPI
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        password: ${{ secrets.PYPI_API_TOKEN }}
        skip-existing: true
</document_content>
</document>

<document index="6">
<source>.gitignore</source>
<document_content>
# Temporary and binary files
*~
*.py[cod]
*.cfg
!.isort.cfg
!setup.cfg
*.orig
*.log
*.pot
__pycache__/*
.cache/*
.*.swp
*/.ipynb_checkpoints/*
.DS_Store

# Project files
.ropeproject
.project
.pydevproject
.settings
.idea
.vscode
tags

# Package files
*.egg
*.eggs/
.installed.cfg
*.egg-info

# Unittest and coverage
htmlcov/*
.coverage
.coverage.*
.tox
junit*.xml
coverage.xml
.pytest_cache/

# Build and docs folder/files
#build/*
#dist/*
#sdist/*
docs/api/*
docs/_rst/*
docs/_build/*
cover/*
MANIFEST

# Per-project virtualenvs
.venv*/
.conda*/
.python-version

</document_content>
</document>

<document index="7">
<source>.gitmodules</source>
<document_content>
[submodule "vendors/resample"]
	path = vendors/resample
	url = https://github.com/dbry/audio-resampler
[submodule "audio-stretch"]
	path = audio-stretch
	url = https://github.com/dbry/audio-stretch.git

</document_content>
</document>

<document index="8">
<source>.isort.cfg</source>
<document_content>
[settings]
profile = black
known_first_party = audiostretchy

</document_content>
</document>

<document index="9">
<source>.pre-commit-config.yaml</source>
<document_content>
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
      - id: check-merge-conflict
      - id: check-toml
      - id: debug-statements

  - repo: https://github.com/psf/black
    rev: 23.9.1
    hooks:
      - id: black
        language_version: python3
        args: [--line-length=88]

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: [--profile, black]

  - repo: https://github.com/pycqa/flake8
    rev: 6.1.0
    hooks:
      - id: flake8
        args: [--max-line-length=88, --extend-ignore=E203,W503]

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.5.1
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
        args: [--ignore-missing-imports, --no-strict-optional]

  - repo: local
    hooks:
      - id: pytest-check
        name: pytest-check
        entry: python -m pytest tests/test_stretch.py::test_stretch_no_change -v
        language: system
        pass_filenames: false
        always_run: true
EOF < /dev/null

</document_content>
</document>

<document index="10">
<source>.readthedocs.yml</source>
<document_content>
# Read the Docs configuration file
# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details

# Required
version: 2

# Build documentation in the docs/ directory with Sphinx
sphinx:
  configuration: docs/conf.py

# Build documentation with MkDocs
#mkdocs:
#  configuration: mkdocs.yml

# Optionally build your docs in additional formats such as PDF
formats:
  - pdf

build:
  os: ubuntu-22.04
  tools:
    python: "3.11"

python:
  install:
    - requirements: docs/requirements.txt
    - {path: ., method: pip}

</document_content>
</document>

<document index="11">
<source>AUTHORS.md</source>
<document_content>
# Contributors

* Adam Twardoch <adam+github@twardoch.com>
</document_content>
</document>

<document index="12">
<source>CHANGELOG.md</source>
<document_content>
# Changelog

## [Unreleased] - 2024-03-15

### Recent Refinements (Jules (AI Assistant), 2024-03-15)
-   **Packaging:**
    -   Updated `pyproject.toml` to use the correct string format for `project.license` (e.g., "BSD-3-Clause"), resolving a `setuptools` deprecation warning.
    -   Added a dummy C extension (`src/audiostretchy/dummy.c`) and updated `setup.py` to include it. This ensures that Python wheels are built with platform-specific tags (e.g., `...-linux_x86_64.whl`), which is crucial for distributing packages containing pre-compiled binaries via `package_data`.
-   **Testing:**
    -   Expanded test coverage in `tests/test_stretch.py` to include:
        -   Variations of TDHS parameters (`fast_detection`, `double_range`, non-default frequency limits).
        -   Stretching with extreme ratios (0.25, 4.0) using `double_range`.
        -   Basic test for `gap_ratio` parameter passthrough.
        -   I/O operations using file-like objects (`io.BytesIO`) for WAV files.
    -   *(Note: Some tests were observed to be failing in the development sandbox environment at the time of this update, requiring further investigation by the team.)*
-   **Documentation:**
    -   Updated the main `AudioStretch` class docstring in `src/audiostretchy/stretch.py` for better clarity on its role and dependencies.
    -   Created `PLAN.md` and `TODO.md` to structure the refactoring effort.
-   **Code Review:**
    -   Reviewed and confirmed that the core logic in `src/audiostretchy/stretch.py` correctly uses `pedalboard` for I/O and resampling, and the custom C library (`TDHSAudioStretch`) for the actual time-stretching, aligning with the project's architectural goals.
    -   Verified C library integration via `ctypes` in `src/audiostretchy/interface/tdhs.py` and the CI workflow for compiling these libraries.
    -   Reviewed and confirmed `README.md`, docstrings, and `CHANGELOG.md` accurately reflect the project's current state, architecture, and usage.

### Architectural Changes

### Architectural Changes
-   Re-focused the library to use David Bryant's `audio-stretch` C library (TDHS algorithm via `vendors/stretch` submodule) as the primary engine for time-stretching audio. This restores features like `gap_ratio` and other TDHS-specific tuning parameters.
-   Integrated the `spotify-pedalboard` library to handle audio file input/output (supporting formats like WAV, MP3, FLAC, OGG, etc.) and for audio resampling.

### Dependencies
-   `pedalboard` is now a core dependency.
-   Removed direct dependencies on `pydub`, `pymp3` (for MP3 handling) and `soxr` (for resampling), as these functionalities are now provided by `pedalboard`.

### Build Process
-   Restored and verified the CI workflow (`.github/workflows/ci.yaml`) for compiling the `audio-stretch` C library across Linux, macOS, and Windows.
-   Ensured `pyproject.toml` is correctly configured to package the pre-compiled C libraries into the Python wheels.

### API and CLI
-   The `AudioStretch` class and `stretch_audio` function in `audiostretchy.stretch` now expose parameters specific to the TDHS C library (e.g., `gap_ratio`, `upper_freq`, `lower_freq`, `double_range`, `fast_detection`).
-   **Note on `gap_ratio`**: While the parameters for detailed gap/silence processing (`gap_ratio`, `buffer_ms`, `threshold_gap_db`) are exposed to the Python interface, the current Python wrapper does not implement the per-segment audio analysis and differential ratio application performed by the original C command-line tool (`main.c`). The C library's core `stretch_samples` function receives a single ratio for the entire segment it processes. Effective `gap_ratio` behavior similar to the C CLI would require further development in the Python wrapper.

### Documentation
-   `README.md` updated to accurately reflect the current architecture, installation instructions (including `pedalboard`'s potential system dependencies like FFmpeg), and API usage with TDHS parameters.

### Testing
-   Tests in `tests/test_stretch.py` have been reviewed and confirmed to align with the C library for stretching (using default TDHS parameters in most test calls) and `pedalboard` for I/O and resampling.

*(Self-correction note: This changelog reflects the state after correcting an initial misinterpretation of the project goals, where `pedalboard` was incorrectly slated to replace the C library for stretching.)*

</document_content>
</document>

<document index="13">
<source>DEVELOPMENT.md</source>
<document_content>
# Development Guide for AudioStretchy

## Overview

This guide covers the complete development workflow for AudioStretchy, including testing, building, and releasing.

## Project Structure

```
audiostretchy/
â”œâ”€â”€ src/audiostretchy/           # Main package source
â”‚   â”œâ”€â”€ __init__.py             # Package initialization with version
â”‚   â”œâ”€â”€ __main__.py             # CLI entry point
â”‚   â”œâ”€â”€ stretch.py              # Core audio processing
â”‚   â””â”€â”€ interface/              # C library bindings
â”œâ”€â”€ tests/                      # Comprehensive test suite
â”‚   â”œâ”€â”€ test_stretch.py         # Main functionality tests
â”‚   â”œâ”€â”€ test_cli.py             # Command line interface tests
â”‚   â”œâ”€â”€ test_mono_audio.py      # Mono audio specific tests
â”‚   â”œâ”€â”€ test_performance.py     # Performance benchmarks
â”‚   â””â”€â”€ conftest.py             # Test fixtures and utilities
â”œâ”€â”€ scripts/                    # Build and release scripts
â”‚   â”œâ”€â”€ build.sh                # Build script
â”‚   â”œâ”€â”€ test.sh                 # Test script
â”‚   â””â”€â”€ release.sh              # Release script
â”œâ”€â”€ .github/workflows/          # CI/CD pipeline
â”‚   â””â”€â”€ ci.yml                  # GitHub Actions workflow
â”œâ”€â”€ Makefile                    # Convenient build commands
â”œâ”€â”€ pyproject.toml              # Package configuration
â”œâ”€â”€ Dockerfile                  # Docker container for testing
â””â”€â”€ SEMVER_GUIDE.md            # Semantic versioning guide
```

## Development Setup

### Prerequisites

- Python 3.8+
- Git
- FFmpeg (for audio format support)
- libsndfile (for audio I/O)

### Local Development

```bash
# Clone the repository
git clone https://github.com/twardoch/audiostretchy.git
cd audiostretchy

# Set up development environment
make dev

# This will:
# - Install the package in editable mode
# - Install all testing dependencies
# - Set up pre-commit hooks
```

### Available Commands

```bash
# Development
make dev          # Set up development environment
make install      # Install package in development mode

# Testing
make test         # Run complete test suite with coverage
make lint         # Run linting checks
make format       # Format code with black and isort
make check        # Run both tests and linting

# Building
make build        # Build source and wheel distributions
make clean        # Clean build artifacts

# Release
make release VERSION=1.2.3  # Create and push release tag
```

## Testing

### Test Structure

AudioStretchy has a comprehensive test suite covering:

1. **Core functionality** (`test_stretch.py`)
   - Audio stretching operations
   - File I/O operations
   - Resampling functionality
   - Parameter validation

2. **CLI interface** (`test_cli.py`)
   - Command line argument parsing
   - Integration with Fire framework
   - Error handling

3. **Audio format support** (`test_mono_audio.py`)
   - Mono and stereo audio processing
   - Various audio formats (WAV, MP3)
   - Silence handling

4. **Performance** (`test_performance.py`)
   - Benchmark tests
   - Memory usage validation
   - Processing time limits

### Running Tests

```bash
# Run all tests
make test

# Run specific test file
python -m pytest tests/test_stretch.py -v

# Run with coverage
python -m pytest tests/ --cov=src/audiostretchy --cov-report=html

# Run performance tests
python -m pytest tests/test_performance.py -m performance
```

### Test Fixtures

The test suite includes several fixtures for consistent testing:

- **Audio file generators**: Create test audio files dynamically
- **Temporary directories**: Clean test environments
- **Property checkers**: Validate audio file properties
- **Tolerance checkers**: Handle floating-point comparisons

## Building

### Local Build

```bash
# Build source distribution and wheel
make build

# Build artifacts will be in dist/
ls dist/
# audiostretchy-1.2.3-py3-none-any.whl
# audiostretchy-1.2.3.tar.gz
```

### Docker Build

```bash
# Build and test in Docker container
docker build -t audiostretchy-test .
docker run --rm audiostretchy-test
```

### Wheel Building

The CI pipeline uses `cibuildwheel` to build wheels for multiple platforms:

- **Linux**: x86_64, aarch64
- **Windows**: AMD64
- **macOS**: x86_64, arm64

## Version Management

AudioStretchy uses `setuptools_scm` for automatic version detection from git tags:

```python
# Version is automatically set from git tags
import audiostretchy
print(audiostretchy.__version__)
```

### Version Format

- **Release**: `1.2.3`
- **Development**: `1.2.3.dev4+g1234abcd`
- **Pre-release**: `1.3.0-alpha.1`

## Release Process

### Automated Release

```bash
# Create release (must be on main branch)
make release VERSION=1.2.3
```

This triggers:
1. Local validation and testing
2. Git tag creation
3. CI/CD pipeline activation
4. Multi-platform wheel building
5. Automatic PyPI publication

### Manual Release

If needed, you can manually release:

```bash
# Build locally
make build

# Check distribution
python -m twine check dist/*

# Upload to PyPI (requires API token)
python -m twine upload dist/*
```

## CI/CD Pipeline

### GitHub Actions Workflow

The CI pipeline (`.github/workflows/ci.yml`) includes:

1. **Testing Phase**
   - Multi-platform testing (Ubuntu, Windows, macOS)
   - Python version matrix (3.8-3.12)
   - Dependency installation
   - Test execution with coverage

2. **Build Phase**
   - Source distribution building
   - Multi-platform wheel building
   - Artifact collection

3. **Release Phase** (on tags)
   - Artifact aggregation
   - PyPI publication
   - Release notification

### Dependencies

The pipeline installs system dependencies:

- **Ubuntu**: `ffmpeg`, `libsndfile1-dev`
- **macOS**: `ffmpeg`, `libsndfile` (via Homebrew)
- **Windows**: `ffmpeg` (via Chocolatey)

## Code Quality

### Pre-commit Hooks

The project uses pre-commit hooks for code quality:

- **Formatting**: Black, isort
- **Linting**: flake8, mypy
- **Security**: Basic security checks
- **Testing**: Quick smoke test

### Code Standards

- **Formatting**: Black with 88 character line length
- **Import sorting**: isort with Black profile
- **Type hints**: Encouraged but not required
- **Documentation**: Docstrings for all public APIs

## Contributing

### Workflow

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Set up development environment (`make dev`)
4. Make changes with tests
5. Run quality checks (`make check`)
6. Commit changes (`git commit -m 'Add amazing feature'`)
7. Push to branch (`git push origin feature/amazing-feature`)
8. Create Pull Request

### Pull Request Requirements

- All tests must pass
- Code coverage should not decrease
- Code must be formatted with Black
- Include tests for new functionality
- Update documentation if needed

## Troubleshooting

### Common Issues

1. **Import errors**: Ensure package is installed (`make install`)
2. **Test failures**: Check system dependencies (FFmpeg, libsndfile)
3. **Build failures**: Clean build artifacts (`make clean`)
4. **Version issues**: Check git tags and setuptools_scm

### Debug Commands

```bash
# Check version detection
python -c "import setuptools_scm; print(setuptools_scm.get_version())"

# Check package installation
python -c "import audiostretchy; print(audiostretchy.__version__)"

# Check git status
git status
git tag -l | tail -10

# Validate build
python -m build --wheel --sdist
python -m twine check dist/*
```

## Performance Considerations

### Optimization

- Pre-compiled C libraries for core algorithms
- Efficient NumPy array operations
- Minimal memory copying in audio processing
- Streaming audio I/O where possible

### Benchmarking

Run performance tests to ensure no regressions:

```bash
python -m pytest tests/test_performance.py -v
```

Expected performance targets:
- 1 second of audio processed in < 5 seconds
- Memory usage stable across multiple operations
- No memory leaks in repeated operations

## Support

For development questions:
- Check this guide and other documentation
- Review test cases for usage examples
- Open issues on GitHub for bugs/features
- Follow contributing guidelines for PRs
</document_content>
</document>

<document index="14">
<source>Dockerfile</source>
<document_content>
# this_file: Dockerfile

FROM python:3.11-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libsndfile1-dev \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements and install Python dependencies
COPY pyproject.toml ./
RUN pip install --no-cache-dir build

# Copy source code
COPY . .

# Install the package
RUN pip install -e .[testing]

# Run tests by default
CMD ["python", "-m", "pytest", "tests/", "-v"]
</document_content>
</document>

<document index="15">
<source>GITHUB_WORKFLOW.md</source>
<document_content>
# GitHub Actions Workflow Setup Guide

Since I cannot directly create workflow files, here are the GitHub Actions workflows you'll need to manually create in `.github/workflows/`:

## Build and Test Workflow (`.github/workflows/build.yml`)

```yaml
name: Build and Test

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  build:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.8', '3.9', '3.10', '3.11', '3.12']
        
    steps:
    - uses: actions/checkout@v4
      with:
        submodules: recursive
        
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Install system dependencies (Ubuntu)
      if: runner.os == 'Linux'
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential
        
    - name: Install system dependencies (macOS)
      if: runner.os == 'macOS'
      run: |
        # Xcode command line tools should be available
        xcode-select --install || true
        
    - name: Install system dependencies (Windows)
      if: runner.os == 'Windows'
      uses: microsoft/setup-msbuild@v2
      
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        python -m pip install build pytest pytest-cov
        
    - name: Compile C library
      run: python scripts/compile_c.py --verbose
      
    - name: Install package in development mode
      run: python -m pip install -e .[dev,test]
      
    - name: Run tests
      run: python -m pytest tests/ -v --cov=src/audiostretchy --cov-report=xml
      
    - name: Upload coverage to Codecov
      if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        
    - name: Build wheel
      run: python -m build
      
    - name: Test wheel installation
      run: |
        python -m pip install dist/*.whl
        python -c "import audiostretchy; print(audiostretchy.__version__)"
        
    - name: Store build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: wheels-${{ matrix.os }}-py${{ matrix.python-version }}
        path: dist/
```

## Publish Workflow (`.github/workflows/publish.yml`)

```yaml
name: Build and Publish

on:
  push:
    tags:
      - 'v*'

jobs:
  build-wheels:
    name: Build wheels on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        
    steps:
    - uses: actions/checkout@v4
      with:
        submodules: recursive
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install cibuildwheel
      run: python -m pip install cibuildwheel==2.16.2
      
    - name: Build wheels
      run: python -m cibuildwheel --output-dir wheelhouse
      env:
        # Configure cibuildwheel to build wheels for Python 3.8+
        CIBW_BUILD: "cp38-* cp39-* cp310-* cp311-* cp312-*"
        CIBW_SKIP: "*-win32 *-manylinux_i686"
        
        # Compile C library before building wheel
        CIBW_BEFORE_BUILD: "python scripts/compile_c.py"
        
        # Install test dependencies and run tests
        CIBW_TEST_REQUIRES: "pytest soundfile"
        CIBW_TEST_COMMAND: "pytest {project}/tests -v"
        
        # Platform-specific settings
        CIBW_ENVIRONMENT_LINUX: "CC=gcc"
        CIBW_ENVIRONMENT_MACOS: "CC=clang"
        
    - name: Upload wheels
      uses: actions/upload-artifact@v3
      with:
        name: wheels-${{ matrix.os }}
        path: ./wheelhouse/*.whl

  build-sdist:
    name: Build source distribution
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        submodules: recursive
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install build dependencies
      run: python -m pip install build
      
    - name: Build sdist
      run: python -m build --sdist
      
    - name: Upload sdist
      uses: actions/upload-artifact@v3
      with:
        name: sdist
        path: dist/*.tar.gz

  publish:
    name: Publish to PyPI
    needs: [build-wheels, build-sdist]
    runs-on: ubuntu-latest
    environment: release
    permissions:
      id-token: write
      
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v3
      with:
        path: dist
        
    - name: Flatten artifacts
      run: |
        mkdir -p upload
        find dist -name "*.whl" -exec cp {} upload/ \;
        find dist -name "*.tar.gz" -exec cp {} upload/ \;
        ls -la upload/
        
    - name: Publish to PyPI
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        packages-dir: upload/
```

## Quick Start After Merge

Due to GitHub App permissions, the CI/CD workflow files need to be manually created. After this PR is merged, please add the following workflow files to `.github/workflows/`:

## File: `.github/workflows/ci.yml`

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  release:
    types: [published]

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.8', '3.9', '3.10', '3.11', '3.12']

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        submodules: recursive

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install system dependencies (Ubuntu)
      if: matrix.os == 'ubuntu-latest'
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg libsndfile1-dev

    - name: Install system dependencies (macOS)
      if: matrix.os == 'macos-latest'
      run: |
        brew install ffmpeg libsndfile

    - name: Install system dependencies (Windows)
      if: matrix.os == 'windows-latest'
      run: |
        choco install ffmpeg

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine
        pip install -e .[testing]

    - name: Run tests
      run: |
        python -m pytest tests/ -v --cov=src/audiostretchy --cov-report=xml

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  build-wheels:
    needs: test
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        submodules: recursive

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build cibuildwheel

    - name: Build wheels
      uses: pypa/cibuildwheel@v2.16.2
      env:
        CIBW_BUILD: cp38-* cp39-* cp310-* cp311-* cp312-*
        CIBW_SKIP: "*-win32 *-manylinux_i686"
        CIBW_BEFORE_BUILD_LINUX: yum install -y ffmpeg-devel libsndfile-devel || apt-get update && apt-get install -y ffmpeg libsndfile1-dev
        CIBW_BEFORE_BUILD_MACOS: brew install ffmpeg libsndfile
        CIBW_BEFORE_BUILD_WINDOWS: choco install ffmpeg
        CIBW_TEST_REQUIRES: pytest soundfile
        CIBW_TEST_COMMAND: python -m pytest {project}/tests/test_stretch.py::test_stretch_no_change -v

    - name: Build source distribution
      if: matrix.os == 'ubuntu-latest'
      run: python -m build --sdist

    - name: Upload artifacts
      uses: actions/upload-artifact@v3
      with:
        name: dist-${{ matrix.os }}
        path: dist/

  release:
    needs: [test, build-wheels]
    runs-on: ubuntu-latest
    if: github.event_name == 'release' && github.event.action == 'published'

    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v3
      with:
        path: dist/

    - name: Flatten artifacts directory
      run: |
        find dist/ -name "*.whl" -o -name "*.tar.gz" | xargs -I {} mv {} dist/
        find dist/ -type d -empty -delete

    - name: Publish to PyPI
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        user: __token__
        password: ${{ secrets.PYPI_API_TOKEN }}
        packages_dir: dist/
```

## Setup Instructions

1. **After PR is merged**, create the directory structure:
   ```bash
   mkdir -p .github/workflows
   ```

2. **Create the workflow file** with the content above:
   ```bash
   # Copy the YAML content above to .github/workflows/ci.yml
   ```

3. **Configure PyPI API Token**:
   - Go to PyPI.org â†’ Account Settings â†’ API Tokens
   - Create a new token with upload permissions
   - Add it to GitHub repository secrets as `PYPI_API_TOKEN`

4. **Test the workflow**:
   - Push a commit to main branch
   - Verify the workflow runs successfully
   - Check that tests pass on all platforms

## Additional Setup

### Codecov Integration (Optional)
If you want code coverage reporting:
1. Sign up at codecov.io
2. Connect your GitHub repository
3. The workflow will automatically upload coverage reports

### Branch Protection Rules (Recommended)
Set up branch protection for main branch:
- Require pull request reviews
- Require status checks (CI tests)
- Require branches to be up to date
- Restrict pushes to main branch

## Testing the Release Process

After the workflow is set up:

1. **Test with a pre-release**:
   ```bash
   git tag -a v1.0.0-beta.1 -m "Beta release"
   git push origin v1.0.0-beta.1
   ```

2. **Create a GitHub release**:
   - Go to GitHub repository â†’ Releases
   - Click "Create a new release"
   - Select your tag
   - Fill in release notes
   - Publish the release

3. **Verify PyPI upload**:
   - Check that the package appears on PyPI
   - Test installation: `pip install audiostretchy==1.0.0b1`

## Troubleshooting

### Common Issues

1. **Workflow permission errors**: Ensure the GitHub App or user has workflows permission
2. **PyPI token errors**: Verify the token is correctly set in repository secrets
3. **Build failures**: Check system dependencies are correctly installed
4. **Test failures**: Ensure all tests pass locally before pushing

### Debug Commands

```bash
# Local testing
make test
make build

# Check version detection
python -c "import setuptools_scm; print(setuptools_scm.get_version())"

# Validate distribution
python -m twine check dist/*
```

This workflow provides:
- âœ… Multi-platform testing (Ubuntu, Windows, macOS)
- âœ… Python version matrix (3.8-3.12)
- âœ… Automated wheel building
- âœ… PyPI publishing on releases
- âœ… Code coverage reporting
- âœ… Artifact collection and storage
</document_content>
</document>

<document index="16">
<source>LICENSE.txt</source>
<document_content>
BSD 3-Clause License

Copyright (c) 2023, twardoch
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

* Redistributions of source code must retain the above copyright notice, this
  list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice,
  this list of conditions and the following disclaimer in the documentation
  and/or other materials provided with the distribution.

* Neither the name of audiostretchy nor the names of its
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

</document_content>
</document>

<document index="17">
<source>Makefile</source>
<document_content>
# this_file: Makefile

.PHONY: help build test clean install dev lint format release
.DEFAULT_GOAL := help

help: ## Show this help message
	@echo "AudioStretchy Build Commands"
	@echo "============================"
	@echo ""
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-12s\033[0m %s\n", $$1, $$2}'

build: ## Build the package
	@./scripts/build.sh

test: ## Run tests with coverage
	@./scripts/test.sh

clean: ## Clean build artifacts
	@echo "ğŸ§¹ Cleaning build artifacts..."
	@rm -rf build/ dist/ *.egg-info/ htmlcov/ .coverage
	@find . -type d -name __pycache__ -exec rm -rf {} +
	@find . -type f -name "*.pyc" -delete

install: ## Install package in development mode
	@echo "ğŸ“¦ Installing package in development mode..."
	@pip install -e .[testing]

dev: install ## Set up development environment
	@echo "ğŸ› ï¸ Setting up development environment..."
	@pip install pre-commit
	@pre-commit install

lint: ## Run linting
	@echo "ğŸ” Running linting..."
	@python -m flake8 src/audiostretchy/ tests/

format: ## Format code
	@echo "ğŸ¨ Formatting code..."
	@python -m black src/audiostretchy/ tests/
	@python -m isort src/audiostretchy/ tests/

release: ## Create a release (usage: make release VERSION=1.2.3)
	@if [ -z "$(VERSION)" ]; then \
		echo "âŒ Error: Please provide a version number"; \
		echo "Usage: make release VERSION=1.2.3"; \
		exit 1; \
	fi
	@./scripts/release.sh $(VERSION)

check: test lint ## Run all checks (tests + linting)

all: clean test build ## Clean, test, and build the package
</document_content>
</document>

<document index="18">
<source>PLAN.md</source>
<document_content>
# AudioStretchy Complete Rewrite and Repackaging Plan

## Overview
Complete rewrite and repackaging of AudioStretchy to use git submodules for audio-stretch C library integration, Pedalboard for file I/O, and Hatch for modern Python packaging with cross-platform wheel building.

## Technical Architecture

### Core Components
1. **Git Submodule Integration**: Use https://github.com/dbry/audio-stretch as a git submodule
2. **Audio I/O**: Replace existing I/O with Pedalboard library exclusively
3. **Build System**: Migrate from setuptools to Hatch with cross-platform wheel building
4. **CI/CD**: GitHub Actions for automated building and publishing

### Project Structure
```
audiostretchy/
â”œâ”€â”€ pyproject.toml           # Hatch configuration
â”œâ”€â”€ src/
â”‚   â””â”€â”€ audiostretchy/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ __main__.py      # CLI entry point
â”‚       â”œâ”€â”€ core.py          # Main AudioStretch class
â”‚       â””â”€â”€ c_interface/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ wrapper.py   # C library ctypes wrapper
â”‚           â””â”€â”€ build.py     # C compilation utilities
â”œâ”€â”€ audio-stretch/           # Git submodule
â”‚   â”œâ”€â”€ stretch.h
â”‚   â”œâ”€â”€ stretch.c
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_local.py       # Local wheel building
â”‚   â””â”€â”€ compile_c.py         # C library compilation
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ build.yml        # Cross-platform wheel building
â”‚       â””â”€â”€ publish.yml      # PyPI publishing
â””â”€â”€ tests/
```

## Implementation Phases

### Phase 1: Infrastructure Setup
- [ ] Configure git submodule for audio-stretch
- [ ] Set up Hatch build system configuration
- [ ] Create basic project structure with src layout

### Phase 2: Core Implementation
- [ ] Implement Pedalboard-based audio I/O
- [ ] Create C library compilation system
- [ ] Develop ctypes wrapper for audio-stretch
- [ ] Implement main AudioStretch class

### Phase 3: Build System
- [ ] Create local build scripts for different platforms
- [ ] Set up GitHub Actions for cross-platform building
- [ ] Configure automated PyPI publishing
- [ ] Test wheel building on multiple platforms

### Phase 4: CLI and Testing
- [ ] Implement CLI interface with Fire
- [ ] Create comprehensive test suite
- [ ] Add performance benchmarks
- [ ] Documentation updates

## Technical Specifications

### Hatch Configuration
- Use `hatchling` as build backend
- Configure wheel building with platform-specific compilation
- Set up proper package data inclusion for compiled libraries
- Configure development dependencies and optional extras

### C Library Integration
- Compile stretch.c for multiple platforms (Linux, macOS, Windows)
- Create platform-specific shared libraries (.so, .dylib, .dll)
- Use ctypes for Python-C interface
- Handle different architectures (x86_64, arm64)

### Pedalboard Integration
- Replace all existing audio I/O with Pedalboard AudioFile
- Utilize built-in resampling capabilities
- Support multiple audio formats (WAV, MP3, FLAC, OGG, etc.)
- Optimize for performance and memory usage

### Cross-Platform Wheel Building
- Use cibuildwheel for GitHub Actions
- Support Linux (x86_64, aarch64), macOS (x86_64, arm64), Windows (x86_64)
- Ensure proper C library compilation for each platform
- Handle platform-specific dependencies

## Dependencies

### Core Dependencies
- `pedalboard>=0.8.6` - Audio I/O and effects
- `numpy>=1.23.0` - Numerical operations
- `fire>=0.5.0` - CLI interface

### Build Dependencies
- `hatchling` - Build backend
- `cibuildwheel` - Cross-platform wheel building
- Platform-specific C compilers

### Development Dependencies
- `pytest` - Testing framework
- `pytest-cov` - Coverage reporting
- `black` - Code formatting
- `ruff` - Linting and import sorting

## Success Criteria
1. Git submodule properly integrated and buildable
2. Pedalboard handles all audio I/O operations
3. Hatch successfully builds wheels for all target platforms
4. GitHub Actions automatically build and publish releases
5. Local build scripts work on developer machines
6. All existing functionality preserved with improved performance
7. Clean, maintainable codebase following modern Python practices

</document_content>
</document>

<document index="19">
<source>README.md</source>
<document_content>
# AudioStretchy

**AudioStretchy is a Python library and command-line interface (CLI) tool designed for high-quality time-stretching of audio files without altering their pitch.**

It leverages David Bryantâ€™s robust [audio-stretch C library](https://github.com/dbry/audio-stretch), which implements the Time-Domain Harmonic Scaling (TDHS) algorithm, particularly effective for speech. For versatile audio file handling (WAV, MP3, FLAC, OGG, etc.) and resampling, AudioStretchy integrates [Spotify's Pedalboard library](https://github.com/spotify/pedalboard).

## Table of Contents

- [Who is this for?](#who-is-this-for)
- [Why is it useful?](#why-is-it-useful)
- [Features](#features)
- [Demo](#demo)
- [Installation](#installation)
    - [Standard Installation](#standard-installation)
    - [Development Installation](#development-installation)
- [Usage](#usage)
    - [Command-Line Interface (CLI)](#command-line-interface-cli)
    - [Python API](#python-api)
- [Technical Details](#technical-details)
    - [How it Works](#how-it-works)
    - [Core Modules](#core-modules)
    - [Coding Conventions](#coding-conventions)
    - [Contributing](#contributing)
- [License](#license)

## Who is this for?

AudioStretchy is aimed at:

*   **Musicians and Music Producers:** To adjust the tempo of backing tracks, samples, or entire songs.
*   **Audio Engineers:** For post-production tasks requiring timing adjustments without pitch artifacts.
*   **Podcast and Video Editors:** To fit voiceovers or audio segments into specific time slots.
*   **Software Developers:** Who need to integrate audio time-stretching capabilities into their Python applications.
*   **Researchers and Hobbyists:** Exploring audio processing techniques.

## Why is it useful?

Time-stretching audio without affecting pitch is a common need in audio production. AudioStretchy provides:

*   **High-Quality Results:** The TDHS algorithm is known for producing natural-sounding results, especially with speech.
*   **Ease of Use:** Simple CLI and Python API make it accessible for various workflows.
*   **Format Flexibility:** Supports a wide range of common audio formats thanks to Pedalboard.
*   **Cross-Platform Compatibility:** Works on Windows, macOS, and Linux.

## Features

*   **High-Quality Time Stretching**: Utilizes David Bryant's `audio-stretch` C library (TDHS algorithm).
*   **Silence-Aware Stretching**: Supports separate stretching ratios for gaps/silence via the `gap_ratio` parameter (Note: The Python wrapper currently passes this to the C library; however, effective silence-specific stretching relies on the C library's internal segmentation or future Python-side pre-segmentation logic).
*   **Broad Audio Format Support**: Reads and writes numerous audio formats (WAV, MP3, FLAC, OGG, AIFF, etc.) using the Pedalboard library.
*   **Resampling**: Supports audio resampling, also via Pedalboard.
*   **Adjustable Parameters**: Fine-tune stretching with parameters like frequency limits for period detection, buffer sizes, and silence thresholds.
*   **Cross-Platform**: Includes pre-compiled C libraries for Windows, macOS (x86_64, arm64), and Linux.
*   **Simple CLI and Python API**.

## Demo

Below are links to a short audio file (as WAV and MP3), with the same file stretched at a ratio of 1.2 (making it 20% slower):

| Input                                                                             | Stretched (Ratio 1.2)                                                                     |
| --------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |
| [`audio.wav`](https://github.com/twardoch/audiostretchy/raw/main/tests/audio.wav) | [`audio-1.2.wav`](https://github.com/twardoch/audiostretchy/raw/main/tests/audio-1.2.wav) |
| [`audio.mp3`](https://github.com/twardoch/audiostretchy/raw/main/tests/audio.mp3) | [`audio-1.2.mp3`](https://github.com/twardoch/audiostretchy/raw/main/tests/audio-1.2.mp3) |

## Installation

### Standard Installation

AudioStretchy includes a C extension that provides the core TDHS algorithm. Pre-compiled wheels are provided for Windows, macOS, and Linux, making installation straightforward via pip:

```bash
python3 -m pip install audiostretchy
```

This command installs `audiostretchy` along with its key dependencies:
*   `numpy`: For numerical operations.
*   `pedalboard`: For reading/writing various audio formats and for resampling.
*   `fire`: For the command-line interface.

**Note on Pedalboard Dependencies (FFmpeg):**
For `pedalboard` to support a wide range of audio formats (especially compressed ones like MP3, M4A, OGG), it relies on system libraries like FFmpeg. If you encounter issues opening or saving specific file types, ensure FFmpeg is installed and accessible in your system's PATH.

*   **macOS (using Homebrew):** `brew install ffmpeg`
*   **Linux (Debian/Ubuntu):** `sudo apt-get install ffmpeg`
*   **Windows:** Download FFmpeg from the [official website](https://ffmpeg.org/download.html), extract it, and add its `bin` directory to your system's PATH environment variable.

### Development Installation

To install the development version from the repository for contributing or testing:

```bash
git clone https://github.com/twardoch/audiostretchy.git
cd audiostretchy
git submodule update --init --recursive # To fetch the audio-stretch C library source
python3 -m pip install -e .[testing] # Installs in editable mode with testing dependencies
```

If you modify the C code in `vendors/stretch/stretch.c`, you will need to recompile the C library. This typically involves:
1.  Having a C compiler installed (GCC/Clang on Linux/macOS, MSVC on Windows).
2.  Manually compiling `vendors/stretch/stretch.c` into the appropriate shared library format (`_stretch.so` on Linux, `_stretch.dylib` on macOS, `_stretch.dll` on Windows).
3.  Placing the compiled library into the correct directory within `src/audiostretchy/interface/` (e.g., `src/audiostretchy/interface/linux/`).
The CI workflow (`.github/workflows/ci.yaml`) handles this for official releases.

## Usage

### Command-Line Interface (CLI)

The `audiostretchy` command allows you to stretch audio files directly from your terminal.

**Syntax:**
```bash
audiostretchy INPUT_FILE OUTPUT_FILE [FLAGS]
```

**Positional Arguments:**
*   `INPUT_FILE`: Path to the input audio file (e.g., `input.wav`, `song.mp3`).
*   `OUTPUT_FILE`: Path to save the processed audio file (e.g., `output_stretched.wav`).

**Optional Flags (TDHS Parameters):**
*   `-r, --ratio=FLOAT`: The stretch ratio. Values > 1.0 extend audio (slower playback), < 1.0 shorten audio (faster playback). Default: `1.0` (no change).
*   `-g, --gap_ratio=FLOAT`: Stretch ratio specifically for silence or gaps in the audio. Default: `0.0` (which means use the main `ratio` for gaps). *Note: The underlying C library may use this if it performs internal silence detection, but the Python wrapper does not currently implement pre-segmentation based on this.*
*   `-u, --upper_freq=INT`: Upper frequency limit for period detection in Hz. Affects how the algorithm identifies fundamental frequencies. Default: `333`.
*   `-l, --lower_freq=INT`: Lower frequency limit for period detection in Hz. Default: `55`.
*   `-b, --buffer_ms=FLOAT`: Buffer size in milliseconds, potentially for silence detection logic. Default: `25`. *(Note: Primarily relevant if advanced gap handling is implemented/utilized).*
*   `-t, --threshold_gap_db=FLOAT`: Silence threshold in dB for gap detection. Default: `-40`. *(Note: Primarily relevant if advanced gap handling is implemented/utilized).*
*   `-d, --double_range=BOOL`: Use an extended ratio range (0.25-4.0 instead of the default 0.5-2.0). Set to `True` or `False`. Default: `False`.
*   `-f, --fast_detection=BOOL`: Enable a faster (but potentially lower quality) period detection method. Set to `True` or `False`. Default: `False`.
*   `-n, --normal_detection=BOOL`: Force normal period detection (this can override fast detection if the sample rate is high, depending on C library logic). Set to `True` or `False`. Default: `False`.
*   `-s, --sample_rate=INT`: Target sample rate in Hz for resampling the output. If `0` or omitted, the output will have the same sample rate as the input (unless stretching itself inherently changes it, which TDHS does not aim to do for sample rate). Default: `0` (no resampling).

**Example:**
To make `input.mp3` 20% slower and save it as `output_slow.wav` with a 44100 Hz sample rate:
```bash
audiostretchy input.mp3 output_slow.wav --ratio 1.2 --sample_rate 44100
```

### Python API

AudioStretchy can be used programmatically within your Python scripts.

**Simple Function Call:**
The `stretch_audio` function provides a quick way to process files.

```python
from audiostretchy.stretch import stretch_audio

stretch_audio(
    input_path="path/to/your/input.mp3",
    output_path="path/to/your/output_stretched.wav",
    ratio=0.8,  # Make audio 20% faster
    sample_rate=22050, # Resample output to 22050 Hz
    upper_freq=300, # Adjust upper frequency for period detection
    fast_detection=True # Use faster algorithm
)

print("Audio stretching complete!")
```

**Using the `AudioStretch` Class:**
For more control, or if working with audio data in memory (e.g., from `BytesIO` objects), use the `AudioStretch` class.

```python
from audiostretchy.stretch import AudioStretch
from io import BytesIO

# Initialize the processor
processor = AudioStretch()

# --- Example 1: Processing files ---
processor.open("input.flac") # Pedalboard handles opening various formats

processor.stretch(
    ratio=1.1,          # Make 10% slower
    # gap_ratio=1.5,    # Stretch silence even more (see note on gap_ratio effectiveness)
    upper_freq=350,
    lower_freq=60,
    double_range=True   # Allow ratios like 0.25 or 4.0
)

# Optional: Resample the processed audio
processor.resample(target_framerate=48000)

processor.save("processed_output.ogg") # Pedalboard infers format from extension
# OR: processor.save("processed_output.custom", output_format="ogg")


# --- Example 2: Processing from BytesIO ---
# Assuming `input_audio_bytes` is a bytes object containing audio data (e.g., read from a stream)
# and `input_format` is known (e.g., 'wav', 'mp3')

# input_audio_bytes = b"..." # Your audio data
# input_format = "wav"
#
# input_file_like_object = BytesIO(input_audio_bytes)
# processor.open(file=input_file_like_object, format=input_format) # `format` might be needed if not inferable
#
# processor.stretch(ratio=1.5)
#
# output_file_like_object = BytesIO()
# processor.save(file=output_file_like_object, format="mp3") # Specify output format
#
# stretched_audio_bytes = output_file_like_object.getvalue()
# with open("output_from_bytesio.mp3", "wb") as f:
#     f.write(stretched_audio_bytes)

```

## Technical Details

### How it Works

AudioStretchy operates through several key stages:

1.  **Audio Input/Output & Resampling (via `Pedalboard`):**
    *   When an input file is provided (e.g., MP3, WAV, FLAC), `pedalboard` is used to decode it into raw audio samples (specifically, a NumPy array of `float32` values). It also reads metadata like sample rate and channel count.
    *   If resampling is requested, `pedalboard` handles this efficiently.
    *   After processing, `pedalboard` encodes the modified audio samples back into the desired output format.

2.  **Core Time-Stretching (via `audio-stretch` C library & `TDHSAudioStretch` wrapper):**
    *   The raw audio samples (float32) obtained from `pedalboard` are converted to 16-bit integers (`int16`), as the C library expects this format. If the audio is stereo, channels are interleaved (L, R, L, R...).
    *   The `TDHSAudioStretch` class in `src/audiostretchy/interface/tdhs.py` uses `ctypes` to call functions from the pre-compiled `audio-stretch` shared library (e.g., `_stretch.so`, `_stretch.dylib`, `_stretch.dll`).
    *   The C library implements **Time-Domain Harmonic Scaling (TDHS)**. This algorithm works by:
        *   Analyzing the input audio signal in the time domain.
        *   Identifying periodic segments (related to pitch) within the audio.
        *   To slow down audio (stretch ratio > 1.0), it intelligently repeats these small segments.
        *   To speed up audio (stretch ratio < 1.0), it removes some of these segments.
        *   This is done in a way that aims to preserve the harmonic structure and formants, thus maintaining the original pitch and timbre.
    *   Parameters like `upper_freq` and `lower_freq` guide the C library in its period detection, defining the expected range of fundamental frequencies in the audio.
    *   Flags like `STRETCH_FAST_FLAG` (for `--fast_detection`) and `STRETCH_DUAL_FLAG` (for `--double_range`) modify the C library's behavior.
    *   After the C library processes the audio, the resulting `int16` samples are converted back to `float32` for `pedalboard` to handle.

3.  **Python Orchestration (`AudioStretch` class):**
    *   The `AudioStretch` class in `src/audiostretchy/stretch.py` manages the overall process:
        *   Initializes and uses `PedalboardAudioFile` for I/O.
        *   Prepares data for the `TDHSAudioStretch` wrapper (data type conversion, interleaving).
        *   Calls the `stretch` method of `TDHSAudioStretch`.
        *   Handles data conversion back from the wrapper.
        *   Coordinates resampling if requested.

The `gap_ratio` parameter is intended for applying a different stretch ratio to silent portions of the audio. While the Python wrapper passes this to the C library initialization, the current Python implementation of `AudioStretch.stretch()` processes the entire audio with the primary `ratio`. Effective utilization of `gap_ratio` would typically require the Python code to segment the audio into speech/silence parts first (e.g., based on RMS levels and `threshold_gap_db`), and then apply different ratios to these segments, or for the C library to have internal advanced segmentation logic that uses this parameter. The original C CLI application (`main.c` in `dbry/audio-stretch`) contains such segmentation logic, which is not fully replicated in the current Python bindings.

### Core Modules

*   **`src/audiostretchy/__main__.py`:**
    *   Provides the command-line interface using the `fire` library.
    *   It calls the `stretch_audio` function from `stretch.py`.
*   **`src/audiostretchy/stretch.py`:**
    *   Contains the main `AudioStretch` class that orchestrates the audio processing.
    *   Implements methods for opening, stretching, resampling, and saving audio.
    *   Includes the `stretch_audio` convenience function used by the CLI.
    *   Relies on `pedalboard` for I/O and resampling, and `TDHSAudioStretch` for the core algorithm.
*   **`src/audiostretchy/interface/tdhs.py`:**
    *   Defines the `TDHSAudioStretch` class, which is a Python `ctypes` wrapper around the pre-compiled `audio-stretch` C library.
    *   Loads the shared library (`.so`, `.dylib`, `.dll`) based on the operating system.
    *   Defines argument types and return types for the C functions (`stretch_init`, `stretch_samples`, `stretch_flush`, etc.).
*   **`src/audiostretchy/interface/{win,mac,linux}/`:**
    *   These directories contain the pre-compiled shared C libraries (`_stretch.dll`, `_stretch.dylib`, `_stretch.so`) for different platforms and architectures.
*   **`vendors/stretch/`:**
    *   Contains the source code of David Bryant's `audio-stretch` C library as a Git submodule. This is used for compiling the shared libraries.

### Coding Conventions

This project adheres to standard Python coding practices and uses tools to maintain code quality:

*   **Formatting:** Code is formatted using [Black](https://github.com/psf/black).
*   **Import Sorting:** Imports are sorted using [isort](https://pycqa.github.io/isort/). Configuration is in `.isort.cfg`.
*   **Linting:** Code is linted using [Flake8](https://flake8.pycqa.org/en/latest/). Configuration is in `pyproject.toml` (`[tool.flake8]`).
*   **Pre-commit Hooks:** The `.pre-commit-config.yaml` file defines hooks that run these tools automatically before commits, ensuring consistency. This includes checks for trailing whitespace, large files, valid syntax, etc.

### Contributing

Contributions are welcome! If you'd like to contribute, please follow these general guidelines:

1.  **Fork the Repository:** Create your own fork of the `audiostretchy` repository on GitHub.
2.  **Clone Your Fork:**
    ```bash
    git clone https://github.com/YOUR_USERNAME/audiostretchy.git
    cd audiostretchy
    git submodule update --init --recursive
    ```
3.  **Create a Branch:** Create a new branch for your feature or bug fix:
    ```bash
    git checkout -b my-new-feature
    ```
4.  **Set Up Development Environment:**
    *   It's recommended to use a virtual environment:
        ```bash
        python3 -m venv venv
        source venv/bin/activate  # On Windows: venv\Scripts\activate
        ```
    *   Install the project in editable mode with testing dependencies:
        ```bash
        python3 -m pip install -e .[testing]
        ```
    *   Install pre-commit hooks:
        ```bash
        pre-commit install
        ```
5.  **Make Your Changes:** Implement your feature or bug fix.
    *   Adhere to the coding conventions (Black, isort, Flake8). The pre-commit hooks will help with this.
    *   Write tests for any new functionality in the `tests/` directory.
6.  **Run Tests:** Ensure all tests pass:
    ```bash
    pytest
    ```
    Check test coverage:
    ```bash
    pytest --cov src/audiostretchy --cov-report term-missing
    ```
7.  **Commit Your Changes:**
    ```bash
    git add .
    git commit -m "feat: Add new feature X" # Or "fix: Resolve bug Y"
    ```
8.  **Push to Your Fork:**
    ```bash
    git push origin my-new-feature
    ```
9.  **Submit a Pull Request:** Open a pull request from your branch to the `main` branch of the original `twardoch/audiostretchy` repository. Provide a clear description of your changes.

If you plan to modify the C library code in `vendors/stretch/`, you will also need to recompile it for your platform and potentially update the CI workflows if changes are significant.

## Development and Release Process

AudioStretchy uses git-tag-based semantic versioning with automated CI/CD pipeline:

### Quick Start for Development

```bash
# Set up development environment
make dev

# Run tests
make test

# Run linting and formatting
make lint
make format

# Build package
make build
```

### Release Process

```bash
# Create a new release (requires main branch)
make release VERSION=1.2.3
```

This will:
- Run all tests
- Build the package
- Create a git tag
- Trigger automated CI/CD pipeline
- Publish to PyPI automatically

### CI/CD Pipeline

- **Multi-platform testing**: Ubuntu, Windows, macOS
- **Python versions**: 3.8, 3.9, 3.10, 3.11, 3.12
- **Automatic wheel building**: Binary wheels for all platforms
- **Automated PyPI publishing**: On git tag creation

See [SEMVER_GUIDE.md](SEMVER_GUIDE.md) for detailed release documentation.

## License

*   The Python wrapper code for AudioStretchy (this project) is licensed under the **BSD-3-Clause License**. See [LICENSE.txt](./LICENSE.txt). Copyright (c) 2023-2024 Adam Twardoch.
*   The core C library `vendors/stretch/stretch.c` is Copyright (c) David Bryant and is included under its original BSD-style license.
*   Audio I/O and Resampling functionalities are provided by [Spotify's Pedalboard library](https://github.com/spotify/pedalboard), which is licensed under the Apache License 2.0. Pedalboard itself may utilize other libraries with their own respective licenses (e.g., libsndfile, Rubber Band library).
*   Some Python code may have been written with assistance from AI language models.

_Current Version: (to be updated by release process)_

</document_content>
</document>

<document index="20">
<source>SEMVER_GUIDE.md</source>
<document_content>
# Semantic Versioning and Release Guide

## Overview

AudioStretchy uses git-tag-based semantic versioning with automated CI/CD pipeline for releases. The version is automatically determined from git tags using `setuptools_scm`.

## Version Format

Versions follow semantic versioning (SemVer) format: `MAJOR.MINOR.PATCH[-PRERELEASE]`

- **MAJOR**: Incompatible API changes
- **MINOR**: New functionality in a backwards compatible manner  
- **PATCH**: Backwards compatible bug fixes
- **PRERELEASE**: Optional pre-release identifier (e.g., `1.0.0-alpha`, `1.0.0-beta.1`)

## Release Process

### 1. Local Development

```bash
# Set up development environment
make dev

# Run tests
make test

# Run linting
make lint

# Build package
make build
```

### 2. Creating a Release

```bash
# Create and push a release tag
make release VERSION=1.2.3

# Or manually:
./scripts/release.sh 1.2.3
```

This will:
- Validate the version format
- Ensure you're on the main branch
- Run all tests
- Build the package
- Create a git tag
- Push the tag to GitHub

### 3. Automated Release Pipeline

When you push a tag to GitHub:

1. **CI Pipeline Triggers**: GitHub Actions detects the new tag
2. **Multi-platform Testing**: Tests run on Ubuntu, Windows, and macOS
3. **Wheel Building**: Binary wheels are built for all supported platforms
4. **Automatic PyPI Release**: Package is automatically published to PyPI

## Version Detection

The package version is automatically detected from git tags using `setuptools_scm`:

```python
# In Python code
import audiostretchy
print(audiostretchy.__version__)
```

```bash
# From command line
python -c "import audiostretchy; print(audiostretchy.__version__)"
```

## Development Versions

During development (between releases), versions are automatically generated:
- Format: `1.2.3.dev4+g1234abcd`
- `dev4`: 4 commits since last tag
- `g1234abcd`: Short git commit hash

## Pre-release Versions

For pre-releases, use descriptive tags:

```bash
# Alpha release
git tag -a v1.3.0-alpha.1 -m "Alpha release 1.3.0-alpha.1"

# Beta release  
git tag -a v1.3.0-beta.1 -m "Beta release 1.3.0-beta.1"

# Release candidate
git tag -a v1.3.0-rc.1 -m "Release candidate 1.3.0-rc.1"
```

## Branch Strategy

- **main**: Production-ready code, all releases are made from here
- **develop**: Integration branch for features (optional)
- **feature/***: Feature branches

## CI/CD Pipeline Details

### Test Matrix
- **Operating Systems**: Ubuntu, Windows, macOS
- **Python Versions**: 3.8, 3.9, 3.10, 3.11, 3.12
- **Dependencies**: FFmpeg, libsndfile

### Build Process
1. **Source Distribution**: Built on Ubuntu
2. **Binary Wheels**: Built using `cibuildwheel` for all platforms
3. **Testing**: Each wheel is tested before release
4. **Publication**: Automatic upload to PyPI on successful build

### Security
- Uses PyPI trusted publishing with GitHub Actions
- No manual token management required
- Automatic signing and verification

## Manual Release Steps (if needed)

If automatic release fails, you can manually release:

```bash
# Build locally
make build

# Check distribution
python -m twine check dist/*

# Upload to PyPI (requires API token)
python -m twine upload dist/*
```

## Troubleshooting

### Common Issues

1. **Version not detected**: Ensure you're in a git repository with tags
2. **Build failures**: Check that all dependencies are installed
3. **Test failures**: Run `make test` locally first
4. **PyPI upload errors**: Check that version doesn't already exist

### Debug Commands

```bash
# Check current version
python -c "import setuptools_scm; print(setuptools_scm.get_version())"

# Check git status
git status
git tag -l

# Validate build
python -m build --wheel
python -m twine check dist/*
```

## Best Practices

1. **Always test before releasing**: Use `make test` and `make build`
2. **Follow semantic versioning**: Breaking changes require major version bump
3. **Write meaningful commit messages**: They become part of the version history
4. **Tag releases properly**: Use annotated tags with descriptive messages
5. **Keep CHANGELOG.md updated**: Document all changes between versions

## Integration with setuptools_scm

The `pyproject.toml` configuration:

```toml
[tool.setuptools_scm]
version_scheme = "no-guess-dev"
```

This ensures consistent version numbering and development version formatting.
</document_content>
</document>

<document index="21">
<source>TODO.md</source>
<document_content>
# AudioStretchy Complete Rewrite - TODO

## Completed âœ…

### Infrastructure Setup
- [x] Set up git submodule for audio-stretch 
- [x] Configure Hatch build system in pyproject.toml
- [x] Create new project structure with src layout
- [x] Remove old setuptools-based configuration

### Core Implementation  
- [x] Implement Pedalboard-based audio I/O in core.py
- [x] Create C library compilation system in c_interface/build.py
- [x] Develop ctypes wrapper for audio-stretch in c_interface/wrapper.py
- [x] Implement main AudioStretch class with TDHS integration
- [x] Update __init__.py and __main__.py for new structure
- [x] Compile C library for current platform

### Build System
- [x] Create local build scripts (scripts/build_local.py, scripts/compile_c.py)
- [x] Set up GitHub Actions for cross-platform building (.github/workflows/build.yml)
- [x] Configure automated PyPI publishing (.github/workflows/publish.yml)
- [x] Configure cibuildwheel for cross-platform wheels

### Testing Framework
- [x] Create basic test suite for core functionality (tests/test_core.py)
- [x] Test audio data conversion methods (float32 âŸ· int16)
- [x] Test error handling for edge cases
- [x] Remove old implementation files

## Next Steps ğŸ“‹

### Testing & Validation
- [ ] Test package build with `python -m build`
- [ ] Verify wheel includes compiled C libraries
- [ ] Test installation from wheel in clean environment  
- [ ] Add integration tests with actual audio files
- [ ] Test CLI functionality end-to-end

### Documentation & Polish
- [ ] Update README.md with new architecture details
- [ ] Update CHANGELOG.md with rewrite information
- [ ] Test cross-platform compatibility
- [ ] Performance benchmarking vs old implementation

### Release Preparation
- [ ] Version bump and tagging
- [ ] Test GitHub Actions workflows
- [ ] Documentation review
- [ ] Final validation of all functionality

</document_content>
</document>

<document index="22">
<source>WORK.md</source>
<document_content>
# Work Progress - AudioStretchy Complete Rewrite

## Completed Work âœ…

### Major Architecture Changes
- **Migrated from setuptools to Hatch** - Modern Python packaging with pyproject.toml
- **Git submodule integration** - Added https://github.com/dbry/audio-stretch as submodule
- **Pedalboard I/O exclusive** - Replaced all audio I/O with Pedalboard library
- **Clean src-layout** - Reorganized project structure following modern Python practices

### New Implementation Components

1. **C Interface Module** (`src/audiostretchy/c_interface/`)
   - `wrapper.py` - Modern ctypes wrapper with error handling
   - `build.py` - Cross-platform C library compilation utilities
   - `lib/` - Directory for compiled shared libraries
   - Successfully compiled `_stretch_x64.so` for Linux

2. **Core AudioStretch Class** (`src/audiostretchy/core.py`)
   - Clean implementation using Pedalboard for all I/O
   - Proper float32 â†” int16 conversion for C library interface
   - Support for mono/stereo audio with channel interleaving
   - Comprehensive error handling and validation
   - Preserved all original functionality

3. **Build Infrastructure**
   - `scripts/build_local.py` - Local development build script
   - `scripts/compile_c.py` - Standalone C compilation utility
   - Hatch configuration for cross-platform wheel building
   - cibuildwheel integration for automated wheels

4. **Testing Framework**
   - `tests/test_core.py` - Comprehensive test suite
   - Tests for audio data conversion methods
   - Error handling validation
   - Unit tests for all core functionality

### Updated Project Files
- `pyproject.toml` - Complete Hatch configuration
- `__init__.py` - Clean imports and version handling
- `__main__.py` - Updated CLI entry point
- `PLAN.md` - Detailed implementation plan
- `TODO.md` - Progress tracking
- `GITHUB_WORKFLOW.md` - CI/CD setup guide (due to permissions)

### Build System Improvements
- **Modern packaging** with Hatch and pyproject.toml
- **Cross-platform compilation** support for C library
- **Automated wheel building** configuration
- **GitHub Actions workflows** (provided as templates)
- **Development environment** setup with proper dependencies

## Key Technical Achievements

### Audio Processing Pipeline
1. **Pedalboard Integration** - All audio I/O now handled by Pedalboard
2. **TDHS Algorithm** - Preserved audio-stretch C library integration
3. **Data Flow** - Clean float32 â†” int16 conversion pipeline
4. **Error Handling** - Comprehensive validation throughout

### Cross-Platform Support
- **Linux** - Native GCC compilation (âœ… tested)
- **macOS** - Clang compilation support with architecture detection
- **Windows** - MSVC compilation support
- **Architecture support** - x86_64, ARM64 detection and handling

### Code Quality
- **Type hints** throughout the codebase
- **Modern Python practices** (pathlib, context managers)
- **Comprehensive documentation** with docstrings
- **Clean separation of concerns** between modules
- **Proper resource management** with context managers

## Cleanup Completed
- Removed old `src/audiostretchy/stretch.py`
- Removed old `src/audiostretchy/interface/` directory
- Removed old `vendors/` directory (replaced with submodule)
- Removed deprecated files and dependencies
- Updated imports and references

## Next Steps (for manual completion)

### GitHub Workflows
Due to GitHub App permissions, the workflow files need to be manually created:
1. Create `.github/workflows/build.yml` (provided in GITHUB_WORKFLOW.md)
2. Create `.github/workflows/publish.yml` (provided in GITHUB_WORKFLOW.md)
3. Configure PyPI API token for automated publishing

### Testing & Validation
1. Install dependencies and test build process
2. Verify wheel creation includes compiled C libraries
3. Test installation in clean environment
4. Add integration tests with actual audio files
5. Cross-platform testing

### Documentation
1. Update README.md with new architecture details
2. Update CHANGELOG.md with rewrite information
3. Version bump and release preparation

## Technical Summary

This complete rewrite modernizes AudioStretchy with:
- âœ… **Git submodule** for audio-stretch source integration
- âœ… **Pedalboard** for all audio I/O operations
- âœ… **Hatch** build system with cross-platform wheels
- âœ… **Modern Python** practices and type hints
- âœ… **Comprehensive testing** framework
- âœ… **CI/CD ready** (templates provided)
- âœ… **Clean architecture** with proper separation of concerns

The repository is now ready for modern Python development with automated building and publishing capabilities.
</document_content>
</document>

<document index="23">
<source>docs/Makefile</source>
<document_content>
# Makefile for Sphinx documentation
#

# You can set these variables from the command line, and also
# from the environment for the first two.
SPHINXOPTS    ?=
SPHINXBUILD   ?= sphinx-build
SOURCEDIR     = .
BUILDDIR      = _build
AUTODOCDIR    = api

# User-friendly check for sphinx-build
ifeq ($(shell which $(SPHINXBUILD) >/dev/null 2>&1; echo $?), 1)
$(error "The '$(SPHINXBUILD)' command was not found. Make sure you have Sphinx installed, then set the SPHINXBUILD environment variable to point to the full path of the '$(SPHINXBUILD)' executable. Alternatively you can add the directory with the executable to your PATH. If you don't have Sphinx installed, grab it from https://sphinx-doc.org/")
endif

.PHONY: help clean Makefile

# Put it first so that "make" without argument is like "make help".
help:
	@$(SPHINXBUILD) -M help "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)

clean:
	rm -rf $(BUILDDIR)/* $(AUTODOCDIR)

# Catch-all target: route all unknown targets to Sphinx using the new
# "make mode" option.  $(O) is meant as a shortcut for $(SPHINXOPTS).
%: Makefile
	@$(SPHINXBUILD) -M $@ "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)

</document_content>
</document>

<document index="24">
<source>docs/_static/.gitignore</source>
<document_content>
# Empty directory

</document_content>
</document>

<document index="25">
<source>docs/authors.md</source>
<document_content>
```{include} ../AUTHORS.md
:relative-docs: docs/
:relative-images:
```

</document_content>
</document>

<document index="26">
<source>docs/changelog.md</source>
<document_content>
```{include} ../CHANGELOG.md
:relative-docs: docs/
:relative-images:
```

</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/docs/conf.py
# Language: python

import os
import shutil
import sys
from sphinx.ext import apidoc
from sphinx import apidoc
import sphinx
from audiostretchy import __version__ as version


<document index="27">
<source>docs/contributing.md</source>
<document_content>
```{include} ../CONTRIBUTING.md
:relative-docs: docs/
:relative-images:
```

</document_content>
</document>

<document index="28">
<source>docs/index.md</source>
<document_content>
# audiostretchy

Add a short description here!


## Note

> This is the main page of your project's [Sphinx] documentation. It is
> formatted in [Markdown]. Add additional pages by creating md-files in
> `docs` or rst-files (formatted in [reStructuredText]) and adding links to
> them in the `Contents` section below.
>
> Please check [Sphinx] and [MyST] for more information
> about how to document your project and how to configure your preferences.


## Contents

```{toctree}
:maxdepth: 2

Overview <readme>
Contributions & Help <contributing>
License <license>
Authors <authors>
Changelog <changelog>
Module Reference <api/modules>
```

## Indices and tables

* {ref}`genindex`
* {ref}`modindex`
* {ref}`search`

[Sphinx]: http://www.sphinx-doc.org/
[Markdown]: https://daringfireball.net/projects/markdown/
[reStructuredText]: http://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html
[MyST]: https://myst-parser.readthedocs.io/en/latest/

</document_content>
</document>

<document index="29">
<source>docs/license.md</source>
<document_content>
# License

```{literalinclude} ../LICENSE.txt
:language: text
```

</document_content>
</document>

<document index="30">
<source>docs/readme.md</source>
<document_content>
```{include} ../README.md
:relative-docs: docs/
:relative-images:
```

</document_content>
</document>

<document index="31">
<source>docs/requirements.txt</source>
<document_content>
# Requirements file for ReadTheDocs, check .readthedocs.yml.
# To build the module reference correctly, make sure every external package
# under `install_requires` in `setup.cfg` is also listed here!
# sphinx_rtd_theme
myst-parser[linkify]
sphinx>=3.2.1

</document_content>
</document>

<document index="32">
<source>pyproject.toml</source>
<document_content>
[build-system]
requires = ["hatchling", "hatch-vcs"]
build-backend = "hatchling.build"

[project]
name = "audiostretchy"
dynamic = ["version"]
description = "AudioStretchy is a Python library and CLI tool for high-quality time-stretching of audio files without changing pitch. Uses David Bryant's audio-stretch C library with Pedalboard for versatile audio I/O."
readme = "README.md"
authors = [{name = "Adam Twardoch", email = "adam+github@twardoch.com"}]
license = "BSD-3-Clause"
license-files = ["LICENSE.txt", "AUTHORS.md"]
requires-python = ">=3.8"
classifiers = [
    "Development Status :: 4 - Beta",
    "Operating System :: MacOS",
    "Operating System :: Microsoft :: Windows",
    "Operating System :: POSIX",
    "Programming Language :: C",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Multimedia :: Sound/Audio",
    "Topic :: Multimedia :: Sound/Audio :: Conversion",
    "Topic :: Multimedia :: Sound/Audio :: Speech",
]
dependencies = [
    "fire>=0.5.0",
    "numpy>=1.23.0",
    "pedalboard>=0.8.6",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0", 
    "ruff>=0.1.0",
    "build>=0.10.0",
]
test = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "soundfile>=0.12.0",
]

[project.urls]
Homepage = "https://github.com/twardoch/audiostretchy"
Repository = "https://github.com/twardoch/audiostretchy.git"
Issues = "https://github.com/twardoch/audiostretchy/issues"

[project.scripts]
audiostretchy = "audiostretchy.__main__:main"

# Hatch configuration
[tool.hatch.version]
source = "vcs"

[tool.hatch.build.targets.wheel]
packages = ["src/audiostretchy"]
include = [
    "src/audiostretchy/**/*.py",
    "src/audiostretchy/**/*.so",
    "src/audiostretchy/**/*.dylib", 
    "src/audiostretchy/**/*.dll",
]

[tool.hatch.build.targets.sdist]
include = [
    "/src",
    "/tests",
    "/audio-stretch",
    "/scripts",
    "pyproject.toml",
    "README.md",
    "LICENSE.txt",
    "AUTHORS.md",
]

# Development environment
[tool.hatch.envs.default]
dependencies = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
    "build>=0.10.0",
]

[tool.hatch.envs.test]
dependencies = [
    "pytest>=7.0.0", 
    "pytest-cov>=4.0.0",
    "soundfile>=0.12.0",
]

# Testing configuration
[tool.pytest.ini_options]
addopts = "--cov=src/audiostretchy --cov-report=term-missing --verbose"
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]

# Linting and formatting
[tool.ruff]
line-length = 88
target-version = "py38"
extend-exclude = ["build", "dist"]

[tool.ruff.lint]
select = ["E", "F", "W", "I", "N", "UP", "YTT", "S", "BLE", "B", "A", "COM", "C4", "DTZ", "T10", "EM", "EXE", "ISC", "ICN", "G", "INP", "PIE", "T20", "PT", "Q", "RSE", "RET", "SLF", "SIM", "TID", "TCH", "ARG", "PTH", "ERA", "PD", "PGH", "PL", "TRY", "NPY", "RUF"]
ignore = ["E203", "W503", "S101", "PLR0913", "PLR0912", "PLR0915", "C901"]

[tool.black]
line-length = 88
target-version = ["py38", "py39", "py310", "py311", "py312"]

</document_content>
</document>

<document index="33">
<source>scripts/build.sh</source>
<document_content>
#!/bin/bash
# this_file: scripts/build.sh

set -e

echo "ğŸ”§ AudioStretchy Build Script"
echo "============================="

# Check if we're in the right directory
if [ ! -f "pyproject.toml" ]; then
    echo "âŒ Error: Please run this script from the project root directory"
    exit 1
fi

# Clean previous builds
echo "ğŸ§¹ Cleaning previous builds..."
rm -rf build/ dist/ *.egg-info/

# Update submodules
echo "ğŸ“¥ Updating submodules..."
git submodule update --init --recursive

# Install build dependencies
echo "ğŸ“¦ Installing build dependencies..."
python -m pip install --upgrade pip build twine

# Build the package
echo "ğŸ—ï¸ Building package..."
python -m build

# Verify the build
echo "âœ… Verifying build..."
python -m twine check dist/*

# Display build artifacts
echo "ğŸ“‹ Build artifacts:"
ls -la dist/

echo "âœ… Build completed successfully!"
echo "ğŸ“ Artifacts are in the 'dist/' directory"
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/scripts/build_local.py
# Language: python

import argparse
import os
import subprocess
import sys
from pathlib import Path
from audiostretchy.c_interface.build import AudioStretchBuilder

def setup_environment(()):
    """Set up the build environment."""

def compile_c_library((force: bool = False)):
    """Compile the audio-stretch C library."""

def build_wheel(()):
    """Build Python wheel using hatch."""

def install_dev_dependencies(()):
    """Install development dependencies."""

def run_tests(()):
    """Run the test suite."""

def main(()):
    """Main build script."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/scripts/compile_c.py
# Language: python

import argparse
import sys
from pathlib import Path
from audiostretchy.c_interface.build import AudioStretchBuilder

def main(()):
    """Main compilation script."""


<document index="34">
<source>scripts/release.sh</source>
<document_content>
#!/bin/bash
# this_file: scripts/release.sh

set -e

echo "ğŸš€ AudioStretchy Release Script"
echo "==============================="

# Check if we're in the right directory
if [ ! -f "pyproject.toml" ]; then
    echo "âŒ Error: Please run this script from the project root directory"
    exit 1
fi

# Check if version is provided
if [ -z "$1" ]; then
    echo "âŒ Error: Please provide a version number"
    echo "Usage: $0 <version>"
    echo "Example: $0 1.2.3"
    exit 1
fi

VERSION=$1

# Validate version format (basic semver check)
if ! echo "$VERSION" | grep -E '^[0-9]+\.[0-9]+\.[0-9]+(-[a-zA-Z0-9]+)?$' >/dev/null; then
    echo "âŒ Error: Version must be in semver format (e.g., 1.2.3 or 1.2.3-beta)"
    exit 1
fi

# Check if we're on main branch
CURRENT_BRANCH=$(git branch --show-current)
if [ "$CURRENT_BRANCH" != "main" ]; then
    echo "âŒ Error: Releases can only be made from the main branch"
    echo "Current branch: $CURRENT_BRANCH"
    exit 1
fi

# Check if working directory is clean
if [ -n "$(git status --porcelain)" ]; then
    echo "âŒ Error: Working directory is not clean. Please commit all changes first."
    git status
    exit 1
fi

# Pull latest changes
echo "ğŸ“¥ Pulling latest changes..."
git pull origin main

# Run tests
echo "ğŸ§ª Running tests..."
./scripts/test.sh

# Build the package
echo "ğŸ—ï¸ Building package..."
./scripts/build.sh

# Create git tag
echo "ğŸ·ï¸ Creating git tag v$VERSION..."
git tag -a "v$VERSION" -m "Release version $VERSION"

# Push tag to remote
echo "ğŸ“¤ Pushing tag to remote..."
git push origin "v$VERSION"

echo "âœ… Release process completed!"
echo "ğŸ‰ Version $VERSION has been tagged and pushed"
echo "ğŸ“ GitHub Actions will now build and publish the release"
echo "ğŸ”— Create a release at: https://github.com/$(git config remote.origin.url | sed 's/.*github.com[:/]\(.*\)\.git/\1/')/releases/new?tag=v$VERSION"
</document_content>
</document>

<document index="35">
<source>scripts/test.sh</source>
<document_content>
#!/bin/bash
# this_file: scripts/test.sh

set -e

echo "ğŸ§ª AudioStretchy Test Script"
echo "==========================="

# Check if we're in the right directory
if [ ! -f "pyproject.toml" ]; then
    echo "âŒ Error: Please run this script from the project root directory"
    exit 1
fi

# Install test dependencies
echo "ğŸ“¦ Installing test dependencies..."
python -m pip install --upgrade pip
pip install -e .[testing]

# Run tests with coverage
echo "ğŸ§ª Running tests with coverage..."
python -m pytest tests/ -v --cov=src/audiostretchy --cov-report=term-missing --cov-report=html

# Run linting
echo "ğŸ” Running linting..."
python -m flake8 src/audiostretchy/ tests/

# Check if coverage report was generated
if [ -f "htmlcov/index.html" ]; then
    echo "ğŸ“Š Coverage report generated at htmlcov/index.html"
fi

echo "âœ… All tests passed!"
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/setup.py
# Language: python

from setuptools import setup


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/src/audiostretchy/__init__.py
# Language: python

import sys
from importlib.metadata import PackageNotFoundError, version
from importlib_metadata import PackageNotFoundError, version
from .core import AudioStretch, stretch_audio


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/src/audiostretchy/__main__.py
# Language: python

import fire
from .core import stretch_audio

def main(()):
    """Main CLI entry point."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/src/audiostretchy/c_interface/__init__.py
# Language: python

from .wrapper import TDHSAudioStretch


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/src/audiostretchy/c_interface/build.py
# Language: python

import os
import platform
import subprocess
import shutil
from pathlib import Path
from typing import Dict, List, Optional
import argparse

class AudioStretchBuilder:
    """Handles compilation of the audio-stretch C library."""
    def __init__((self, source_dir: Optional[Path] = None, output_dir: Optional[Path] = None)):
        """ Initialize the builder...."""
    def get_compiler_config((self)) -> Dict[str, List[str]]:
        """Get compiler configuration for the current platform."""
    def find_source_files((self)) -> List[Path]:
        """Find C source files to compile."""
    def compile_library((self, force: bool = False)) -> Path:
        """ Compile the audio-stretch library...."""
    def clean((self)) -> None:
        """Remove compiled libraries."""
    def build_all_platforms((self, platforms: Optional[List[str]] = None)) -> Dict[str, Path]:
        """ Build libraries for multiple platforms (for CI use)...."""

def __init__((self, source_dir: Optional[Path] = None, output_dir: Optional[Path] = None)):
    """ Initialize the builder...."""

def get_compiler_config((self)) -> Dict[str, List[str]]:
    """Get compiler configuration for the current platform."""

def find_source_files((self)) -> List[Path]:
    """Find C source files to compile."""

def compile_library((self, force: bool = False)) -> Path:
    """ Compile the audio-stretch library...."""

def clean((self)) -> None:
    """Remove compiled libraries."""

def build_all_platforms((self, platforms: Optional[List[str]] = None)) -> Dict[str, Path]:
    """ Build libraries for multiple platforms (for CI use)...."""

def main(()):
    """Command-line interface for building the C library."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/src/audiostretchy/c_interface/wrapper.py
# Language: python

import ctypes
import platform
from pathlib import Path
from typing import Optional
import numpy as np

class TDHSAudioStretch:
    """ Python wrapper for the audio-stretch C library using TDHS algorithm...."""
    def __init__((
        self, 
        shortest_period: int, 
        longest_period: int, 
        num_chans: int, 
        flags: int
    )) -> None:
        """ Initialize the stretching context...."""
    def _load_library((self)) -> ctypes.CDLL:
        """Load the appropriate shared library for the current platform."""
    def _setup_function_signatures((self)) -> None:
        """Set up ctypes function signatures for the C library."""
    def output_capacity((self, max_num_samples: int, max_ratio: float)) -> int:
        """ Calculate required output buffer capacity...."""
    def process_samples((
        self, 
        samples: np.ndarray, 
        num_samples: int, 
        output: np.ndarray, 
        ratio: float
    )) -> int:
        """ Process audio samples with specified stretch ratio...."""
    def flush((self, output: np.ndarray)) -> int:
        """ Flush remaining samples from internal buffers...."""
    def reset((self)) -> None:
        """Reset the stretch context to initial state."""
    def deinit((self)) -> None:
        """Clean up and free the stretch context."""
    def __del__((self)) -> None:
        """Ensure cleanup on object destruction."""

def __init__((
        self, 
        shortest_period: int, 
        longest_period: int, 
        num_chans: int, 
        flags: int
    )) -> None:
    """ Initialize the stretching context...."""

def _load_library((self)) -> ctypes.CDLL:
    """Load the appropriate shared library for the current platform."""

def _setup_function_signatures((self)) -> None:
    """Set up ctypes function signatures for the C library."""

def output_capacity((self, max_num_samples: int, max_ratio: float)) -> int:
    """ Calculate required output buffer capacity...."""

def process_samples((
        self, 
        samples: np.ndarray, 
        num_samples: int, 
        output: np.ndarray, 
        ratio: float
    )) -> int:
    """ Process audio samples with specified stretch ratio...."""

def flush((self, output: np.ndarray)) -> int:
    """ Flush remaining samples from internal buffers...."""

def reset((self)) -> None:
    """Reset the stretch context to initial state."""

def deinit((self)) -> None:
    """Clean up and free the stretch context."""

def __del__((self)) -> None:
    """Ensure cleanup on object destruction."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/src/audiostretchy/core.py
# Language: python

from io import BytesIO
from pathlib import Path
from typing import BinaryIO, Optional, Union
import numpy as np
from pedalboard import Resample
from pedalboard.io import AudioFile
from .c_interface import TDHSAudioStretch

class AudioStretch:
    """ High-level interface for audio time-stretching using TDHS algorithm...."""
    def __init__((self)):
        """Initialize AudioStretch processor."""
    def open((
        self,
        path: Optional[Union[str, Path]] = None,
        file: Optional[BinaryIO] = None,
        format: Optional[str] = None,
    )) -> None:
        """ Open an audio file using Pedalboard...."""
    def save((
        self,
        path: Optional[Union[str, Path]] = None,
        file: Optional[BinaryIO] = None,
        format: Optional[str] = None,
    )) -> None:
        """ Save processed audio using Pedalboard...."""
    def resample((self, target_samplerate: int)) -> None:
        """ Resample audio to target sample rate using Pedalboard...."""
    def stretch((
        self,
        ratio: float = 1.0,
        gap_ratio: float = 0.0,
        upper_freq: int = 333,
        lower_freq: int = 55,
        buffer_ms: float = 25.0,
        threshold_gap_db: float = -40.0,
        double_range: bool = False,
        fast_detection: bool = False,
        normal_detection: bool = False,
    )) -> None:
        """ Stretch audio using the TDHS algorithm...."""
    def _convert_to_int16((self, samples: np.ndarray)) -> np.ndarray:
        """Convert float32 samples to int16 format expected by C library."""
    def _convert_from_int16((self, samples_int16: np.ndarray)) -> np.ndarray:
        """Convert int16 samples back to float32 format."""
    def _process_with_stretcher((
        self, 
        stretcher: TDHSAudioStretch,
        samples_int16: np.ndarray,
        ratio: float
    )) -> np.ndarray:
        """Process samples using the TDHS stretcher."""

def __init__((self)):
    """Initialize AudioStretch processor."""

def open((
        self,
        path: Optional[Union[str, Path]] = None,
        file: Optional[BinaryIO] = None,
        format: Optional[str] = None,
    )) -> None:
    """ Open an audio file using Pedalboard...."""

def save((
        self,
        path: Optional[Union[str, Path]] = None,
        file: Optional[BinaryIO] = None,
        format: Optional[str] = None,
    )) -> None:
    """ Save processed audio using Pedalboard...."""

def resample((self, target_samplerate: int)) -> None:
    """ Resample audio to target sample rate using Pedalboard...."""

def stretch((
        self,
        ratio: float = 1.0,
        gap_ratio: float = 0.0,
        upper_freq: int = 333,
        lower_freq: int = 55,
        buffer_ms: float = 25.0,
        threshold_gap_db: float = -40.0,
        double_range: bool = False,
        fast_detection: bool = False,
        normal_detection: bool = False,
    )) -> None:
    """ Stretch audio using the TDHS algorithm...."""

def _convert_to_int16((self, samples: np.ndarray)) -> np.ndarray:
    """Convert float32 samples to int16 format expected by C library."""

def _convert_from_int16((self, samples_int16: np.ndarray)) -> np.ndarray:
    """Convert int16 samples back to float32 format."""

def _process_with_stretcher((
        self, 
        stretcher: TDHSAudioStretch,
        samples_int16: np.ndarray,
        ratio: float
    )) -> np.ndarray:
    """Process samples using the TDHS stretcher."""

def stretch_audio((
    input_path: Union[str, Path],
    output_path: Union[str, Path],
    ratio: float = 1.0,
    gap_ratio: float = 0.0,
    upper_freq: int = 333,
    lower_freq: int = 55,
    buffer_ms: float = 25.0,
    threshold_gap_db: float = -40.0,
    double_range: bool = False,
    fast_detection: bool = False,
    normal_detection: bool = False,
    sample_rate: int = 0,
)) -> None:
    """ Convenience function to stretch an audio file...."""


<document index="36">
<source>src/audiostretchy/dummy.c</source>
<document_content>
// This is a dummy C file.
// Its purpose is to make setuptools generate a platform-specific wheel
// because this package includes pre-compiled binaries via package_data.
void dummy_function() {
}

</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/src/audiostretchy/interface/tdhs.py
# Language: python

import ctypes
import platform
from pathlib import Path
import numpy as np

class TDHSAudioStretch:
    """ The Stretch class is a Python binding for the _stretch library, providing an interface..."""
    def __init__((
        self, shortest_period: int, longest_period: int, num_chans: int, flags: int
    )) -> None:
        """ Initialize the stretching context with the given parameters...."""
    def output_capacity((self, max_num_samples: int, max_ratio: float)) -> int:
        """ Determine the number of samples to reserve in the output array for..."""
    def process_samples((
        self, samples: np.ndarray, num_samples: int, output: np.ndarray, ratio: float
    )) -> int:
        """ Process the samples with a specified ratio...."""
    def flush((self, output: np.ndarray)) -> int:
        """ Flush any leftover samples out at normal speed...."""
    def reset((self)) -> None:
        """ Reset the stretching context...."""
    def deinit((self)) -> None:
        """ Deinitialize the stretching context and free up memory...."""

def __init__((
        self, shortest_period: int, longest_period: int, num_chans: int, flags: int
    )) -> None:
    """ Initialize the stretching context with the given parameters...."""

def output_capacity((self, max_num_samples: int, max_ratio: float)) -> int:
    """ Determine the number of samples to reserve in the output array for..."""

def process_samples((
        self, samples: np.ndarray, num_samples: int, output: np.ndarray, ratio: float
    )) -> int:
    """ Process the samples with a specified ratio...."""

def flush((self, output: np.ndarray)) -> int:
    """ Flush any leftover samples out at normal speed...."""

def reset((self)) -> None:
    """ Reset the stretching context...."""

def deinit((self)) -> None:
    """ Deinitialize the stretching context and free up memory...."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/src/audiostretchy/stretch.py
# Language: python

from io import BytesIO
from pathlib import Path
from typing import BinaryIO
from wave import Wave_read, Wave_write
import numpy as np
import pedalboard
from pedalboard import Pedalboard, Resample
from pedalboard import time_stretch as TimeStretch
from pedalboard.io import (
    AudioFile as PedalboardAudioFile,
)
from .interface.tdhs import TDHSAudioStretch

class AudioStretch:
    """ Main class to perform audio processing...."""
    def __init__((
        self,
    )):
        """ Constructor for the AudioStretch class...."""
    def open((
        self,
        path: str | Path | None = None,
        file: BinaryIO | None = None,
        format: str | None = None,
    )):
        """ Open an audio file using Pedalboard...."""
    def save((
        self,
        path: str | Path | None = None,
        file: BinaryIO | None = None,
        format: str | None = None,
    )):
        """ Save the audio file using Pedalboard...."""
    def resample((self, target_framerate: int)):
        """ Resample the audio using Pedalboard...."""
    def stretch((
        self,
        ratio: float = 1.0,
        gap_ratio: float = 0.0,
        upper_freq: int = 333,
        lower_freq: int = 55,
        buffer_ms: float = 25,
        threshold_gap_db: float = -40,
        double_range: bool = False,
        fast_detection: bool = False,
        normal_detection: bool = False,
    )):
        """ Stretch the audio using the TDHS C library...."""

def __init__((
        self,
    )):
    """ Constructor for the AudioStretch class...."""

def open((
        self,
        path: str | Path | None = None,
        file: BinaryIO | None = None,
        format: str | None = None,
    )):
    """ Open an audio file using Pedalboard...."""

def save((
        self,
        path: str | Path | None = None,
        file: BinaryIO | None = None,
        format: str | None = None,
    )):
    """ Save the audio file using Pedalboard...."""

def resample((self, target_framerate: int)):
    """ Resample the audio using Pedalboard...."""

def stretch((
        self,
        ratio: float = 1.0,
        gap_ratio: float = 0.0,
        upper_freq: int = 333,
        lower_freq: int = 55,
        buffer_ms: float = 25,
        threshold_gap_db: float = -40,
        double_range: bool = False,
        fast_detection: bool = False,
        normal_detection: bool = False,
    )):
    """ Stretch the audio using the TDHS C library...."""

def stretch_audio((
    input_path: str,
    output_path: str,
    ratio: float = 1.0,
    gap_ratio: float = 0.0,
    upper_freq: int = 333,
    lower_freq: int = 55,
    buffer_ms: float = 25,  # Currently not used effectively by Python stretch method
    threshold_gap_db: float = -40,  # Currently not used effectively
    double_range: bool = False,
    fast_detection: bool = False,
    normal_detection: bool = False,  # Currently not used effectively
    sample_rate: int = 0,
)):
    """ Stretches the input audio file using TDHS C library and saves the result...."""


<document index="37">
<source>src_docs/md/01-installation.md</source>
<document_content>
---
# this_file: src_docs/md/01-installation.md
title: Installation
description: How to install AudioStretchy and its dependencies
---

# Installation

AudioStretchy can be installed in multiple ways depending on your needs. The package includes pre-compiled C extensions for cross-platform compatibility.

## Standard Installation

### Requirements

- Python 3.8 or higher
- pip package manager

### Quick Install

The simplest way to install AudioStretchy is via pip:

```bash
pip install audiostretchy
```

or with Python 3 explicitly:

```bash
python3 -m pip install audiostretchy
```

This installs AudioStretchy along with its core dependencies:

- **numpy** - For numerical operations
- **pedalboard** - For audio I/O and format support  
- **fire** - For the command-line interface

### Pre-compiled Wheels

AudioStretchy provides pre-compiled wheels for:

- **Windows** (x86_64)
- **macOS** (x86_64, ARM64)  
- **Linux** (x86_64)

These wheels include the compiled C extension, so no additional compilation is needed.

## FFmpeg Dependencies

For maximum audio format support, AudioStretchy relies on FFmpeg through the Pedalboard library.

!!! note "Format Support"
    Without FFmpeg, you'll be limited to basic formats like WAV. For MP3, M4A, OGG, and other compressed formats, FFmpeg is required.

### Installing FFmpeg

=== "macOS"

    Using Homebrew:
    ```bash
    brew install ffmpeg
    ```

=== "Ubuntu/Debian"

    Using apt:
    ```bash
    sudo apt-get update
    sudo apt-get install ffmpeg
    ```

=== "Windows"

    1. Download FFmpeg from [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)
    2. Extract the archive
    3. Add the `bin` directory to your system PATH

=== "Other Linux"

    Use your distribution's package manager:
    
    **CentOS/RHEL/Fedora:**
    ```bash
    sudo dnf install ffmpeg
    # or for older versions
    sudo yum install ffmpeg
    ```
    
    **Arch Linux:**
    ```bash
    sudo pacman -S ffmpeg
    ```

### Verifying FFmpeg Installation

Test FFmpeg installation:

```bash
ffmpeg -version
```

You should see version information if FFmpeg is properly installed.

## Development Installation

For contributing to AudioStretchy or working with the latest development version:

### Prerequisites

- Git
- Python 3.8+
- C compiler (GCC/Clang on Unix, MSVC on Windows)

### Clone and Install

```bash
# Clone the repository
git clone https://github.com/twardoch/audiostretchy.git
cd audiostretchy

# Initialize submodules (includes C library source)
git submodule update --init --recursive

# Create virtual environment (recommended)
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in editable mode with development dependencies
pip install -e .[testing]
```

### Development Dependencies

The `[testing]` extra includes:

- **pytest** - Testing framework
- **pytest-cov** - Coverage reporting
- **black** - Code formatting
- **isort** - Import sorting
- **flake8** - Linting
- **pre-commit** - Git hooks

### Setting Up Pre-commit Hooks

```bash
pre-commit install
```

This ensures code quality checks run before each commit.

## Compiling C Extensions

If you modify the C library source in `vendors/stretch/`, you'll need to recompile:

### Prerequisites

=== "Linux"

    ```bash
    sudo apt-get install build-essential
    ```

=== "macOS"

    ```bash
    xcode-select --install
    ```

=== "Windows"

    Install Visual Studio Build Tools or Visual Studio Community with C++ support.

### Manual Compilation

The C library needs to be compiled into platform-specific shared libraries:

- **Linux**: `_stretch.so`
- **macOS**: `_stretch.dylib`  
- **Windows**: `_stretch.dll`

Place compiled libraries in the appropriate directories under `src/audiostretchy/interface/`.

!!! tip "CI Automation"
    The GitHub Actions workflow automatically handles compilation for official releases. See `.github/workflows/ci.yaml` for details.

## Virtual Environments

It's recommended to use virtual environments to avoid dependency conflicts:

### Using venv

```bash
python3 -m venv audiostretchy-env
source audiostretchy-env/bin/activate  # On Windows: audiostretchy-env\Scripts\activate
pip install audiostretchy
```

### Using conda

```bash
conda create -n audiostretchy python=3.11
conda activate audiostretchy
pip install audiostretchy
```

## Troubleshooting

### Common Issues

**Import errors after installation:**

```bash
python -c "import audiostretchy; print('Installation successful!')"
```

**Missing C extension:**

```
ImportError: cannot import name '_stretch' from 'audiostretchy.interface'
```

This usually means the C extension didn't compile properly. Try reinstalling or check platform compatibility.

**FFmpeg-related errors:**

```
RuntimeError: Could not open file for reading
```

Install FFmpeg as described above, or use WAV files which don't require FFmpeg.

**Permission errors on Windows:**

Run Command Prompt or PowerShell as Administrator.

### Platform-Specific Notes

=== "Apple Silicon (M1/M2)"

    AudioStretchy includes native ARM64 wheels for Apple Silicon Macs. No additional setup needed.

=== "Windows"

    Ensure you have the latest Visual C++ Redistributable installed if you encounter DLL errors.

=== "Linux"

    Most modern Linux distributions are supported. For older distributions, you may need to compile from source.

## Verification

Test your installation:

```bash
# Test CLI
audiostretchy --help

# Test Python import
python -c "from audiostretchy.stretch import stretch_audio; print('Success!')"

# Test with sample file (if you have audio files)
audiostretchy input.wav output.wav --ratio 1.1
```

Next: [Quick Start Guide](02-quick-start.md)
</document_content>
</document>

<document index="38">
<source>src_docs/md/02-quick-start.md</source>
<document_content>
---
# this_file: src_docs/md/02-quick-start.md
title: Quick Start
description: Basic usage examples to get you up and running
---

# Quick Start

Get up and running with AudioStretchy in minutes. This guide covers the most common use cases with practical examples.

## Basic Concepts

Before diving in, understand these key concepts:

- **Stretch Ratio**: Controls time-stretching (>1.0 = slower, <1.0 = faster)
- **Pitch Preservation**: Duration changes without affecting pitch
- **TDHS Algorithm**: Time-Domain Harmonic Scaling for natural sound

## Command Line Usage

### Simple Time Stretching

Make audio 20% slower (ratio = 1.2):

```bash
audiostretchy input.mp3 output.wav --ratio 1.2
```

Make audio 25% faster (ratio = 0.75):

```bash
audiostretchy speech.wav faster.wav --ratio 0.75
```

### Common Parameters

Add sample rate conversion:

```bash
audiostretchy music.flac output.wav --ratio 1.1 --sample_rate 44100
```

Optimize for speech with frequency limits:

```bash
audiostretchy podcast.mp3 stretched.wav --ratio 1.3 --upper_freq 300 --lower_freq 80
```

Enable fast mode for quicker processing:

```bash
audiostretchy large_file.wav output.wav --ratio 0.9 --fast_detection true
```

## Python API Usage

### Quick Function Call

The simplest approach using the `stretch_audio` function:

```python
from audiostretchy.stretch import stretch_audio

# Basic stretching
stretch_audio("input.mp3", "output.wav", ratio=1.2)

# With additional parameters
stretch_audio(
    input_path="speech.flac",
    output_path="slower_speech.wav", 
    ratio=1.4,
    sample_rate=22050,
    upper_freq=300
)
```

### Using the AudioStretch Class

For more control and advanced workflows:

```python
from audiostretchy.stretch import AudioStretch

# Initialize processor
processor = AudioStretch()

# Open input file
processor.open("input.mp3")

# Apply stretching
processor.stretch(ratio=1.1, upper_freq=350, lower_freq=60)

# Optional: resample
processor.resample(target_framerate=48000)

# Save result
processor.save("output.wav")
```

### Multiple Processing Steps

Process the same audio with different parameters:

```python
processor = AudioStretch()
processor.open("original.wav")

# Create slow version
processor.stretch(ratio=1.5)
processor.save("slow_version.wav")

# Reset and create fast version
processor.open("original.wav")  # Reload original
processor.stretch(ratio=0.7)
processor.save("fast_version.wav")
```

## Common Use Cases

### 1. Podcast Speed Adjustment

Speed up podcasts for faster listening:

```bash
# 1.25x speed (25% faster)
audiostretchy podcast.mp3 faster_podcast.mp3 --ratio 0.8
```

```python
stretch_audio("podcast.mp3", "faster_podcast.mp3", ratio=0.8)
```

### 2. Music Practice

Slow down music for practice:

```bash
# Make song 30% slower for learning
audiostretchy song.mp3 practice_version.wav --ratio 1.3
```

```python
stretch_audio("song.mp3", "practice_version.wav", ratio=1.3)
```

### 3. Voice Analysis

Stretch speech for detailed analysis:

```bash
# Slow down speech with speech-optimized settings
audiostretchy speech.wav analysis.wav --ratio 1.5 --upper_freq 300 --lower_freq 80
```

```python
stretch_audio(
    "speech.wav", 
    "analysis.wav", 
    ratio=1.5,
    upper_freq=300,
    lower_freq=80
)
```

### 4. Batch Processing

Process multiple files:

```python
import os
from audiostretchy.stretch import stretch_audio

input_dir = "input_files"
output_dir = "output_files"
ratio = 1.2

for filename in os.listdir(input_dir):
    if filename.endswith(('.mp3', '.wav', '.flac')):
        input_path = os.path.join(input_dir, filename)
        output_path = os.path.join(output_dir, f"stretched_{filename}")
        
        stretch_audio(input_path, output_path, ratio=ratio)
        print(f"Processed: {filename}")
```

## Working with Different Formats

AudioStretchy supports many audio formats via Pedalboard:

### Input Formats

- **Uncompressed**: WAV, AIFF
- **Compressed**: MP3, FLAC, OGG, M4A
- **Professional**: BWF, RF64

### Output Format Selection

Format is determined by file extension:

```python
# Different output formats
processor.save("output.wav")    # WAV
processor.save("output.mp3")    # MP3  
processor.save("output.flac")   # FLAC
processor.save("output.ogg")    # OGG
```

### Format Conversion with Stretching

Combine format conversion with stretching:

```bash
# Convert MP3 to WAV while stretching
audiostretchy input.mp3 output.wav --ratio 1.1

# Convert to FLAC with resampling
audiostretchy input.wav output.flac --ratio 0.9 --sample_rate 48000
```

## Memory-Efficient Processing

For large files, AudioStretchy handles memory efficiently:

```python
# Large file processing
processor = AudioStretch()
processor.open("large_file.wav")
processor.stretch(ratio=1.2)
processor.save("stretched_large.wav")
# Memory is managed automatically
```

## Error Handling

Handle common issues gracefully:

```python
from audiostretchy.stretch import stretch_audio

try:
    stretch_audio("input.mp3", "output.wav", ratio=1.2)
    print("Success!")
except FileNotFoundError:
    print("Input file not found")
except Exception as e:
    print(f"Processing error: {e}")
```

## Performance Tips

### 1. Choose Appropriate Ratios

- **Normal range**: 0.5 - 2.0 (default)
- **Extended range**: 0.25 - 4.0 (use `--double_range true`)

### 2. Optimize for Content Type

**For speech:**
```bash
audiostretchy speech.wav output.wav --ratio 1.2 --upper_freq 300 --lower_freq 80
```

**For music:**
```bash
audiostretchy music.wav output.wav --ratio 1.1 --upper_freq 400 --lower_freq 50
```

### 3. Use Fast Mode for Quick Tests

```bash
audiostretchy test.wav output.wav --ratio 1.1 --fast_detection true
```

## Next Steps

Now that you're familiar with basic usage:

- **CLI Users**: See [Command Line Interface](03-cli-usage.md) for complete parameter reference
- **Python Developers**: Check [Python API](04-python-api.md) for advanced programming techniques  
- **Curious about internals**: Read [How It Works](05-how-it-works.md) to understand the TDHS algorithm

## Quick Reference

### Common Ratios

| Ratio | Effect | Use Case |
|-------|--------|----------|
| 0.5   | 2x faster | Quick review |
| 0.75  | 25% faster | Faster listening |
| 0.8   | 20% faster | Podcast speedup |
| 1.0   | No change | Testing/baseline |
| 1.2   | 20% slower | Learning audio |
| 1.5   | 50% slower | Detailed analysis |
| 2.0   | 2x slower | Transcription |

### File Extension Mapping

| Extension | Format | Quality | Use Case |
|-----------|--------|---------|----------|
| `.wav`    | WAV | Lossless | Professional |
| `.flac`   | FLAC | Lossless | Archival |
| `.mp3`    | MP3 | Lossy | General use |
| `.ogg`    | OGG | Lossy | Open source |
| `.m4a`    | AAC | Lossy | Apple ecosystem |
</document_content>
</document>

<document index="39">
<source>src_docs/md/03-cli-usage.md</source>
<document_content>
---
# this_file: src_docs/md/03-cli-usage.md
title: Command Line Interface
description: Complete CLI reference with examples
---

# Command Line Interface

The AudioStretchy CLI provides a powerful command-line interface for audio time-stretching. This guide covers all available options and practical usage examples.

## Basic Syntax

```bash
audiostretchy INPUT_FILE OUTPUT_FILE [OPTIONS]
```

### Required Arguments

- **`INPUT_FILE`**: Path to the input audio file
- **`OUTPUT_FILE`**: Path where the processed audio will be saved

### Simple Example

```bash
audiostretchy input.mp3 output.wav --ratio 1.2
```

## Core Parameters

### Stretch Ratio

The most important parameter controlling time-stretching behavior.

```bash
--ratio FLOAT, -r FLOAT
```

- **Default**: `1.0` (no change)
- **Range**: `0.5 - 2.0` (normal), `0.25 - 4.0` (with `--double_range`)
- **> 1.0**: Slower playback (longer duration)
- **< 1.0**: Faster playback (shorter duration)

!!! example "Ratio Examples"
    ```bash
    # 20% slower
    audiostretchy input.wav output.wav --ratio 1.2
    
    # 25% faster  
    audiostretchy input.wav output.wav --ratio 0.75
    
    # Double speed (2x faster)
    audiostretchy input.wav output.wav --ratio 0.5
    ```

### Gap Ratio

Separate stretching ratio for silence/gaps in audio.

```bash
--gap_ratio FLOAT, -g FLOAT
```

- **Default**: `0.0` (uses main ratio for gaps)
- **Usage**: Set different ratio for silent portions

!!! note "Gap Ratio Limitation"
    Current Python implementation doesn't pre-segment audio. The C library may use this parameter internally, but effectiveness depends on the library's silence detection.

```bash
# Different gap handling
audiostretchy speech.wav output.wav --ratio 1.3 --gap_ratio 1.0
```

## Frequency Detection Parameters

Control how the algorithm detects audio periods and fundamental frequencies.

### Upper Frequency Limit

```bash
--upper_freq INT, -u INT
```

- **Default**: `333` Hz
- **Range**: Typically `200-500` Hz
- **Purpose**: Upper limit for period detection

### Lower Frequency Limit

```bash
--lower_freq INT, -l INT
```

- **Default**: `55` Hz  
- **Range**: Typically `50-100` Hz
- **Purpose**: Lower limit for period detection

!!! tip "Frequency Optimization"
    - **Speech**: `--upper_freq 300 --lower_freq 80`
    - **Music**: `--upper_freq 400 --lower_freq 50`
    - **Bass-heavy**: `--lower_freq 30`

```bash
# Optimize for speech
audiostretchy speech.wav output.wav --ratio 1.2 --upper_freq 300 --lower_freq 80

# Optimize for music with wide frequency range
audiostretchy music.wav output.wav --ratio 1.1 --upper_freq 450 --lower_freq 40
```

## Advanced Algorithm Options

### Double Range Mode

```bash
--double_range BOOL, -d BOOL
```

- **Default**: `False`
- **Effect**: Extends ratio range to `0.25-4.0` instead of `0.5-2.0`
- **Values**: `True` or `False`

```bash
# Enable extreme stretching
audiostretchy input.wav output.wav --ratio 0.3 --double_range True
```

### Fast Detection

```bash
--fast_detection BOOL, -f BOOL
```

- **Default**: `False`
- **Effect**: Faster but potentially lower quality processing
- **Trade-off**: Speed vs. quality

```bash
# Quick processing for tests
audiostretchy large_file.wav test_output.wav --ratio 1.1 --fast_detection True
```

### Normal Detection

```bash
--normal_detection BOOL, -n BOOL
```

- **Default**: `False`
- **Effect**: Forces normal detection method
- **Usage**: Override automatic detection selection

```bash
# Force high-quality detection
audiostretchy input.wav output.wav --ratio 1.2 --normal_detection True
```

## Audio Processing Options

### Sample Rate

```bash
--sample_rate INT, -s INT
```

- **Default**: `0` (preserve original)
- **Effect**: Resamples output to specified rate
- **Common rates**: `22050`, `44100`, `48000`, `96000`

```bash
# Resample to CD quality
audiostretchy input.wav output.wav --ratio 1.1 --sample_rate 44100

# Upsample to professional rate
audiostretchy input.wav output.wav --ratio 1.0 --sample_rate 96000
```

## Advanced Parameters

### Buffer Size

```bash
--buffer_ms FLOAT, -b FLOAT
```

- **Default**: `25` ms
- **Purpose**: Buffer size for internal processing
- **Impact**: Affects memory usage and processing behavior

### Threshold Gap Detection

```bash
--threshold_gap_db FLOAT, -t FLOAT
```

- **Default**: `-40` dB
- **Purpose**: Silence detection threshold
- **Usage**: Lower values detect more silence

```bash
# Sensitive gap detection
audiostretchy speech.wav output.wav --ratio 1.2 --threshold_gap_db -35

# Less sensitive (quieter sounds treated as non-silence)
audiostretchy noisy_audio.wav output.wav --ratio 1.1 --threshold_gap_db -50
```

## Practical Examples

### Podcast Processing

Speed up podcast for faster listening:

```bash
# Standard speedup
audiostretchy podcast.mp3 faster_podcast.mp3 --ratio 0.8

# Aggressive speedup with speech optimization
audiostretchy podcast.mp3 very_fast.mp3 --ratio 0.7 --upper_freq 300 --fast_detection True
```

### Music Practice

Slow down music for learning:

```bash
# Guitar practice version
audiostretchy song.mp3 practice.wav --ratio 1.4 --upper_freq 400

# Very slow for difficult passages
audiostretchy complex_piece.wav super_slow.wav --ratio 2.0 --double_range True
```

### Voice Analysis

Detailed speech analysis:

```bash
# Slow, high-quality speech analysis
audiostretchy speech.wav analysis.wav --ratio 1.6 --upper_freq 350 --lower_freq 75 --normal_detection True
```

### Format Conversion

Combine stretching with format conversion:

```bash
# MP3 to WAV with slight speedup
audiostretchy input.mp3 output.wav --ratio 0.95 --sample_rate 44100

# Multi-format workflow
audiostretchy source.flac intermediate.wav --ratio 1.1
audiostretchy intermediate.wav final.mp3 --ratio 1.0 --sample_rate 48000
```

## Batch Processing Scripts

### Bash Script Example

```bash
#!/bin/bash
# Process all MP3 files in a directory

RATIO=1.2
INPUT_DIR="./input"
OUTPUT_DIR="./output"

mkdir -p "$OUTPUT_DIR"

for file in "$INPUT_DIR"/*.mp3; do
    filename=$(basename "$file" .mp3)
    audiostretchy "$file" "$OUTPUT_DIR/${filename}_stretched.wav" --ratio $RATIO
    echo "Processed: $filename"
done
```

### PowerShell Script Example

```powershell
# PowerShell batch processing
$ratio = 1.2
$inputDir = ".\input"
$outputDir = ".\output"

New-Item -ItemType Directory -Force -Path $outputDir

Get-ChildItem -Path $inputDir -Filter "*.mp3" | ForEach-Object {
    $outputFile = Join-Path $outputDir ($_.BaseName + "_stretched.wav")
    audiostretchy $_.FullName $outputFile --ratio $ratio
    Write-Host "Processed: $($_.Name)"
}
```

## Error Handling and Troubleshooting

### Common Error Messages

**File not found:**
```
Error: Could not open input file
```
Check file path and permissions.

**Unsupported format:**
```
Error: Could not determine file format
```
Ensure FFmpeg is installed for compressed formats.

**Invalid ratio:**
```
Error: Ratio out of range
```
Use `--double_range True` for extreme ratios.

### Debugging Tips

1. **Test with WAV files** first (no FFmpeg dependency)
2. **Start with default parameters** before customizing
3. **Use `--fast_detection True`** for quick tests
4. **Check file permissions** for both input and output

### Verbose Output

For debugging, you can capture detailed information:

```bash
# Redirect output for logging
audiostretchy input.wav output.wav --ratio 1.2 2>&1 | tee process.log
```

## Performance Considerations

### File Size vs. Processing Time

| Input Size | Typical Processing Time | Memory Usage |
|------------|------------------------|--------------|
| < 1 MB | < 1 second | Low |
| 1-10 MB | 1-10 seconds | Moderate |
| 10-100 MB | 10-60 seconds | Moderate |
| > 100 MB | 1+ minutes | Higher |

### Optimization Tips

1. **Use `--fast_detection True`** for large files during testing
2. **Process in batches** rather than individually for many files
3. **Choose appropriate output formats** (WAV for quality, MP3 for size)
4. **Consider sample rate** (lower rates process faster)

## Integration with Other Tools

### FFmpeg Pipeline

```bash
# Extract audio, stretch, then encode
ffmpeg -i video.mp4 -vn audio.wav
audiostretchy audio.wav stretched.wav --ratio 1.2
ffmpeg -i stretched.wav -i video.mp4 -c:v copy -map 1:v -map 0:a output.mp4
```

### SoX Integration

```bash
# Apply additional effects after stretching
audiostretchy input.wav stretched.wav --ratio 1.1
sox stretched.wav final.wav norm reverb
```

## Next Steps

- **Python Integration**: Learn [Python API](04-python-api.md) for programmatic control
- **Understanding Internals**: Read [How It Works](05-how-it-works.md)
- **Parameter Tuning**: Check [Parameters Reference](07-parameters-reference.md) for detailed explanations
</document_content>
</document>

<document index="40">
<source>src_docs/md/04-python-api.md</source>
<document_content>
---
# this_file: src_docs/md/04-python-api.md
title: Python API
description: Programming interface for Python applications
---

# Python API

AudioStretchy provides a comprehensive Python API for integrating time-stretching capabilities into your applications. This guide covers both simple function calls and advanced class-based usage.

## Quick Function Interface

### Basic Usage

The `stretch_audio` function provides the simplest way to process audio files:

```python
from audiostretchy.stretch import stretch_audio

# Basic stretching
stretch_audio("input.mp3", "output.wav", ratio=1.2)
```

### Function Signature

```python
def stretch_audio(
    input_path: str,
    output_path: str,
    ratio: float = 1.0,
    gap_ratio: float = 0.0,
    upper_freq: int = 333,
    lower_freq: int = 55,
    buffer_ms: float = 25.0,
    threshold_gap_db: float = -40.0,
    double_range: bool = False,
    fast_detection: bool = False,
    normal_detection: bool = False,
    sample_rate: int = 0
) -> None
```

### Parameter Examples

```python
# Speech optimization
stretch_audio(
    "speech.wav", 
    "slow_speech.wav",
    ratio=1.3,
    upper_freq=300,
    lower_freq=80
)

# Music with high quality
stretch_audio(
    "song.flac",
    "practice.wav", 
    ratio=1.5,
    upper_freq=400,
    lower_freq=50,
    normal_detection=True
)

# Fast processing
stretch_audio(
    "podcast.mp3",
    "faster.mp3",
    ratio=0.8,
    fast_detection=True
)
```

## AudioStretch Class

For advanced control and multiple operations, use the `AudioStretch` class:

### Basic Class Usage

```python
from audiostretchy.stretch import AudioStretch

# Initialize processor
processor = AudioStretch()

# Open, process, save
processor.open("input.mp3")
processor.stretch(ratio=1.2)
processor.save("output.wav")
```

### Class Methods Overview

| Method | Purpose | Returns |
|--------|---------|---------|
| `open()` | Load audio file | None |
| `stretch()` | Apply time-stretching | None |
| `resample()` | Change sample rate | None |
| `save()` | Export processed audio | None |

### Advanced Class Usage

```python
processor = AudioStretch()

# Load file
processor.open("complex_audio.flac")

# Multiple processing steps
processor.stretch(
    ratio=1.1,
    upper_freq=350,
    lower_freq=60,
    double_range=True
)

# Optional resampling
processor.resample(target_framerate=48000)

# Save with explicit format
processor.save("processed.wav")
```

## File I/O Operations

### Opening Files

```python
# Simple file opening
processor.open("audio.mp3")

# With format specification (rare cases)
processor.open("audio_file", format="wav")
```

### Supported Input Formats

AudioStretchy supports numerous formats via Pedalboard:

- **Lossless**: WAV, FLAC, AIFF, BWF
- **Lossy**: MP3, OGG, M4A, AAC
- **Professional**: RF64, CAF

### Saving Files

```python
# Format determined by extension
processor.save("output.wav")    # WAV format
processor.save("output.mp3")    # MP3 format
processor.save("output.flac")   # FLAC format

# Explicit format specification
processor.save("output_file", format="ogg")
```

## Memory-Efficient Processing

### Working with BytesIO

For in-memory processing without file I/O:

```python
from io import BytesIO
from audiostretchy.stretch import AudioStretch

# Read audio data into memory
with open("input.mp3", "rb") as f:
    input_data = f.read()

# Process in memory
input_bio = BytesIO(input_data)
output_bio = BytesIO()

processor = AudioStretch()
processor.open(file=input_bio, format="mp3")
processor.stretch(ratio=1.2)
processor.save(file=output_bio, format="wav")

# Get processed data
processed_data = output_bio.getvalue()

# Save to file
with open("output.wav", "wb") as f:
    f.write(processed_data)
```

### Streaming Workflow

For large files or streaming applications:

```python
def process_audio_stream(input_stream, output_stream, ratio=1.0):
    """Process audio from input stream to output stream"""
    
    processor = AudioStretch()
    
    # Load from stream
    processor.open(file=input_stream, format="wav")
    
    # Process
    processor.stretch(ratio=ratio)
    
    # Save to stream
    processor.save(file=output_stream, format="wav")
    
    return output_stream
```

## Error Handling

### Common Exceptions

```python
from audiostretchy.stretch import stretch_audio

try:
    stretch_audio("input.mp3", "output.wav", ratio=1.2)
except FileNotFoundError:
    print("Input file not found")
except ValueError as e:
    print(f"Invalid parameter: {e}")
except RuntimeError as e:
    print(f"Processing error: {e}")
except Exception as e:
    print(f"Unexpected error: {e}")
```

### Robust Error Handling

```python
import os
from pathlib import Path
from audiostretchy.stretch import AudioStretch

def safe_audio_stretch(input_path, output_path, **kwargs):
    """Safely stretch audio with comprehensive error handling"""
    
    # Validate input
    if not Path(input_path).exists():
        raise FileNotFoundError(f"Input file not found: {input_path}")
    
    # Ensure output directory exists
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)
    
    processor = AudioStretch()
    
    try:
        # Process audio
        processor.open(input_path)
        processor.stretch(**kwargs)
        processor.save(output_path)
        
        return True
        
    except Exception as e:
        # Clean up partial output
        if Path(output_path).exists():
            Path(output_path).unlink()
        raise RuntimeError(f"Processing failed: {e}")

# Usage
try:
    safe_audio_stretch("input.mp3", "output.wav", ratio=1.2)
    print("Success!")
except Exception as e:
    print(f"Error: {e}")
```

## Batch Processing

### Simple Batch Processing

```python
import os
from pathlib import Path
from audiostretchy.stretch import stretch_audio

def batch_stretch(input_dir, output_dir, ratio=1.0, **kwargs):
    """Process all audio files in a directory"""
    
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Supported extensions
    audio_extensions = {'.mp3', '.wav', '.flac', '.ogg', '.m4a'}
    
    for file_path in input_path.iterdir():
        if file_path.suffix.lower() in audio_extensions:
            output_file = output_path / f"{file_path.stem}_stretched{file_path.suffix}"
            
            try:
                stretch_audio(str(file_path), str(output_file), ratio=ratio, **kwargs)
                print(f"âœ“ Processed: {file_path.name}")
            except Exception as e:
                print(f"âœ— Failed: {file_path.name} - {e}")

# Usage
batch_stretch("input_files", "output_files", ratio=1.2, upper_freq=300)
```

### Advanced Batch Processing

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import time

def process_single_file(file_info):
    """Process a single file with error handling"""
    input_file, output_file, params = file_info
    
    try:
        start_time = time.time()
        stretch_audio(str(input_file), str(output_file), **params)
        duration = time.time() - start_time
        
        return {
            'file': input_file.name,
            'status': 'success',
            'duration': duration
        }
    except Exception as e:
        return {
            'file': input_file.name,
            'status': 'error',
            'error': str(e)
        }

def parallel_batch_stretch(input_dir, output_dir, ratio=1.0, max_workers=4, **kwargs):
    """Process files in parallel for better performance"""
    
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Prepare file list
    audio_files = []
    audio_extensions = {'.mp3', '.wav', '.flac', '.ogg', '.m4a'}
    
    for file_path in input_path.iterdir():
        if file_path.suffix.lower() in audio_extensions:
            output_file = output_path / f"{file_path.stem}_stretched{file_path.suffix}"
            params = {'ratio': ratio, **kwargs}
            audio_files.append((file_path, output_file, params))
    
    # Process in parallel
    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_file = {executor.submit(process_single_file, file_info): file_info[0] 
                         for file_info in audio_files}
        
        for future in as_completed(future_to_file):
            result = future.result()
            results.append(result)
            
            status_icon = "âœ“" if result['status'] == 'success' else "âœ—"
            if result['status'] == 'success':
                print(f"{status_icon} {result['file']} ({result['duration']:.1f}s)")
            else:
                print(f"{status_icon} {result['file']} - {result['error']}")
    
    return results

# Usage
results = parallel_batch_stretch(
    "input_files", 
    "output_files", 
    ratio=1.2, 
    max_workers=2,
    upper_freq=300
)

# Summary
successful = sum(1 for r in results if r['status'] == 'success')
print(f"\nProcessed {successful}/{len(results)} files successfully")
```

## Integration Patterns

### Flask Web Application

```python
from flask import Flask, request, send_file
from werkzeug.utils import secure_filename
import tempfile
import os

app = Flask(__name__)

@app.route('/stretch', methods=['POST'])
def stretch_audio_endpoint():
    """Web endpoint for audio stretching"""
    
    if 'audio' not in request.files:
        return {'error': 'No audio file provided'}, 400
    
    file = request.files['audio']
    ratio = float(request.form.get('ratio', 1.0))
    
    if file.filename == '':
        return {'error': 'No file selected'}, 400
    
    # Secure file handling
    filename = secure_filename(file.filename)
    
    with tempfile.TemporaryDirectory() as temp_dir:
        input_path = os.path.join(temp_dir, filename)
        output_path = os.path.join(temp_dir, f"stretched_{filename}")
        
        # Save uploaded file
        file.save(input_path)
        
        try:
            # Process audio
            stretch_audio(input_path, output_path, ratio=ratio)
            
            # Return processed file
            return send_file(output_path, as_attachment=True)
            
        except Exception as e:
            return {'error': str(e)}, 500

if __name__ == '__main__':
    app.run(debug=True)
```

### Django Integration

```python
from django.http import HttpResponse, JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.core.files.storage import default_storage
import tempfile
import json

@csrf_exempt
def stretch_audio_view(request):
    """Django view for audio stretching"""
    
    if request.method != 'POST':
        return JsonResponse({'error': 'POST required'}, status=405)
    
    if 'audio' not in request.FILES:
        return JsonResponse({'error': 'No audio file'}, status=400)
    
    audio_file = request.FILES['audio']
    params = json.loads(request.POST.get('params', '{}'))
    
    with tempfile.TemporaryDirectory() as temp_dir:
        # Save uploaded file
        input_path = os.path.join(temp_dir, audio_file.name)
        with open(input_path, 'wb') as f:
            for chunk in audio_file.chunks():
                f.write(chunk)
        
        # Process
        output_path = os.path.join(temp_dir, f"stretched_{audio_file.name}")
        
        try:
            stretch_audio(input_path, output_path, **params)
            
            # Return file
            with open(output_path, 'rb') as f:
                response = HttpResponse(f.read(), content_type='audio/wav')
                response['Content-Disposition'] = f'attachment; filename="stretched_{audio_file.name}"'
                return response
                
        except Exception as e:
            return JsonResponse({'error': str(e)}, status=500)
```

### CLI Wrapper

```python
import argparse
import sys
from pathlib import Path
from audiostretchy.stretch import stretch_audio

def create_cli():
    """Create a custom CLI wrapper"""
    
    parser = argparse.ArgumentParser(description='Custom AudioStretchy CLI')
    parser.add_argument('input', help='Input audio file')
    parser.add_argument('output', help='Output audio file')
    parser.add_argument('--ratio', type=float, default=1.0, help='Stretch ratio')
    parser.add_argument('--preset', choices=['speech', 'music', 'fast'], 
                       help='Parameter presets')
    
    return parser

def get_preset_params(preset):
    """Get predefined parameter sets"""
    presets = {
        'speech': {
            'upper_freq': 300,
            'lower_freq': 80,
            'normal_detection': True
        },
        'music': {
            'upper_freq': 400,
            'lower_freq': 50,
            'normal_detection': True
        },
        'fast': {
            'fast_detection': True
        }
    }
    return presets.get(preset, {})

def main():
    parser = create_cli()
    args = parser.parse_args()
    
    # Validate files
    if not Path(args.input).exists():
        print(f"Error: Input file '{args.input}' not found", file=sys.stderr)
        sys.exit(1)
    
    # Get parameters
    params = {'ratio': args.ratio}
    if args.preset:
        params.update(get_preset_params(args.preset))
    
    # Process
    try:
        stretch_audio(args.input, args.output, **params)
        print(f"Successfully processed: {args.input} -> {args.output}")
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == '__main__':
    main()
```

## Performance Optimization

### Memory Management

```python
import gc
from audiostretchy.stretch import AudioStretch

def memory_efficient_processing(files, ratio=1.0):
    """Process files with explicit memory management"""
    
    for input_file, output_file in files:
        processor = AudioStretch()
        
        try:
            processor.open(input_file)
            processor.stretch(ratio=ratio)
            processor.save(output_file)
        finally:
            # Explicit cleanup
            del processor
            gc.collect()
```

### Processing Time Estimation

```python
import time
from pathlib import Path

def estimate_processing_time(file_path, ratio=1.0):
    """Estimate processing time based on file size"""
    
    file_size_mb = Path(file_path).stat().st_size / (1024 * 1024)
    
    # Rough estimates (adjust based on your system)
    base_time = file_size_mb * 0.1  # seconds per MB
    ratio_factor = abs(ratio - 1.0) * 2 + 1  # ratio complexity
    
    estimated_time = base_time * ratio_factor
    
    return estimated_time

# Usage
estimated = estimate_processing_time("large_file.wav", ratio=1.5)
print(f"Estimated processing time: {estimated:.1f} seconds")
```

## Next Steps

- **Advanced Parameters**: Learn about [Parameters Reference](07-parameters-reference.md)
- **Algorithm Details**: Understand [How It Works](05-how-it-works.md)
- **Core Architecture**: Explore [Core Architecture](06-core-architecture.md)
</document_content>
</document>

<document index="41">
<source>src_docs/md/05-how-it-works.md</source>
<document_content>
---
# this_file: src_docs/md/05-how-it-works.md
title: How It Works
description: Understanding the TDHS algorithm and processing pipeline
---

# How It Works

AudioStretchy uses sophisticated signal processing techniques to change audio duration while preserving pitch. This guide explains the underlying algorithms and processing pipeline.

## Overview

Audio time-stretching without pitch changes is a complex problem in digital signal processing. AudioStretchy solves this using the **Time-Domain Harmonic Scaling (TDHS)** algorithm, which operates directly on audio waveforms to intelligently modify their timing structure.

## The Challenge

### Simple Speed Change Problems

Naive approaches to changing audio speed have significant limitations:

- **Playback rate changes**: Altering playback speed changes both duration and pitch (like playing a record at wrong speed)
- **Sample dropping/repeating**: Simple sample manipulation creates audible artifacts
- **Linear interpolation**: Basic stretching creates distortion and loses harmonic content

### What We Need

Ideal time-stretching should:

1. **Preserve pitch**: Fundamental frequencies remain unchanged
2. **Maintain timbre**: Harmonic content and formants stay intact
3. **Avoid artifacts**: No clicking, distortion, or robotic sounds
4. **Handle various content**: Work well with speech, music, and mixed audio

## Time-Domain Harmonic Scaling (TDHS)

### Algorithm Principles

TDHS operates on these key insights:

1. **Harmonic Structure**: Audio signals contain repeating patterns related to pitch
2. **Time-Domain Analysis**: Working directly with waveform samples avoids frequency-domain artifacts
3. **Intelligent Segmentation**: Audio is divided into meaningful periods for processing
4. **Selective Modification**: Only timing is altered, harmonic relationships are preserved

### Processing Steps

```mermaid
graph TD
    A[Input Audio] --> B[Period Detection]
    B --> C[Segment Identification]
    C --> D[Harmonic Analysis]
    D --> E{Stretch Ratio}
    E -->|> 1.0| F[Repeat Segments]
    E -->|< 1.0| G[Remove Segments]
    F --> H[Reconstruct Waveform]
    G --> H
    H --> I[Output Audio]
```

#### 1. Period Detection

The algorithm first identifies fundamental periods in the audio:

- **Frequency Analysis**: Looks for repeating patterns within specified frequency ranges
- **Autocorrelation**: Finds self-similarity at different time lags
- **Period Validation**: Confirms detected periods represent true harmonic content

```python
# Conceptual period detection
def detect_periods(audio_data, lower_freq, upper_freq, sample_rate):
    # Convert frequency limits to sample periods
    min_period = sample_rate // upper_freq
    max_period = sample_rate // lower_freq
    
    # Find repeating patterns in this range
    periods = find_autocorrelation_peaks(audio_data, min_period, max_period)
    return validate_periods(periods)
```

#### 2. Segment Classification

Audio is classified into different types:

- **Harmonic segments**: Contain clear pitch information
- **Noise segments**: Random or non-periodic content
- **Silence/gaps**: Low-energy regions
- **Transients**: Attack portions of sounds

#### 3. Selective Processing

Different segment types are handled differently:

=== "Stretching (Ratio > 1.0)"

    - **Harmonic segments**: Intelligent period repetition
    - **Noise segments**: Simple interpolation or repetition
    - **Silence**: Extended proportionally or per gap_ratio
    - **Transients**: Minimal modification to preserve attack

=== "Compression (Ratio < 1.0)"

    - **Harmonic segments**: Selective period removal
    - **Noise segments**: Downsampling or decimation
    - **Silence**: Reduced proportionally or per gap_ratio
    - **Transients**: Preserved when possible

### Mathematical Foundation

The core TDHS operation can be expressed as:

```
For stretch ratio R > 1.0:
- Identify periods Pâ‚, Pâ‚‚, ..., Pâ‚™
- Insert additional periods: Pâ‚, Pâ‚', Pâ‚‚, Pâ‚‚', ...
- Where Pâ‚' is a shifted/modified copy of Pâ‚

For compression ratio R < 1.0:
- Remove selective periods: Pâ‚, Pâ‚ƒ, Pâ‚…, ...
- Maintain harmonic continuity at boundaries
```

## AudioStretchy Implementation

### Processing Pipeline

AudioStretchy implements TDHS through a multi-layer architecture:

```mermaid
graph LR
    A[Audio File] --> B[Pedalboard I/O]
    B --> C[Format Conversion]
    C --> D[TDHS Engine]
    D --> E[Format Conversion]
    E --> F[Pedalboard I/O]
    F --> G[Output File]
    
    subgraph "TDHS Processing"
        D1[Period Detection] --> D2[Segment Analysis]
        D2 --> D3[Harmonic Scaling]
        D3 --> D4[Waveform Reconstruction]
    end
    
    D --> D1
    D4 --> E
```

### 1. Audio Input/Output Layer

**Pedalboard Integration**:
- Handles diverse audio formats (MP3, FLAC, WAV, etc.)
- Provides high-quality resampling
- Manages metadata and format conversion

```python
# Conceptual I/O layer
def load_audio(file_path):
    # Use Pedalboard to load various formats
    audio_data, sample_rate, channels = pedalboard.load(file_path)
    return convert_to_processing_format(audio_data)

def save_audio(audio_data, file_path, format_info):
    # Convert back from processing format
    output_data = convert_from_processing_format(audio_data)
    pedalboard.save(output_data, file_path, format_info)
```

### 2. Data Format Conversion

**Format Pipeline**:
- **Input**: Float32 samples from Pedalboard
- **Processing**: Int16 samples for C library
- **Output**: Float32 samples back to Pedalboard

```python
# Data conversion pipeline
def prepare_for_tdhs(float32_audio):
    # Convert to int16 for C library
    int16_audio = (float32_audio * 32767).astype(np.int16)
    
    # Handle stereo interleaving
    if stereo:
        return interleave_channels(int16_audio)
    return int16_audio

def process_tdhs_output(int16_audio):
    # Convert back to float32
    float32_audio = int16_audio.astype(np.float32) / 32767.0
    
    # Handle stereo de-interleaving
    if stereo:
        return deinterleave_channels(float32_audio)
    return float32_audio
```

### 3. TDHS Core Engine

**C Library Interface**:
- David Bryant's optimized C implementation
- ctypes binding for Python integration
- Platform-specific shared libraries

```python
# Simplified C interface
class TDHSAudioStretch:
    def __init__(self, sample_rate, channels):
        self.c_lib = load_platform_library()
        self.context = self.c_lib.stretch_init(sample_rate, channels)
    
    def stretch(self, audio_data, ratio, **params):
        # Configure stretching parameters
        self.c_lib.stretch_configure(self.context, ratio, **params)
        
        # Process audio
        output_data = self.c_lib.stretch_samples(self.context, audio_data)
        
        # Finalize processing
        final_data = self.c_lib.stretch_flush(self.context)
        
        return combine_output(output_data, final_data)
```

## Parameter Impact on Quality

### Frequency Range Parameters

**Upper and Lower Frequency Limits**:

These parameters guide period detection:

- **Narrow range**: More precise period detection, better for specific content
- **Wide range**: More flexible, handles diverse content but may be less accurate

```python
# Content-specific optimization
speech_params = {
    'upper_freq': 300,  # Human speech rarely exceeds 300Hz fundamental
    'lower_freq': 80    # Typical lower bound for speech
}

music_params = {
    'upper_freq': 400,  # Instruments can have higher fundamentals
    'lower_freq': 50    # Include bass instruments
}
```

### Quality vs. Speed Trade-offs

**Detection Modes**:

=== "Normal Detection"

    - **Quality**: Highest
    - **Speed**: Slower
    - **Use case**: Final production, critical applications

=== "Fast Detection"

    - **Quality**: Good
    - **Speed**: Faster
    - **Use case**: Testing, real-time applications

=== "Auto Detection"

    - **Quality**: Adaptive
    - **Speed**: Moderate
    - **Use case**: General purpose

### Ratio Range Considerations

**Standard Range (0.5 - 2.0)**:
- Well-tested ratio range
- Reliable quality
- Suitable for most applications

**Extended Range (0.25 - 4.0)**:
- Extreme stretching capabilities
- Potential quality degradation
- Requires `double_range=True`

## Algorithm Limitations

### Current Limitations

1. **Gap Ratio Implementation**: 
   - Python wrapper doesn't pre-segment audio
   - Relies on C library's internal gap detection
   - May not be as effective as dedicated preprocessing

2. **Real-time Processing**:
   - Not optimized for streaming
   - Requires complete audio buffer
   - Processing latency proportional to audio length

3. **Content Sensitivity**:
   - Works best with harmonic content
   - May struggle with pure noise or percussive sounds
   - Extreme ratios can introduce artifacts

### Best Practices

**For Optimal Results**:

1. **Match parameters to content type**
2. **Use moderate ratios when possible** (0.7 - 1.5)
3. **Test different frequency ranges** for your specific audio
4. **Consider preprocessing** for mixed content
5. **Validate output quality** especially for extreme ratios

## Comparison with Other Algorithms

### Phase Vocoder

- **Approach**: Frequency-domain processing
- **Pros**: Well-understood, flexible
- **Cons**: Can introduce phasiness, artifacts

### PSOLA (Pitch Synchronous Overlap and Add)

- **Approach**: Pitch-period based manipulation
- **Pros**: Good for speech
- **Cons**: Requires accurate pitch detection

### TDHS Advantages

- **Time-domain processing**: Avoids frequency-domain artifacts
- **Harmonic preservation**: Maintains natural sound quality
- **Robustness**: Works well across different content types
- **Efficiency**: Optimized C implementation

## Future Enhancements

### Potential Improvements

1. **Advanced Gap Handling**:
   - Python-side audio segmentation
   - Intelligent silence detection
   - Content-aware ratio application

2. **Real-time Capabilities**:
   - Streaming processing
   - Reduced latency buffering
   - Live audio applications

3. **Quality Metrics**:
   - Automated quality assessment
   - Parameter optimization
   - Perceptual quality measures

4. **Extended Content Support**:
   - Polyphonic music handling
   - Percussive content optimization
   - Multi-language speech adaptation

## Understanding Quality Factors

The quality of time-stretched audio depends on several factors:

### Input Audio Characteristics

- **Harmonic content**: Clear pitch makes stretching easier
- **Signal-to-noise ratio**: Clean audio processes better
- **Complexity**: Simple signals stretch more cleanly than complex ones

### Processing Parameters

- **Ratio magnitude**: Smaller changes generally sound better
- **Frequency range**: Proper tuning improves period detection
- **Detection quality**: Higher quality modes produce better results

### Output Requirements

- **Use case**: Different applications have different quality needs
- **Playback system**: High-quality systems reveal more artifacts
- **Listener sensitivity**: Some listeners are more sensitive to artifacts

Next: [Core Architecture](06-core-architecture.md) for implementation details
</document_content>
</document>

<document index="42">
<source>src_docs/md/06-core-architecture.md</source>
<document_content>
---
# this_file: src_docs/md/06-core-architecture.md
title: Core Architecture
description: Internal components and data flow
---

# Core Architecture

AudioStretchy's architecture is designed for high performance, cross-platform compatibility, and ease of use. This guide explores the internal components, data flow, and design decisions.

## System Overview

```mermaid
graph TB
    subgraph "User Interface Layer"
        CLI[Command Line Interface]
        API[Python API]
    end
    
    subgraph "Python Layer"
        MAIN[__main__.py]
        STRETCH[stretch.py]
        CORE[core.py]
    end
    
    subgraph "Interface Layer" 
        TDHS[tdhs.py]
        WRAPPER[wrapper.py]
        CTYPES[ctypes bindings]
    end
    
    subgraph "Native Layer"
        CLIB[C Library]
        LINUX[_stretch.so]
        MAC[_stretch.dylib]
        WIN[_stretch.dll]
    end
    
    subgraph "I/O Layer"
        PB[Pedalboard]
        FORMATS[Audio Formats]
    end
    
    CLI --> MAIN
    API --> STRETCH
    MAIN --> STRETCH
    STRETCH --> CORE
    STRETCH --> PB
    CORE --> TDHS
    TDHS --> CTYPES
    CTYPES --> CLIB
    CLIB --> LINUX
    CLIB --> MAC  
    CLIB --> WIN
    PB --> FORMATS
```

## Module Architecture

### Core Python Modules

#### `src/audiostretchy/__main__.py`

**Purpose**: Command-line interface entry point

```python
# this_file: src/audiostretchy/__main__.py
"""
CLI entry point using Fire library
- Parses command line arguments  
- Calls stretch_audio function
- Handles basic error reporting
"""

import fire
from .stretch import stretch_audio

def main():
    """CLI entry point"""
    fire.Fire(stretch_audio)

if __name__ == "__main__":
    main()
```

**Key Features**:
- Uses Python Fire for automatic CLI generation
- Minimal code, maximum functionality
- All parameters automatically exposed as CLI options

#### `src/audiostretchy/stretch.py`

**Purpose**: Main orchestration and public API

```python
# this_file: src/audiostretchy/stretch.py
"""
Core AudioStretch class and convenience functions
- File I/O management via Pedalboard
- Data format conversion
- TDHS algorithm orchestration
- Error handling and validation
"""

class AudioStretch:
    """Main audio processing class"""
    
    def __init__(self):
        self.audio_file = None
        self.sample_rate = None
        self.channels = None
        
    def open(self, file_path_or_object, format=None):
        """Load audio file using Pedalboard"""
        
    def stretch(self, ratio=1.0, **params):
        """Apply TDHS time-stretching"""
        
    def resample(self, target_framerate):
        """Resample audio using Pedalboard"""
        
    def save(self, file_path_or_object, format=None):
        """Save processed audio"""

def stretch_audio(input_path, output_path, **params):
    """Convenience function for simple stretching"""
```

**Responsibilities**:
- File format handling
- Parameter validation
- Data flow coordination
- Public API surface

#### `src/audiostretchy/core.py`

**Purpose**: Core processing logic (minimal, mainly imports)

```python
# this_file: src/audiostretchy/core.py
"""
Core processing imports and utilities
Currently minimal - may expand for shared utilities
"""

# Re-exports for internal use
from .interface.tdhs import TDHSAudioStretch
from .stretch import AudioStretch, stretch_audio
```

### Interface Layer

#### `src/audiostretchy/interface/tdhs.py`

**Purpose**: Python-C interface using ctypes

```python
# this_file: src/audiostretchy/interface/tdhs.py
"""
TDHS C library wrapper
- Platform detection and library loading
- ctypes function signatures
- Data conversion between Python/C
- Memory management
"""

import ctypes
import platform
from pathlib import Path

class TDHSAudioStretch:
    """Python wrapper for TDHS C library"""
    
    def __init__(self):
        self.lib = self._load_library()
        self._setup_function_signatures()
        self.context = None
        
    def _load_library(self):
        """Load platform-specific shared library"""
        system = platform.system()
        machine = platform.machine()
        
        if system == "Windows":
            lib_name = "_stretch.dll"
            lib_dir = "win"
        elif system == "Darwin":
            lib_name = "_stretch.dylib"
            lib_dir = "mac"
        elif system == "Linux":
            lib_name = "_stretch.so"
            lib_dir = "linux"
        else:
            raise RuntimeError(f"Unsupported platform: {system}")
            
        lib_path = Path(__file__).parent / lib_dir / lib_name
        return ctypes.CDLL(str(lib_path))
    
    def _setup_function_signatures(self):
        """Define ctypes function signatures"""
        # stretch_init function
        self.lib.stretch_init.argtypes = [
            ctypes.c_int,    # sample_rate
            ctypes.c_int,    # channels
            ctypes.c_double, # ratio
            # ... other parameters
        ]
        self.lib.stretch_init.restype = ctypes.c_void_p
        
        # Other function signatures...
```

**Key Features**:
- Cross-platform library loading
- Type-safe ctypes bindings
- Memory management
- Error handling

### Native C Library

#### Platform-Specific Binaries

The C library is compiled for multiple platforms:

=== "Linux"

    **Location**: `src/audiostretchy/interface/linux/_stretch.so`
    
    **Build**: GCC/Clang compilation
    ```bash
    gcc -shared -fPIC -O3 stretch.c -o _stretch.so
    ```

=== "macOS"

    **Location**: `src/audiostretchy/interface/mac/_stretch.dylib`
    
    **Build**: Universal binary (x86_64 + arm64)
    ```bash
    clang -shared -O3 -arch x86_64 -arch arm64 stretch.c -o _stretch.dylib
    ```

=== "Windows"

    **Location**: `src/audiostretchy/interface/win/_stretch.dll`
    
    **Build**: MSVC compilation
    ```bash
    cl /LD /O2 stretch.c /Fe:_stretch.dll
    ```

#### C Library Interface

The C library exposes these key functions:

```c
// Initialize stretching context
void* stretch_init(int sample_rate, int channels, double ratio, ...);

// Process audio samples
int stretch_samples(void* context, short* input, int input_length, 
                   short* output, int* output_length);

// Flush remaining samples
int stretch_flush(void* context, short* output, int* output_length);

// Clean up context
void stretch_cleanup(void* context);
```

## Data Flow

### Processing Pipeline

```mermaid
sequenceDiagram
    participant User
    participant API as Python API
    participant PB as Pedalboard
    participant TDHS as TDHS Wrapper
    participant C as C Library
    
    User->>API: Call stretch_audio()
    API->>PB: Load audio file
    PB-->>API: Float32 audio data
    
    API->>API: Convert Float32 â†’ Int16
    API->>TDHS: Initialize with parameters
    TDHS->>C: stretch_init()
    C-->>TDHS: Context pointer
    
    API->>TDHS: Process audio chunks
    TDHS->>C: stretch_samples()
    C-->>TDHS: Processed samples
    
    TDHS->>C: stretch_flush()
    C-->>TDHS: Final samples
    TDHS-->>API: Combined output
    
    API->>API: Convert Int16 â†’ Float32
    API->>PB: Save audio file
    PB-->>User: Output file
```

### Memory Management

#### Audio Data Lifecycle

1. **Loading**: Pedalboard loads audio into NumPy arrays (Float32)
2. **Conversion**: Python converts to Int16 for C library
3. **Processing**: C library processes data in chunks
4. **Collection**: Python collects processed chunks
5. **Conversion**: Back to Float32 for Pedalboard
6. **Saving**: Pedalboard writes to output format

#### Memory Optimization

```python
def memory_efficient_stretch(audio_data, ratio):
    """Memory-efficient processing for large files"""
    
    chunk_size = 8192  # Process in chunks
    output_chunks = []
    
    for i in range(0, len(audio_data), chunk_size):
        chunk = audio_data[i:i + chunk_size]
        processed = process_chunk(chunk, ratio)
        output_chunks.append(processed)
        
        # Optional: explicit memory cleanup
        del chunk
        
    return np.concatenate(output_chunks)
```

## Error Handling Architecture

### Layered Error Handling

```mermaid
graph TD
    A[User Input] --> B{Validation Layer}
    B -->|Valid| C[Processing Layer]
    B -->|Invalid| E[Parameter Error]
    
    C --> D{File I/O Layer}
    D -->|Success| F[TDHS Layer]
    D -->|Fail| G[I/O Error]
    
    F --> H{C Library Layer}
    H -->|Success| I[Output]
    H -->|Fail| J[Processing Error]
    
    E --> K[User Error Message]
    G --> K
    J --> K
```

### Error Categories

#### 1. Input Validation Errors

```python
class ParameterError(ValueError):
    """Invalid parameter values"""
    pass

def validate_ratio(ratio):
    if not isinstance(ratio, (int, float)):
        raise ParameterError("Ratio must be a number")
    if ratio <= 0:
        raise ParameterError("Ratio must be positive")
    if ratio > 4.0 or ratio < 0.25:
        raise ParameterError("Ratio out of supported range")
```

#### 2. File I/O Errors

```python
def safe_file_open(file_path):
    try:
        return pedalboard_load(file_path)
    except FileNotFoundError:
        raise FileNotFoundError(f"Input file not found: {file_path}")
    except PermissionError:
        raise PermissionError(f"Cannot read file: {file_path}")
    except Exception as e:
        raise RuntimeError(f"Failed to load audio: {e}")
```

#### 3. Processing Errors

```python
def safe_tdhs_process(context, audio_data):
    try:
        return tdhs_library.process(context, audio_data)
    except ctypes.ArgumentError:
        raise RuntimeError("Invalid audio data format")
    except OSError as e:
        raise RuntimeError(f"C library error: {e}")
```

## Configuration Management

### Parameter Hierarchy

AudioStretchy supports multiple configuration levels:

1. **Defaults**: Built-in sensible defaults
2. **Function parameters**: Direct function arguments
3. **Environment variables**: System-level configuration
4. **Config files**: Persistent user preferences (future)

```python
class ParameterManager:
    """Manage parameter precedence"""
    
    DEFAULTS = {
        'ratio': 1.0,
        'upper_freq': 333,
        'lower_freq': 55,
        # ... other defaults
    }
    
    def resolve_parameters(self, **kwargs):
        """Resolve parameters with precedence"""
        params = self.DEFAULTS.copy()
        
        # Environment variables
        params.update(self._load_env_params())
        
        # Function arguments (highest priority)
        params.update({k: v for k, v in kwargs.items() if v is not None})
        
        return params
```

## Platform Compatibility

### Cross-Platform Design

#### File Path Handling

```python
from pathlib import Path

def normalize_path(path_input):
    """Normalize paths across platforms"""
    if isinstance(path_input, str):
        return Path(path_input).resolve()
    return path_input  # Assume file-like object
```

#### Library Loading

```python
def get_library_path():
    """Get platform-specific library path"""
    import platform
    
    system_map = {
        'Windows': ('win', '_stretch.dll'),
        'Darwin': ('mac', '_stretch.dylib'),
        'Linux': ('linux', '_stretch.so'),
    }
    
    system = platform.system()
    if system not in system_map:
        raise RuntimeError(f"Unsupported platform: {system}")
    
    dir_name, lib_name = system_map[system]
    return Path(__file__).parent / dir_name / lib_name
```

### Build System Integration

#### CI/CD Pipeline

```yaml
# Simplified CI build matrix
strategy:
  matrix:
    os: [ubuntu-latest, windows-latest, macos-latest]
    python-version: [3.8, 3.9, 3.10, 3.11, 3.12]
    
steps:
  - name: Build C Library
    run: |
      # Platform-specific build commands
      python scripts/build_c_library.py
      
  - name: Test Installation
    run: |
      pip install -e .
      python -c "import audiostretchy; print('Import successful')"
```

## Performance Characteristics

### Computational Complexity

#### Time Complexity

- **File I/O**: O(n) where n = file size
- **Format conversion**: O(n) where n = sample count
- **TDHS processing**: O(n Ã— f) where f = frequency analysis factor
- **Overall**: O(n) linear with audio length

#### Memory Complexity

- **Baseline**: O(n) for audio data storage
- **Processing overhead**: O(c) constant for algorithm state
- **Peak usage**: ~2Ã— input size during processing

### Optimization Strategies

#### 1. Chunked Processing

```python
def chunked_stretch(audio_data, chunk_size=8192):
    """Process audio in chunks to manage memory"""
    for i in range(0, len(audio_data), chunk_size):
        yield process_chunk(audio_data[i:i+chunk_size])
```

#### 2. Lazy Loading

```python
class LazyAudioLoader:
    """Load audio data only when needed"""
    
    def __init__(self, file_path):
        self.file_path = file_path
        self._data = None
        self._metadata = None
    
    @property
    def data(self):
        if self._data is None:
            self._data = load_audio_data(self.file_path)
        return self._data
```

#### 3. Memory Pools

```python
class AudioBufferPool:
    """Reuse audio buffers to reduce allocation overhead"""
    
    def __init__(self):
        self._buffers = {}
    
    def get_buffer(self, size, dtype=np.float32):
        key = (size, dtype)
        if key not in self._buffers:
            self._buffers[key] = np.empty(size, dtype=dtype)
        return self._buffers[key]
```

## Testing Architecture

### Test Structure

```
tests/
â”œâ”€â”€ test_cli.py           # Command-line interface tests
â”œâ”€â”€ test_core.py          # Core functionality tests  
â”œâ”€â”€ test_stretch.py       # Stretching algorithm tests
â”œâ”€â”€ test_performance.py   # Performance benchmarks
â”œâ”€â”€ test_mono_audio.py    # Mono audio specific tests
â””â”€â”€ conftest.py          # Test configuration
```

### Test Categories

#### 1. Unit Tests

```python
def test_parameter_validation():
    """Test parameter validation logic"""
    with pytest.raises(ParameterError):
        validate_ratio(-1.0)
        
def test_format_conversion():
    """Test audio format conversion"""
    float_data = np.array([0.5, -0.5], dtype=np.float32)
    int_data = convert_to_int16(float_data)
    assert int_data.dtype == np.int16
```

#### 2. Integration Tests

```python
def test_full_pipeline():
    """Test complete processing pipeline"""
    result = stretch_audio("test_input.wav", "test_output.wav", ratio=1.2)
    assert Path("test_output.wav").exists()
    
    # Validate output properties
    original = load_audio("test_input.wav")
    stretched = load_audio("test_output.wav")
    expected_length = len(original) * 1.2
    assert abs(len(stretched) - expected_length) < 1000  # Tolerance
```

#### 3. Performance Tests

```python
def test_processing_speed():
    """Benchmark processing speed"""
    import time
    
    start_time = time.time()
    stretch_audio("large_test_file.wav", "output.wav", ratio=1.1)
    duration = time.time() - start_time
    
    # Should process faster than real-time for reasonable files
    audio_duration = get_audio_duration("large_test_file.wav")
    assert duration < audio_duration * 2  # 2x real-time max
```

## Extension Points

### Future Architecture Enhancements

#### 1. Plugin System

```python
class StretchAlgorithm:
    """Base class for stretching algorithms"""
    
    def stretch(self, audio_data, ratio, **params):
        raise NotImplementedError
        
class TDHSAlgorithm(StretchAlgorithm):
    """TDHS implementation"""
    pass
    
class PhaseVocoderAlgorithm(StretchAlgorithm):
    """Phase vocoder implementation"""  
    pass
```

#### 2. Real-time Processing

```python
class StreamingAudioStretch:
    """Future: real-time audio stretching"""
    
    def __init__(self, buffer_size=1024):
        self.buffer_size = buffer_size
        self.processor = None
        
    def process_chunk(self, audio_chunk):
        """Process audio in real-time chunks"""
        return self.processor.stretch_chunk(audio_chunk)
```

#### 3. Quality Metrics

```python
class QualityAnalyzer:
    """Future: automated quality assessment"""
    
    def analyze(self, original, stretched):
        """Compute quality metrics"""
        return {
            'snr': compute_snr(original, stretched),
            'thd': compute_thd(stretched),
            'perceptual': compute_perceptual_quality(original, stretched)
        }
```

Next: [Parameters Reference](07-parameters-reference.md) for detailed parameter explanations
</document_content>
</document>

<document index="43">
<source>src_docs/md/07-parameters-reference.md</source>
<document_content>
---
# this_file: src_docs/md/07-parameters-reference.md
title: Parameters Reference
description: Detailed parameter explanations and tuning
---

# Parameters Reference

This comprehensive guide explains every AudioStretchy parameter, their interactions, and how to optimize them for different use cases.

## Core Parameters

### Stretch Ratio

The fundamental parameter controlling time-stretching behavior.

#### `ratio` (float)

**Default**: `1.0`  
**Range**: `0.5 - 2.0` (normal), `0.25 - 4.0` (with `double_range=True`)  
**CLI**: `--ratio`, `-r`

Controls the time-stretching factor:

- **`ratio = 1.0`**: No change (original duration)
- **`ratio > 1.0`**: Slower playback (longer duration)  
- **`ratio < 1.0`**: Faster playback (shorter duration)

!!! example "Ratio Examples"
    ```python
    # 20% slower (duration Ã— 1.2)
    stretch_audio("input.wav", "output.wav", ratio=1.2)
    
    # 25% faster (duration Ã— 0.75)  
    stretch_audio("input.wav", "output.wav", ratio=0.75)
    
    # Double speed (half duration)
    stretch_audio("input.wav", "output.wav", ratio=0.5)
    ```

**Quality Considerations**:

| Ratio Range | Quality | Use Cases |
|-------------|---------|-----------|
| 0.8 - 1.25 | Excellent | General use, subtle adjustments |
| 0.5 - 0.8, 1.25 - 2.0 | Good | Podcasts, practice material |
| 0.25 - 0.5, 2.0 - 4.0 | Fair | Special effects, analysis |

#### `gap_ratio` (float)

**Default**: `0.0` (use main ratio)  
**Range**: `0.0 - 4.0`  
**CLI**: `--gap_ratio`, `-g`

Separate stretching ratio for silence/gaps in audio.

```python
# Stretch speech 1.3x but keep silence at normal speed
stretch_audio("speech.wav", "output.wav", ratio=1.3, gap_ratio=1.0)

# Compress gaps more aggressively than speech
stretch_audio("podcast.wav", "output.wav", ratio=0.9, gap_ratio=0.5)
```

!!! warning "Current Limitation"
    The Python wrapper doesn't pre-segment audio for gap detection. Effectiveness depends on the C library's internal silence detection capabilities.

**When to Use**:
- Podcasts with long pauses
- Speech with significant silence
- Presentations with gaps between sections

## Frequency Detection Parameters

These parameters control how the algorithm identifies audio periods and fundamental frequencies.

### `upper_freq` (int)

**Default**: `333` Hz  
**Range**: `50 - 1000` Hz (typical)  
**CLI**: `--upper_freq`, `-u`

Upper frequency limit for period detection.

**Content Optimization**:

=== "Speech"

    ```python
    # Human speech fundamentals rarely exceed 300Hz
    stretch_audio("speech.wav", "output.wav", 
                 ratio=1.2, upper_freq=300)
    ```

=== "Music"

    ```python
    # Instruments can have higher fundamentals
    stretch_audio("music.wav", "output.wav", 
                 ratio=1.1, upper_freq=400)
    ```

=== "Male Speech"

    ```python
    # Male voices typically lower
    stretch_audio("male_voice.wav", "output.wav", 
                 ratio=1.3, upper_freq=250)
    ```

=== "Female Speech"

    ```python
    # Female voices can be higher
    stretch_audio("female_voice.wav", "output.wav", 
                 ratio=1.3, upper_freq=350)
    ```

**Quality Impact**:
- **Too low**: May miss higher-pitched content
- **Too high**: May detect false periods in noise
- **Optimal**: Match the fundamental frequency range of your content

### `lower_freq` (int)

**Default**: `55` Hz  
**Range**: `20 - 200` Hz (typical)  
**CLI**: `--lower_freq`, `-l`

Lower frequency limit for period detection.

**Content Optimization**:

```python
# Bass-heavy music
stretch_audio("bass_music.wav", "output.wav", 
             ratio=1.1, lower_freq=30)

# Speech (no very low fundamentals needed)  
stretch_audio("speech.wav", "output.wav", 
             ratio=1.2, lower_freq=80)

# Full-range music
stretch_audio("orchestral.wav", "output.wav", 
             ratio=1.15, lower_freq=40)
```

**Frequency Range Guidelines**:

| Content Type | Lower Freq | Upper Freq | Reasoning |
|--------------|------------|------------|-----------|
| Male Speech | 80 Hz | 250 Hz | Typical male fundamental range |
| Female Speech | 80 Hz | 350 Hz | Higher female fundamentals |
| Mixed Speech | 80 Hz | 300 Hz | Safe range for both genders |
| Pop Music | 50 Hz | 400 Hz | Vocals + most instruments |
| Classical | 40 Hz | 450 Hz | Full orchestral range |
| Electronic | 30 Hz | 500 Hz | Synthetic sounds, wide range |

## Algorithm Control Parameters

### `double_range` (bool)

**Default**: `False`  
**Range**: `True` or `False`  
**CLI**: `--double_range`, `-d`

Enables extended ratio range (0.25 - 4.0 instead of 0.5 - 2.0).

```python
# Enable extreme stretching
stretch_audio("input.wav", "output.wav", 
             ratio=0.3, double_range=True)

# 4x slower for detailed analysis
stretch_audio("complex_audio.wav", "analysis.wav", 
             ratio=4.0, double_range=True)
```

**When to Enable**:
- Extreme time compression (< 0.5x)
- Very slow analysis (> 2.0x)
- Special effects processing
- Transcription aid (very slow speech)

**Quality Trade-offs**:
- Ratios outside 0.5-2.0 may introduce more artifacts
- Use with caution for production audio
- Test thoroughly for acceptable quality

### `fast_detection` (bool)

**Default**: `False`  
**Range**: `True` or `False`  
**CLI**: `--fast_detection`, `-f`

Enables faster but potentially lower quality period detection.

```python
# Quick processing for testing
stretch_audio("test_file.wav", "quick_test.wav", 
             ratio=1.2, fast_detection=True)

# Batch processing with speed priority
for file in audio_files:
    stretch_audio(file, f"fast_{file}", 
                 ratio=0.8, fast_detection=True)
```

**Use Cases**:
- **Development/Testing**: Quick iterations during development
- **Batch Processing**: When processing many files
- **Real-time Applications**: Reduced latency requirements
- **Preview Generation**: Quick previews before final processing

**Quality Considerations**:
- Generally produces acceptable quality for most content
- May struggle with complex harmonic content
- Always test critical applications with `fast_detection=False`

### `normal_detection` (bool)

**Default**: `False`  
**Range**: `True` or `False`  
**CLI**: `--normal_detection`, `-n`

Forces normal (high-quality) period detection method.

```python
# Force highest quality for critical audio
stretch_audio("master_recording.wav", "stretched_master.wav", 
             ratio=1.1, normal_detection=True)

# Override automatic detection selection
stretch_audio("complex_music.wav", "output.wav", 
             ratio=1.3, normal_detection=True)
```

**When to Use**:
- Critical/production audio
- Complex musical content
- When automatic detection isn't optimal
- Final masters and releases

## Audio Processing Parameters

### `sample_rate` (int)

**Default**: `0` (preserve original)  
**Range**: `8000 - 192000` Hz (typical)  
**CLI**: `--sample_rate`, `-s`

Target sample rate for output resampling.

```python
# Downsample to reduce file size
stretch_audio("hd_audio.wav", "compressed.wav", 
             ratio=1.1, sample_rate=44100)

# Upsample for high-quality processing
stretch_audio("input.wav", "hq_output.wav", 
             ratio=1.2, sample_rate=96000)

# Match target system requirements
stretch_audio("source.flac", "phone_optimized.mp3", 
             ratio=0.9, sample_rate=22050)
```

**Common Sample Rates**:

| Rate | Quality | Use Case |
|------|---------|----------|
| 22050 Hz | Low | Voice, podcasts, mobile |
| 44100 Hz | CD Quality | General music, streaming |
| 48000 Hz | Professional | Video, broadcast |
| 96000 Hz | High-res | Mastering, archival |

**Resampling Guidelines**:
- **Upsampling**: Generally safe, slight quality improvement possible
- **Downsampling**: May lose high-frequency content
- **Matching**: Use target system's native rate when possible

## Advanced Parameters

### `buffer_ms` (float)

**Default**: `25.0` ms  
**Range**: `5.0 - 100.0` ms (typical)  
**CLI**: `--buffer_ms`, `-b`

Buffer size for internal processing, potentially affecting silence detection.

```python
# Smaller buffer for responsive processing
stretch_audio("speech.wav", "output.wav", 
             ratio=1.2, buffer_ms=10.0)

# Larger buffer for complex audio
stretch_audio("dense_music.wav", "output.wav", 
             ratio=1.1, buffer_ms=50.0)
```

**Impact**:
- **Smaller buffers**: More responsive, potentially less smooth
- **Larger buffers**: Smoother processing, higher latency
- **Memory usage**: Larger buffers use more memory

### `threshold_gap_db` (float)

**Default**: `-40.0` dB  
**Range**: `-60.0` to `-20.0` dB (typical)  
**CLI**: `--threshold_gap_db`, `-t`

Silence detection threshold for gap handling.

```python
# Sensitive gap detection (quiet passages as silence)
stretch_audio("classical.wav", "output.wav", 
             ratio=1.2, threshold_gap_db=-35.0)

# Less sensitive (only true silence detected)
stretch_audio("noisy_recording.wav", "output.wav", 
             ratio=1.1, threshold_gap_db=-50.0)
```

**Threshold Guidelines**:

| Content Type | Threshold | Reasoning |
|--------------|-----------|-----------|
| Studio Recording | -45 dB | Clean, low noise floor |
| Live Recording | -35 dB | Higher noise floor |
| Compressed Audio | -40 dB | General purpose |
| Noisy Source | -30 dB | Only detect obvious silence |

## Parameter Combinations

### Optimized Presets

#### Speech Processing

```python
speech_params = {
    'upper_freq': 300,
    'lower_freq': 80,
    'normal_detection': True,
    'threshold_gap_db': -40.0
}

stretch_audio("speech.wav", "output.wav", 
             ratio=1.3, **speech_params)
```

#### Music Processing

```python
music_params = {
    'upper_freq': 400,
    'lower_freq': 50,
    'normal_detection': True,
    'buffer_ms': 30.0
}

stretch_audio("song.flac", "practice.wav", 
             ratio=1.5, **music_params)
```

#### Fast Processing

```python
fast_params = {
    'fast_detection': True,
    'buffer_ms': 15.0,
    'sample_rate': 44100
}

stretch_audio("large_file.wav", "quick_result.mp3", 
             ratio=0.8, **fast_params)
```

#### High Quality

```python
hq_params = {
    'normal_detection': True,
    'buffer_ms': 40.0,
    'sample_rate': 96000,
    'upper_freq': 450,
    'lower_freq': 40
}

stretch_audio("master.wav", "hq_stretched.wav", 
             ratio=1.1, **hq_params)
```

## Parameter Validation

### Automatic Validation

AudioStretchy automatically validates parameters:

```python
# These will raise ValueError
stretch_audio("input.wav", "output.wav", ratio=-1.0)     # Negative ratio
stretch_audio("input.wav", "output.wav", ratio=5.0)      # Ratio too large
stretch_audio("input.wav", "output.wav", upper_freq=0)   # Invalid frequency
```

### Custom Validation

```python
def validate_parameters(**params):
    """Custom parameter validation"""
    
    ratio = params.get('ratio', 1.0)
    upper_freq = params.get('upper_freq', 333)
    lower_freq = params.get('lower_freq', 55)
    
    # Ratio validation
    if ratio <= 0:
        raise ValueError("Ratio must be positive")
    
    if ratio > 2.0 and not params.get('double_range', False):
        raise ValueError("Ratio > 2.0 requires double_range=True")
    
    # Frequency validation  
    if upper_freq <= lower_freq:
        raise ValueError("upper_freq must be greater than lower_freq")
    
    if lower_freq < 20:
        raise ValueError("lower_freq too low (< 20 Hz)")
    
    return True

# Usage
params = {'ratio': 1.5, 'upper_freq': 350, 'lower_freq': 80}
validate_parameters(**params)
stretch_audio("input.wav", "output.wav", **params)
```

## Performance vs. Quality Trade-offs

### Processing Speed Factors

| Parameter | Speed Impact | Quality Impact |
|-----------|--------------|----------------|
| `fast_detection=True` | +50% faster | -10% quality |
| `buffer_ms=10` | +20% faster | -5% quality |
| `sample_rate=22050` | +30% faster | -variable |
| `normal_detection=True` | -30% slower | +15% quality |

### Optimization Strategies

#### Speed-Optimized

```python
speed_config = {
    'fast_detection': True,
    'buffer_ms': 10.0,
    'sample_rate': 22050
}
```

#### Quality-Optimized

```python
quality_config = {
    'normal_detection': True,
    'buffer_ms': 40.0,
    'sample_rate': 96000
}
```

#### Balanced

```python
balanced_config = {
    'buffer_ms': 25.0,
    'sample_rate': 48000,
    # Use defaults for detection
}
```

## Troubleshooting Parameters

### Common Issues and Solutions

#### Poor Quality Output

**Symptoms**: Robotic sound, artifacts, distortion

**Solutions**:
```python
# Try these improvements
improved_params = {
    'normal_detection': True,      # Higher quality detection
    'buffer_ms': 35.0,            # Larger buffer
    'upper_freq': 350,            # Adjust frequency range
    'lower_freq': 60              # Match content better
}
```

#### Processing Too Slow

**Symptoms**: Long processing times

**Solutions**:
```python
# Speed optimizations
fast_params = {
    'fast_detection': True,       # Faster algorithm
    'buffer_ms': 15.0,           # Smaller buffer
    'sample_rate': 44100         # Reduce sample rate
}
```

#### Artifacts in Speech

**Symptoms**: Unnatural speech, choppy delivery

**Solutions**:
```python
# Speech-specific tuning
speech_fix = {
    'upper_freq': 250,           # Lower for male speech
    'lower_freq': 85,            # Remove very low frequencies
    'threshold_gap_db': -35.0,   # Better gap detection
    'normal_detection': True     # High quality
}
```

#### Silent Gaps Not Handled Well

**Symptoms**: Gaps stretched incorrectly

**Solutions**:
```python
# Better gap handling
gap_fix = {
    'gap_ratio': 1.0,            # Don't stretch silence
    'threshold_gap_db': -40.0,   # Adjust sensitivity
    'buffer_ms': 30.0            # Larger buffer for detection
}
```

## Future Parameter Enhancements

### Planned Additions

- **`quality_mode`**: Automatic quality/speed selection
- **`content_type`**: Automatic parameter optimization
- **`real_time`**: Streaming processing parameters
- **`noise_reduction`**: Integrated noise handling

### Advanced Features

- **Adaptive parameters**: Automatic adjustment based on content analysis
- **Perceptual optimization**: Parameters based on psychoacoustic models
- **Multi-band processing**: Different parameters for frequency bands

Next: [Contributing](08-contributing.md) for development guidelines
</document_content>
</document>

<document index="44">
<source>src_docs/md/08-contributing.md</source>
<document_content>
---
# this_file: src_docs/md/08-contributing.md
title: Contributing
description: Guidelines for contributing to the project
---

# Contributing

AudioStretchy welcomes contributions from the community! Whether you're fixing bugs, adding features, improving documentation, or sharing ideas, your help is appreciated.

## Getting Started

### Prerequisites

Before contributing, ensure you have:

- **Python 3.8+** installed
- **Git** for version control
- **C compiler** for building extensions (if modifying C code)
- **FFmpeg** for audio format support

### Setting Up Development Environment

#### 1. Fork and Clone

```bash
# Fork the repository on GitHub, then clone your fork
git clone https://github.com/YOUR_USERNAME/audiostretchy.git
cd audiostretchy

# Add upstream remote
git remote add upstream https://github.com/twardoch/audiostretchy.git
```

#### 2. Initialize Submodules

```bash
# The C library source is included as a submodule
git submodule update --init --recursive
```

#### 3. Create Virtual Environment

```bash
# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

#### 4. Install Development Dependencies

```bash
# Install in editable mode with testing dependencies
pip install -e .[testing]

# Install pre-commit hooks
pre-commit install
```

### Development Tools

AudioStretchy uses several tools to maintain code quality:

| Tool | Purpose | Configuration |
|------|---------|---------------|
| **Black** | Code formatting | `pyproject.toml` |
| **isort** | Import sorting | `.isort.cfg` |
| **Flake8** | Linting | `pyproject.toml` |
| **pytest** | Testing | `pyproject.toml` |
| **pre-commit** | Git hooks | `.pre-commit-config.yaml` |

## Development Workflow

### 1. Create Feature Branch

```bash
# Always create a new branch for your changes
git checkout -b feature/your-feature-name

# Or for bug fixes
git checkout -b fix/issue-description
```

### 2. Make Changes

Follow these guidelines while developing:

#### Code Style

```python
# Follow PEP 8 and use type hints
def stretch_audio(
    input_path: str,
    output_path: str,
    ratio: float = 1.0,
    **kwargs: Any
) -> None:
    """
    Stretch audio file with specified ratio.
    
    Args:
        input_path: Path to input audio file
        output_path: Path for output file
        ratio: Stretch ratio (>1.0 = slower, <1.0 = faster)
        **kwargs: Additional stretching parameters
    """
    # Implementation here
    pass
```

#### Documentation

```python
class AudioStretch:
    """
    Audio time-stretching processor using TDHS algorithm.
    
    This class provides high-level interface for audio time-stretching
    without pitch changes. It uses the Time-Domain Harmonic Scaling
    algorithm for natural-sounding results.
    
    Example:
        Basic usage:
        
        >>> processor = AudioStretch()
        >>> processor.open("input.wav")
        >>> processor.stretch(ratio=1.2)
        >>> processor.save("output.wav")
    """
```

#### Error Handling

```python
def validate_ratio(ratio: float) -> None:
    """Validate stretch ratio parameter."""
    if not isinstance(ratio, (int, float)):
        raise TypeError(f"Ratio must be numeric, got {type(ratio)}")
    
    if ratio <= 0:
        raise ValueError(f"Ratio must be positive, got {ratio}")
    
    if ratio > 4.0 or ratio < 0.25:
        raise ValueError(f"Ratio {ratio} outside supported range (0.25-4.0)")
```

### 3. Write Tests

All new code should include tests:

#### Unit Tests

```python
# tests/test_stretch.py
import pytest
from audiostretchy.stretch import AudioStretch, stretch_audio

def test_ratio_validation():
    """Test ratio parameter validation."""
    with pytest.raises(ValueError, match="must be positive"):
        stretch_audio("input.wav", "output.wav", ratio=-1.0)

def test_basic_stretching():
    """Test basic audio stretching functionality."""
    # Create test audio or use fixtures
    stretch_audio("tests/data/test.wav", "tests/output/stretched.wav", ratio=1.2)
    
    # Validate output exists and has expected properties
    assert Path("tests/output/stretched.wav").exists()
```

#### Integration Tests

```python
def test_full_pipeline(tmp_path):
    """Test complete processing pipeline."""
    input_file = tmp_path / "input.wav"
    output_file = tmp_path / "output.wav"
    
    # Generate test audio
    create_test_audio(input_file, duration=2.0, sample_rate=44100)
    
    # Process
    stretch_audio(str(input_file), str(output_file), ratio=1.5)
    
    # Validate
    original_duration = get_audio_duration(input_file)
    stretched_duration = get_audio_duration(output_file)
    expected_duration = original_duration * 1.5
    
    assert abs(stretched_duration - expected_duration) < 0.1
```

### 4. Run Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src/audiostretchy --cov-report=term-missing

# Run specific test file
pytest tests/test_stretch.py

# Run specific test
pytest tests/test_stretch.py::test_ratio_validation
```

### 5. Check Code Quality

```bash
# Run all pre-commit hooks
pre-commit run --all-files

# Or run tools individually
black src/ tests/
isort src/ tests/
flake8 src/ tests/
```

### 6. Commit Changes

```bash
# Stage your changes
git add .

# Commit with descriptive message
git commit -m "feat: add support for streaming audio processing

- Implement StreamingAudioStretch class
- Add chunked processing for large files
- Include tests for streaming functionality
- Update documentation with streaming examples"
```

#### Commit Message Format

Use [Conventional Commits](https://www.conventionalcommits.org/) format:

- **feat**: New features
- **fix**: Bug fixes
- **docs**: Documentation changes
- **style**: Code style changes (formatting, etc.)
- **refactor**: Code refactoring
- **test**: Adding or updating tests
- **chore**: Maintenance tasks

### 7. Push and Create Pull Request

```bash
# Push to your fork
git push origin feature/your-feature-name

# Create pull request on GitHub
```

## Types of Contributions

### Bug Fixes

#### Finding Bugs

- Check the [issue tracker](https://github.com/twardoch/audiostretchy/issues)
- Test edge cases and unusual inputs
- Try different audio formats and parameters

#### Reporting Bugs

When reporting bugs, include:

```markdown
**Bug Description**
Clear description of the problem

**To Reproduce**
1. Steps to reproduce
2. Expected behavior
3. Actual behavior

**Environment**
- OS: [e.g., Windows 10, macOS 12, Ubuntu 20.04]
- Python version: [e.g., 3.9.7]
- AudioStretchy version: [e.g., 1.2.3]
- Audio file format: [e.g., MP3, WAV]

**Additional Context**
Error messages, logs, sample files (if possible)
```

#### Fixing Bugs

```python
# Example bug fix with test
def test_handles_empty_audio():
    """Test handling of empty audio files."""
    with pytest.raises(ValueError, match="empty audio"):
        stretch_audio("tests/data/empty.wav", "output.wav", ratio=1.2)

def load_audio_file(file_path):
    """Load audio file with empty file validation."""
    audio_data = pedalboard.load(file_path)
    
    if len(audio_data) == 0:
        raise ValueError(f"Audio file is empty: {file_path}")
    
    return audio_data
```

### New Features

#### Feature Requests

Before implementing new features:

1. **Check existing issues** for similar requests
2. **Create an issue** to discuss the feature
3. **Get feedback** from maintainers
4. **Design the API** before implementing

#### Feature Implementation

```python
# Example: Adding a quality assessment feature
class QualityAnalyzer:
    """Analyze audio quality after stretching."""
    
    def __init__(self):
        self.metrics = ['snr', 'thd', 'perceptual']
    
    def analyze(self, original: np.ndarray, stretched: np.ndarray) -> Dict[str, float]:
        """
        Analyze quality of stretched audio.
        
        Args:
            original: Original audio samples
            stretched: Stretched audio samples
            
        Returns:
            Dictionary of quality metrics
        """
        return {
            'snr': self._compute_snr(original, stretched),
            'thd': self._compute_thd(stretched),
            'perceptual': self._compute_perceptual_quality(original, stretched)
        }
```

### Documentation

#### Types of Documentation

1. **API Documentation**: Docstrings and type hints
2. **User Guides**: How-to guides and tutorials
3. **Examples**: Code examples and use cases
4. **Architecture**: Internal design documentation

#### Documentation Standards

```python
def stretch_audio(
    input_path: str,
    output_path: str,
    ratio: float = 1.0,
    **kwargs: Any
) -> None:
    """
    Stretch audio file without changing pitch.
    
    This function provides a simple interface for audio time-stretching
    using the TDHS (Time-Domain Harmonic Scaling) algorithm. The duration
    of the audio is changed while preserving the original pitch and timbre.
    
    Args:
        input_path: Path to the input audio file. Supports various formats
            including WAV, MP3, FLAC, OGG via Pedalboard library.
        output_path: Path where the stretched audio will be saved. Format
            is determined by file extension.
        ratio: Stretch ratio. Values > 1.0 make audio slower (longer),
            values < 1.0 make audio faster (shorter). Default is 1.0 (no change).
        **kwargs: Additional parameters passed to the TDHS algorithm.
            See Parameters section for details.
    
    Raises:
        FileNotFoundError: If input file doesn't exist.
        ValueError: If ratio is invalid or other parameter errors.
        RuntimeError: If processing fails.
    
    Example:
        Basic usage:
        
        >>> stretch_audio("input.mp3", "output.wav", ratio=1.2)
        
        Advanced usage with parameters:
        
        >>> stretch_audio(
        ...     "speech.wav", 
        ...     "slow_speech.wav",
        ...     ratio=1.5,
        ...     upper_freq=300,
        ...     lower_freq=80
        ... )
    
    Note:
        For processing multiple files or advanced control, consider using
        the AudioStretch class directly.
    """
```

### Performance Improvements

#### Profiling

```python
# Example profiling script
import cProfile
import pstats
from audiostretchy.stretch import stretch_audio

def profile_stretching():
    """Profile audio stretching performance."""
    pr = cProfile.Profile()
    pr.enable()
    
    # Run the code to profile
    stretch_audio("large_test_file.wav", "output.wav", ratio=1.2)
    
    pr.disable()
    
    # Analyze results
    stats = pstats.Stats(pr)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # Top 20 functions

if __name__ == "__main__":
    profile_stretching()
```

#### Optimization Example

```python
# Before: Inefficient memory usage
def process_large_file(audio_data, ratio):
    """Process large audio file."""
    # Load entire file into memory
    processed = stretch_algorithm(audio_data, ratio)
    return processed

# After: Memory-efficient chunked processing
def process_large_file_chunked(audio_data, ratio, chunk_size=8192):
    """Process large audio file in chunks."""
    output_chunks = []
    
    for i in range(0, len(audio_data), chunk_size):
        chunk = audio_data[i:i + chunk_size]
        processed_chunk = stretch_algorithm(chunk, ratio)
        output_chunks.append(processed_chunk)
        
        # Free memory explicitly for very large files
        del chunk
    
    return np.concatenate(output_chunks)
```

## C Library Development

### When to Modify C Code

Consider C library changes for:

- **Performance improvements**
- **New algorithm features**
- **Bug fixes in core processing**
- **Platform compatibility**

### C Development Setup

#### Prerequisites

=== "Linux"

    ```bash
    sudo apt-get install build-essential
    gcc --version  # Verify installation
    ```

=== "macOS"

    ```bash
    xcode-select --install
    clang --version  # Verify installation
    ```

=== "Windows"

    Install Visual Studio Build Tools or Visual Studio Community with C++ support.

#### Building C Library

```bash
# Navigate to C library source
cd vendors/stretch

# Compile for your platform
gcc -shared -fPIC -O3 stretch.c -o _stretch.so  # Linux
clang -shared -O3 stretch.c -o _stretch.dylib   # macOS
cl /LD /O2 stretch.c /Fe:_stretch.dll           # Windows

# Copy to appropriate interface directory
cp _stretch.so ../../src/audiostretchy/interface/linux/
```

#### Testing C Changes

```python
# Test C library changes
from audiostretchy.interface.tdhs import TDHSAudioStretch

def test_c_library():
    """Test C library functionality."""
    processor = TDHSAudioStretch()
    
    # Test initialization
    context = processor.init(44100, 2, 1.2)
    assert context is not None
    
    # Test processing
    test_audio = np.random.randint(-32768, 32767, 1000, dtype=np.int16)
    result = processor.process(context, test_audio)
    
    assert len(result) > 0
    processor.cleanup(context)
```

## Release Process

### Version Management

AudioStretchy uses semantic versioning (SemVer):

- **Major** (X.0.0): Breaking changes
- **Minor** (0.X.0): New features (backward compatible)
- **Patch** (0.0.X): Bug fixes

### Creating a Release

```bash
# Ensure you're on main branch
git checkout main
git pull upstream main

# Run all tests
pytest
pre-commit run --all-files

# Build and test package
make build
make test

# Create release (maintainers only)
make release VERSION=1.3.0
```

### CI/CD Pipeline

The automated pipeline:

1. **Tests** on multiple Python versions and platforms
2. **Builds** wheels for all platforms
3. **Publishes** to PyPI on tag creation
4. **Updates** documentation

## Community Guidelines

### Code of Conduct

- Be respectful and inclusive
- Focus on constructive feedback
- Help newcomers get started
- Celebrate contributions of all sizes

### Getting Help

- **GitHub Issues**: Bug reports and feature requests
- **Discussions**: Questions and community help
- **Documentation**: Check existing docs first
- **Code Review**: Learn from feedback

### Recognition

Contributors are recognized through:

- **Contributors file**: Listed in CONTRIBUTORS.md
- **Release notes**: Mentioned in changelogs
- **GitHub**: Contributor statistics
- **Documentation**: Author attribution

## Advanced Topics

### Custom Algorithms

To implement alternative stretching algorithms:

```python
class CustomStretchAlgorithm:
    """Template for custom stretch algorithms."""
    
    def __init__(self):
        self.name = "custom_algorithm"
    
    def stretch(self, audio_data: np.ndarray, ratio: float) -> np.ndarray:
        """
        Implement your stretching algorithm here.
        
        Args:
            audio_data: Input audio samples
            ratio: Stretch ratio
            
        Returns:
            Stretched audio samples
        """
        # Your algorithm implementation
        pass
    
    def validate_parameters(self, **params) -> bool:
        """Validate algorithm-specific parameters."""
        pass
```

### Plugin System (Future)

Framework for extending AudioStretchy:

```python
# Future plugin interface
from audiostretchy.plugins import StretchPlugin

class PhaseVocoderPlugin(StretchPlugin):
    """Phase vocoder stretching plugin."""
    
    name = "phase_vocoder"
    supported_ratios = (0.1, 10.0)
    
    def stretch(self, audio_data, ratio, **params):
        """Phase vocoder implementation."""
        pass
```

### Real-time Processing (Future)

Considerations for real-time applications:

```python
class RealtimeAudioStretch:
    """Real-time audio stretching (future feature)."""
    
    def __init__(self, buffer_size=1024, latency_ms=50):
        self.buffer_size = buffer_size
        self.max_latency = latency_ms
        
    def process_chunk(self, audio_chunk):
        """Process audio in real-time chunks."""
        pass
```

## Questions?

If you have questions about contributing:

1. Check the [FAQ](09-api-reference.md#faq) in the API reference
2. Search [existing issues](https://github.com/twardoch/audiostretchy/issues)
3. Create a new [discussion](https://github.com/twardoch/audiostretchy/discussions)
4. Reach out to maintainers

Thank you for contributing to AudioStretchy! ğŸµ
</document_content>
</document>

<document index="45">
<source>src_docs/md/09-api-reference.md</source>
<document_content>
---
# this_file: src_docs/md/09-api-reference.md
title: API Reference
description: Complete API documentation with examples
---

# API Reference

Complete reference for all AudioStretchy classes, functions, and modules.

## Main Functions

### `stretch_audio()`

The primary convenience function for audio time-stretching.

```python
def stretch_audio(
    input_path: str,
    output_path: str,
    ratio: float = 1.0,
    gap_ratio: float = 0.0,
    upper_freq: int = 333,
    lower_freq: int = 55,
    buffer_ms: float = 25.0,
    threshold_gap_db: float = -40.0,
    double_range: bool = False,
    fast_detection: bool = False,
    normal_detection: bool = False,
    sample_rate: int = 0
) -> None
```

**Parameters:**

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `input_path` | str | - | Path to input audio file |
| `output_path` | str | - | Path for output audio file |
| `ratio` | float | 1.0 | Stretch ratio (>1.0 = slower, <1.0 = faster) |
| `gap_ratio` | float | 0.0 | Separate ratio for silence/gaps |
| `upper_freq` | int | 333 | Upper frequency limit for period detection (Hz) |
| `lower_freq` | int | 55 | Lower frequency limit for period detection (Hz) |
| `buffer_ms` | float | 25.0 | Buffer size in milliseconds |
| `threshold_gap_db` | float | -40.0 | Silence detection threshold (dB) |
| `double_range` | bool | False | Enable extended ratio range (0.25-4.0) |
| `fast_detection` | bool | False | Use faster detection algorithm |
| `normal_detection` | bool | False | Force normal detection algorithm |
| `sample_rate` | int | 0 | Target output sample rate (0 = preserve) |

**Raises:**

- `FileNotFoundError`: Input file doesn't exist
- `ValueError`: Invalid parameters  
- `RuntimeError`: Processing errors

**Example:**

```python
from audiostretchy.stretch import stretch_audio

# Basic usage
stretch_audio("input.mp3", "output.wav", ratio=1.2)

# Advanced usage
stretch_audio(
    "speech.wav",
    "slow_speech.wav", 
    ratio=1.5,
    upper_freq=300,
    lower_freq=80,
    normal_detection=True
)
```

## Core Classes

### `AudioStretch`

Main class for audio processing with fine-grained control.

```python
class AudioStretch:
    """
    Audio time-stretching processor using TDHS algorithm.
    
    Provides high-level interface for loading, processing, and saving
    audio files with time-stretching capabilities.
    """
```

#### Constructor

```python
def __init__(self) -> None
```

Creates a new AudioStretch instance.

**Example:**

```python
from audiostretchy.stretch import AudioStretch

processor = AudioStretch()
```

#### Methods

##### `open()`

```python
def open(
    self, 
    file: Union[str, Path, BinaryIO],
    format: Optional[str] = None
) -> None
```

Load an audio file for processing.

**Parameters:**

- `file`: File path (str/Path) or file-like object (BinaryIO)
- `format`: Audio format hint (e.g., "wav", "mp3") for file-like objects

**Raises:**

- `FileNotFoundError`: File doesn't exist
- `RuntimeError`: Cannot load audio file

**Examples:**

```python
# From file path
processor.open("audio.mp3")

# From file-like object
from io import BytesIO
with open("audio.wav", "rb") as f:
    data = BytesIO(f.read())
processor.open(data, format="wav")
```

##### `stretch()`

```python
def stretch(
    self,
    ratio: float = 1.0,
    gap_ratio: float = 0.0,
    upper_freq: int = 333,
    lower_freq: int = 55,
    buffer_ms: float = 25.0,
    threshold_gap_db: float = -40.0,
    double_range: bool = False,
    fast_detection: bool = False,
    normal_detection: bool = False
) -> None
```

Apply time-stretching to the loaded audio.

**Parameters:** Same as `stretch_audio()` function (except file paths)

**Raises:**

- `ValueError`: Invalid parameters or no audio loaded
- `RuntimeError`: Processing errors

**Example:**

```python
processor.open("input.wav")
processor.stretch(ratio=1.3, upper_freq=350)
```

##### `resample()`

```python
def resample(self, target_framerate: int) -> None
```

Resample the audio to a different sample rate.

**Parameters:**

- `target_framerate`: Target sample rate in Hz

**Raises:**

- `ValueError`: Invalid sample rate or no audio loaded
- `RuntimeError`: Resampling errors

**Example:**

```python
processor.resample(target_framerate=48000)
```

##### `save()`

```python
def save(
    self,
    file: Union[str, Path, BinaryIO],
    format: Optional[str] = None
) -> None
```

Save the processed audio to file.

**Parameters:**

- `file`: Output file path or file-like object
- `format`: Output format (inferred from extension if not specified)

**Raises:**

- `RuntimeError`: Save errors or no audio processed

**Examples:**

```python
# Save to file
processor.save("output.wav")

# Save to file-like object
from io import BytesIO
output_buffer = BytesIO()
processor.save(output_buffer, format="mp3")
```

#### Properties

##### `audio_file`

```python
@property
def audio_file(self) -> Optional[PedalboardAudioFile]
```

Access to the underlying Pedalboard audio file object.

##### `sample_rate`

```python
@property
def sample_rate(self) -> Optional[float]
```

Sample rate of the loaded audio file.

##### `channels`

```python
@property
def channels(self) -> Optional[int]
```

Number of audio channels.

#### Complete Example

```python
from audiostretchy.stretch import AudioStretch

# Initialize processor
processor = AudioStretch()

try:
    # Load audio
    processor.open("input.flac")
    print(f"Loaded: {processor.sample_rate} Hz, {processor.channels} channels")
    
    # Process with custom parameters
    processor.stretch(
        ratio=1.2,
        upper_freq=400,
        lower_freq=60,
        normal_detection=True
    )
    
    # Optional resampling
    processor.resample(target_framerate=44100)
    
    # Save result
    processor.save("output.wav")
    print("Processing complete!")
    
except Exception as e:
    print(f"Error: {e}")
```

## Interface Classes

### `TDHSAudioStretch`

Low-level interface to the TDHS C library.

```python
class TDHSAudioStretch:
    """
    Direct interface to TDHS C library.
    
    Low-level wrapper around the audio-stretch C library using ctypes.
    Most users should use AudioStretch class instead.
    """
```

#### Constructor

```python
def __init__(self) -> None
```

Initialize the TDHS wrapper and load platform-specific library.

**Raises:**

- `RuntimeError`: Platform not supported or library not found

#### Methods

##### `init()`

```python
def init(
    self,
    sample_rate: int,
    channels: int,
    ratio: float,
    **kwargs
) -> ctypes.c_void_p
```

Initialize TDHS processing context.

**Parameters:**

- `sample_rate`: Audio sample rate
- `channels`: Number of audio channels (1 or 2)
- `ratio`: Stretch ratio
- `**kwargs`: Additional TDHS parameters

**Returns:** Opaque context pointer

##### `process()`

```python
def process(
    self,
    context: ctypes.c_void_p,
    audio_data: np.ndarray
) -> np.ndarray
```

Process audio samples through TDHS algorithm.

**Parameters:**

- `context`: Context from `init()`
- `audio_data`: Int16 audio samples

**Returns:** Processed Int16 audio samples

##### `cleanup()`

```python
def cleanup(self, context: ctypes.c_void_p) -> None
```

Clean up processing context and free memory.

**Example:**

```python
from audiostretchy.interface.tdhs import TDHSAudioStretch
import numpy as np

# Low-level usage (advanced)
tdhs = TDHSAudioStretch()
context = tdhs.init(44100, 2, 1.2)

# Process audio chunk
audio_chunk = np.random.randint(-32768, 32767, 1000, dtype=np.int16)
processed = tdhs.process(context, audio_chunk)

# Clean up
tdhs.cleanup(context)
```

## Utility Functions

### File Format Support

AudioStretchy supports various audio formats through Pedalboard:

#### Supported Input Formats

- **Lossless**: WAV, FLAC, AIFF, BWF, RF64
- **Lossy**: MP3, OGG, M4A, AAC
- **Raw**: Raw audio with format specification

#### Supported Output Formats

Output format is determined by file extension:

```python
# Format examples
processor.save("output.wav")    # WAV
processor.save("output.mp3")    # MP3
processor.save("output.flac")   # FLAC
processor.save("output.ogg")    # OGG Vorbis
processor.save("output.m4a")    # AAC in M4A container
```

### Error Classes

#### `ParameterError`

```python
class ParameterError(ValueError):
    """Raised when invalid parameters are provided."""
    pass
```

#### `ProcessingError`

```python
class ProcessingError(RuntimeError):
    """Raised when audio processing fails."""
    pass
```

## Module Structure

### `audiostretchy.stretch`

Main module containing user-facing classes and functions.

**Exports:**
- `AudioStretch` class
- `stretch_audio()` function

### `audiostretchy.interface.tdhs`

Low-level TDHS C library interface.

**Exports:**
- `TDHSAudioStretch` class

### `audiostretchy.core`

Core utilities and re-exports.

**Exports:**
- Re-exports from other modules

## Command Line Interface

### CLI Function

The CLI is implemented using Python Fire:

```python
def main() -> None:
    """CLI entry point using Fire."""
    fire.Fire(stretch_audio)
```

### Usage

```bash
# Basic usage
audiostretchy input.wav output.wav --ratio 1.2

# All parameters
audiostretchy input.mp3 output.wav \
    --ratio 1.5 \
    --upper_freq 300 \
    --lower_freq 80 \
    --fast_detection True \
    --sample_rate 44100
```

### Help

```bash
# Get help
audiostretchy --help

# Parameter help
audiostretchy input.wav output.wav --help
```

## Type Hints

AudioStretchy provides comprehensive type hints:

```python
from typing import Union, Optional, BinaryIO
from pathlib import Path
import numpy as np

# Type aliases used throughout the codebase
AudioData = np.ndarray
FilePath = Union[str, Path]
FileOrPath = Union[FilePath, BinaryIO]
```

## Examples Collection

### Basic Processing

```python
# Simple time-stretching
stretch_audio("input.wav", "output.wav", ratio=1.2)
```

### Advanced Processing

```python
# High-quality speech processing
stretch_audio(
    "speech.wav",
    "processed.wav",
    ratio=1.4,
    upper_freq=300,
    lower_freq=80,
    normal_detection=True,
    gap_ratio=1.0
)
```

### Batch Processing

```python
from pathlib import Path

input_dir = Path("input_files")
output_dir = Path("output_files")
output_dir.mkdir(exist_ok=True)

for audio_file in input_dir.glob("*.wav"):
    output_file = output_dir / f"stretched_{audio_file.name}"
    stretch_audio(str(audio_file), str(output_file), ratio=1.3)
```

### Memory-Efficient Processing

```python
from io import BytesIO

# Process without intermediate files
with open("input.mp3", "rb") as f:
    input_data = BytesIO(f.read())

output_data = BytesIO()

processor = AudioStretch()
processor.open(input_data, format="mp3")
processor.stretch(ratio=1.2)
processor.save(output_data, format="wav")

# Get processed data
result = output_data.getvalue()
```

### Error Handling

```python
def safe_stretch(input_path, output_path, **params):
    """Stretch audio with comprehensive error handling."""
    try:
        stretch_audio(input_path, output_path, **params)
        return True
    except FileNotFoundError:
        print(f"Input file not found: {input_path}")
    except ValueError as e:
        print(f"Invalid parameters: {e}")
    except RuntimeError as e:
        print(f"Processing failed: {e}")
    except Exception as e:
        print(f"Unexpected error: {e}")
    return False
```

## Performance Notes

### Memory Usage

- **File Loading**: ~1x file size in memory
- **Processing**: ~2x audio size peak usage
- **Streaming**: Constant memory with chunked processing

### Processing Speed

Typical processing speeds (varies by hardware):

| Content Type | Speed Factor | Notes |
|--------------|--------------|-------|
| Speech | 5-10x real-time | Fast processing |
| Music | 3-8x real-time | Depends on complexity |
| Complex Audio | 2-5x real-time | Dense harmonic content |

### Optimization Tips

1. **Use `fast_detection=True`** for development/testing
2. **Lower `sample_rate`** for faster processing
3. **Smaller `buffer_ms`** reduces latency
4. **Chunked processing** for large files

## Frequently Asked Questions

### Q: What audio formats are supported?

A: AudioStretchy supports most common formats through Pedalboard: WAV, MP3, FLAC, OGG, M4A, AIFF. For compressed formats, FFmpeg must be installed.

### Q: Can I process very long audio files?

A: Yes, AudioStretchy handles large files efficiently. For extremely large files (>1GB), consider processing in chunks using the `AudioStretch` class.

### Q: How accurate is the stretching?

A: Duration accuracy is typically within 0.1% of the target ratio. Quality depends on content type and parameters.

### Q: Can I use this for real-time processing?

A: The current implementation is designed for file processing. Real-time capabilities are planned for future releases.

### Q: What's the difference between `fast_detection` and `normal_detection`?

A: `fast_detection=True` uses a faster algorithm with slightly lower quality. `normal_detection=True` forces high-quality processing. Default is automatic selection.

### Q: How do I choose the right frequency parameters?

A: Match the parameters to your content: speech (80-300 Hz), music (50-400 Hz), bass-heavy (30-450 Hz). See [Parameters Reference](07-parameters-reference.md) for details.

### Q: Can I stretch multiple files in parallel?

A: Yes, AudioStretchy is thread-safe. You can use `concurrent.futures` or similar for parallel processing.

### Q: What platforms are supported?

A: Windows (x64), macOS (x64, ARM64), and Linux (x64) are officially supported with pre-compiled binaries.

Next: Return to [Home](index.md) or explore [How It Works](05-how-it-works.md)
</document_content>
</document>

<document index="46">
<source>src_docs/md/index.md</source>
<document_content>
---
# this_file: src_docs/md/index.md
title: AudioStretchy Documentation
description: High-quality time-stretching of audio files without altering their pitch
---

# AudioStretchy Documentation

**AudioStretchy is a Python library and command-line interface (CLI) tool designed for high-quality time-stretching of audio files without altering their pitch.**

It leverages David Bryant's robust [audio-stretch C library](https://github.com/dbry/audio-stretch), which implements the Time-Domain Harmonic Scaling (TDHS) algorithm, particularly effective for speech. For versatile audio file handling (WAV, MP3, FLAC, OGG, etc.) and resampling, AudioStretchy integrates [Spotify's Pedalboard library](https://github.com/spotify/pedalboard).

## TL;DR

AudioStretchy provides high-quality audio time-stretching without pitch changes using the TDHS algorithm. Install with `pip install audiostretchy`, then use via CLI or Python API to stretch audio files while preserving natural sound quality.

## Table of Contents

### Getting Started
1. **[Installation](01-installation.md)** - How to install AudioStretchy and its dependencies
2. **[Quick Start](02-quick-start.md)** - Basic usage examples to get you up and running

### Usage Guides  
3. **[Command Line Interface](03-cli-usage.md)** - Complete CLI reference with examples
4. **[Python API](04-python-api.md)** - Programming interface for Python applications

### Technical Deep Dive
5. **[How It Works](05-how-it-works.md)** - Understanding the TDHS algorithm and processing pipeline
6. **[Core Architecture](06-core-architecture.md)** - Internal components and data flow
7. **[Parameters Reference](07-parameters-reference.md)** - Detailed parameter explanations and tuning

### Development
8. **[Contributing](08-contributing.md)** - Guidelines for contributing to the project
9. **[API Reference](09-api-reference.md)** - Complete API documentation with examples

## Key Features

- :material-music: **High-Quality Time Stretching** - TDHS algorithm preserves natural sound
- :material-file-music: **Wide Format Support** - WAV, MP3, FLAC, OGG, AIFF via Pedalboard
- :material-console-line: **Easy CLI Interface** - Simple command-line usage
- :material-language-python: **Python API** - Programmatic access for applications
- :material-laptop: **Cross-Platform** - Windows, macOS, and Linux support
- :material-tune: **Configurable Parameters** - Fine-tune stretching behavior

## Who Should Use This?

- **Musicians & Producers** - Adjust tempo without changing pitch
- **Audio Engineers** - Post-production timing adjustments  
- **Podcast/Video Editors** - Fit audio to specific durations
- **Developers** - Integrate time-stretching into applications
- **Researchers** - Explore audio processing techniques

## Quick Example

=== "Command Line"

    ```bash
    # Make audio 20% slower
    audiostretchy input.mp3 output.wav --ratio 1.2
    
    # Make audio 25% faster with custom parameters
    audiostretchy speech.wav faster.wav --ratio 0.75 --upper_freq 300
    ```

=== "Python"

    ```python
    from audiostretchy.stretch import stretch_audio
    
    # Simple stretching
    stretch_audio("input.mp3", "output.wav", ratio=1.2)
    
    # Advanced usage with class
    from audiostretchy.stretch import AudioStretch
    
    processor = AudioStretch()
    processor.open("input.flac")
    processor.stretch(ratio=0.8, upper_freq=350)
    processor.resample(target_framerate=48000)
    processor.save("output.wav")
    ```

## What Makes AudioStretchy Special?

Unlike simple playback speed changes that also alter pitch, AudioStretchy uses sophisticated algorithms to:

- **Preserve pitch** while changing duration
- **Maintain audio quality** through advanced signal processing
- **Handle various audio types** from speech to music
- **Provide fine control** over the stretching process

Ready to get started? Head to the [Installation](01-installation.md) guide!
</document_content>
</document>

<document index="47">
<source>src_docs/mkdocs.yml</source>
<document_content>
# this_file: src_docs/mkdocs.yml

site_name: AudioStretchy Documentation
site_description: High-quality time-stretching of audio files without altering their pitch
site_author: Adam Twardoch
site_url: https://twardoch.github.io/audiostretchy

repo_name: twardoch/audiostretchy
repo_url: https://github.com/twardoch/audiostretchy
edit_uri: edit/main/src_docs/md/

docs_dir: md
site_dir: ../docs

theme:
  name: material
  language: en
  features:
    - navigation.tabs
    - navigation.tabs.sticky
    - navigation.sections
    - navigation.expand
    - navigation.path
    - navigation.indexes
    - toc.follow
    - toc.integrate
    - search.suggest
    - search.highlight
    - search.share
    - content.code.copy
    - content.code.select
    - content.tabs.link
  palette:
    - scheme: default
      primary: deep purple
      accent: purple
      toggle:
        icon: material/brightness-7
        name: Switch to dark mode
    - scheme: slate
      primary: deep purple
      accent: purple
      toggle:
        icon: material/brightness-4
        name: Switch to light mode
  icon:
    repo: fontawesome/brands/github

plugins:
  - search:
      separator: '[\s\-,:!=\[\]()"`/]+|\.(?!\d)|&[lg]t;|(?!\b)(?=[A-Z][a-z])'
  - minify:
      minify_html: true

markdown_extensions:
  - abbr
  - admonition
  - attr_list
  - def_list
  - footnotes
  - md_in_html
  - toc:
      permalink: true
  - pymdownx.arithmatex:
      generic: true
  - pymdownx.betterem:
      smart_enable: all
  - pymdownx.caret
  - pymdownx.details
  - pymdownx.emoji:
      emoji_generator: !!python/name:material.extensions.emoji.to_svg
      emoji_index: !!python/name:material.extensions.emoji.twemoji
  - pymdownx.highlight:
      anchor_linenums: true
      line_spans: __span
      pygments_lang_class: true
  - pymdownx.inlinehilite
  - pymdownx.keys
  - pymdownx.magiclink:
      repo_url_shorthand: true
      user: twardoch
      repo: audiostretchy
  - pymdownx.mark
  - pymdownx.smartsymbols
  - pymdownx.superfences:
      custom_fences:
        - name: mermaid
          class: mermaid
          format: !!python/name:pymdownx.superfences.fence_code_format
  - pymdownx.tabbed:
      alternate_style: true
  - pymdownx.tasklist:
      custom_checkbox: true
  - pymdownx.tilde

nav:
  - Home: index.md
  - Getting Started:
    - Installation: 01-installation.md
    - Quick Start: 02-quick-start.md
  - Usage:
    - Command Line Interface: 03-cli-usage.md
    - Python API: 04-python-api.md
  - Technical Details:
    - How It Works: 05-how-it-works.md
    - Core Architecture: 06-core-architecture.md
    - Parameters Reference: 07-parameters-reference.md
  - Development:
    - Contributing: 08-contributing.md
    - API Reference: 09-api-reference.md

extra:
  social:
    - icon: fontawesome/brands/github
      link: https://github.com/twardoch/audiostretchy
    - icon: fontawesome/brands/python
      link: https://pypi.org/project/audiostretchy/

copyright: Copyright &copy; 2023-2024 Adam Twardoch
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/tests/conftest.py
# Language: python

import pytest
import tempfile
import shutil
from pathlib import Path
import soundfile as sf
import numpy as np

def temp_audio_dir(()):
    """Create a temporary directory for test audio files."""

def sample_audio_generator(()):
    """Generate sample audio data for testing."""

def generate_audio((
        duration_seconds=1.0, 
        sample_rate=44100, 
        channels=2, 
        frequency=440.0
    )):
    """Generate a sine wave audio sample."""

def generate_test_files((temp_audio_dir, sample_audio_generator)):
    """Generate test audio files in various formats."""

def audio_properties_checker(()):
    """Fixture to check audio file properties."""

def check_properties((file_path)):

def tolerance_checker(()):
    """Fixture for checking numeric tolerances in tests."""

def check_tolerance((actual, expected, tolerance_percent=5)):
    """Check if actual value is within tolerance_percent of expected."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/tests/test_cli.py
# Language: python

import pytest
import subprocess
import sys
from pathlib import Path
import soundfile as sf
import soundfile as sf

def test_cli_help(()):
    """Test that the CLI shows help information."""

def test_cli_version(()):
    """Test that the CLI can show version information."""

def test_cli_stretch_audio((generate_test_files, tmp_path)):
    """Test the CLI with actual audio files."""

def test_cli_with_all_parameters((generate_test_files, tmp_path)):
    """Test CLI with various parameters."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/tests/test_core.py
# Language: python

import numpy as np
import pytest
from pathlib import Path
from audiostretchy.core import AudioStretch, stretch_audio

class TestAudioStretch:
    """Test cases for AudioStretch class."""
    def test_init((self)):
        """Test AudioStretch initialization."""
    def test_open_missing_input((self)):
        """Test error handling for missing input."""
    def test_save_no_data((self)):
        """Test error handling when saving without data."""
    def test_stretch_no_data((self)):
        """Test error handling when stretching without data."""
    def test_stretch_invalid_ratio((self)):
        """Test error handling for invalid stretch ratio."""
    def test_stretch_no_change((self)):
        """Test that stretch with ratio 1.0 doesn't change audio."""
    def test_resample_no_data((self)):
        """Test error handling when resampling without data."""
    def test_resample_no_change((self)):
        """Test that resampling to same rate doesn't change audio."""
    def test_convert_to_int16_mono((self)):
        """Test float32 to int16 conversion for mono audio."""
    def test_convert_to_int16_stereo((self)):
        """Test float32 to int16 conversion for stereo audio."""
    def test_convert_from_int16_mono((self)):
        """Test int16 to float32 conversion for mono audio."""
    def test_convert_from_int16_stereo((self)):
        """Test int16 to float32 conversion for stereo audio."""
    def test_unsupported_channels((self)):
        """Test error handling for unsupported channel counts."""

def test_init((self)):
    """Test AudioStretch initialization."""

def test_open_missing_input((self)):
    """Test error handling for missing input."""

def test_save_no_data((self)):
    """Test error handling when saving without data."""

def test_stretch_no_data((self)):
    """Test error handling when stretching without data."""

def test_stretch_invalid_ratio((self)):
    """Test error handling for invalid stretch ratio."""

def test_stretch_no_change((self)):
    """Test that stretch with ratio 1.0 doesn't change audio."""

def test_resample_no_data((self)):
    """Test error handling when resampling without data."""

def test_resample_no_change((self)):
    """Test that resampling to same rate doesn't change audio."""

def test_convert_to_int16_mono((self)):
    """Test float32 to int16 conversion for mono audio."""

def test_convert_to_int16_stereo((self)):
    """Test float32 to int16 conversion for stereo audio."""

def test_convert_from_int16_mono((self)):
    """Test int16 to float32 conversion for mono audio."""

def test_convert_from_int16_stereo((self)):
    """Test int16 to float32 conversion for stereo audio."""

def test_unsupported_channels((self)):
    """Test error handling for unsupported channel counts."""

def test_stretch_audio_function(()):
    """Test the stretch_audio convenience function."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/tests/test_mono_audio.py
# Language: python

import pytest
import numpy as np
from pathlib import Path
from audiostretchy.stretch import AudioStretch, stretch_audio
import soundfile as sf

def test_mono_audio_stretch((generate_test_files, audio_properties_checker, tolerance_checker)):
    """Test stretching mono audio files."""

def test_stereo_audio_stretch((generate_test_files, audio_properties_checker, tolerance_checker)):
    """Test stretching stereo audio files."""

def test_gapped_audio_stretch((generate_test_files, audio_properties_checker, tolerance_checker)):
    """Test stretching audio with silence gaps."""

def test_mono_to_stereo_conversion((generate_test_files, tmp_path)):
    """Test processing mono audio and ensuring output format is preserved."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/tests/test_performance.py
# Language: python

import pytest
import time
import numpy as np
from pathlib import Path
from audiostretchy.stretch import AudioStretch, stretch_audio

def test_stretch_performance_benchmark((generate_test_files)):
    """Benchmark stretching performance."""

def test_resample_performance_benchmark((generate_test_files)):
    """Benchmark resampling performance."""

def test_complete_pipeline_performance((generate_test_files, tmp_path)):
    """Benchmark complete pipeline performance."""

def test_memory_usage_stability((generate_test_files)):
    """Test that multiple operations don't cause memory leaks."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/audiostretchy/tests/test_stretch.py
# Language: python

import pytest
from pathlib import Path
import numpy as np
import soundfile
from audiostretchy.stretch import AudioStretch, stretch_audio
import io
import io
from pedalboard.io import AudioFile as PedalboardAudioFile_local

def get_audio_properties((file_path)):

def audio_processor(()):

def sample_wav_path(()):

def sample_mp3_path(()):

def test_open_wav((audio_processor, sample_wav_path)):

def test_open_mp3((audio_processor, sample_mp3_path)):

def test_save_wav((audio_processor, sample_wav_path, tmp_path)):

def test_save_mp3((audio_processor, sample_wav_path, tmp_path)):

def test_resample((audio_processor, sample_wav_path)):

def test_resample_noop((audio_processor, sample_wav_path)):
    """Test that resampling to the same sample rate is a no-op."""

def test_stretch_no_change((audio_processor, sample_wav_path)):

def test_stretch_longer((audio_processor, sample_wav_path)):

def test_stretch_shorter((audio_processor, sample_wav_path)):

def test_stretch_various_params((
    audio_processor, sample_wav_path, ratio_val, fast_detection_val, double_range_val
)):
    """Test stretching with various TDHS parameters."""

def test_stretch_double_range_extreme((audio_processor, sample_wav_path)):
    """Test stretching with double_range for ratios like 0.25 and 4.0."""

def test_stretch_with_gap_ratio((audio_processor, sample_wav_path)):
    """ Tests that providing gap_ratio doesn't crash...."""

def test_open_wav_filelike((audio_processor, sample_wav_path)):

def test_save_wav_filelike((audio_processor, sample_wav_path, tmp_path)):

def test_stretch_audio_func_wav_to_wav((sample_wav_path, tmp_path)):

def test_stretch_audio_func_mp3_to_mp3((sample_mp3_path, tmp_path)):

def test_stretch_audio_func_resample((sample_wav_path, tmp_path)):

def test_stretch_audio_func_stretch_and_resample((sample_wav_path, tmp_path)):


<document index="48">
<source>vendors/stretch/.git</source>
<document_content>
gitdir: ../../.git/modules/vendors/stretch

</document_content>
</document>

<document index="49">
<source>vendors/stretch/.gitignore</source>
<document_content>
output
audio-stretch
samples/*.wav


</document_content>
</document>

<document index="50">
<source>vendors/stretch/README</source>
<document_content>
////////////////////////////////////////////////////////////////////////////
//                        **** AUDIO-STRETCH ****                         //
//                      Time Domain Harmonic Scaler                       //
//                    Copyright (c) 2022 David Bryant                     //
//                          All Rights Reserved.                          //
//      Distributed under the BSD Software License (see license.txt)      //
////////////////////////////////////////////////////////////////////////////

From Wikipedia, the free encyclopedia:

    Time-domain harmonic scaling (TDHS) is a method for time-scale
    modification of speech (or other audio signals), allowing the apparent
    rate of speech articulation to be changed without affecting the
    pitch-contour and the time-evolution of the formant structure. TDHS
    differs from other time-scale modification algorithms in that
    time-scaling operations are performed in the time domain (not the
    frequency domain).

This project is an implementation of a TDHS library and a command-line demo
program to utilize it with standard WAV files. The command-line program
also incorporates silence detection so that can be handled differently.

There are two effects possible with TDHS and the audio-stretch demo. The
first is the more obvious mentioned above of changing the duration (or
speed) of a speech (or other audio) sample without modifying its pitch.
The other effect is similar, but after applying the duration change we
change the sampling rate in a complimentary manner to restore the original
duration and timing, which then results in the pitch being altered.

So when a ratio is supplied to the audio-stretch program, the default
operation is for the total duration of the audio file to be scaled by
exactly that ratio (0.5X to 2.0X), with the pitches remaining constant.
If the option to scale the sample-rate proportionally is specified (-s)
then the total duration and timing of the audio file will be preserved,
but the pitches will be scaled by the specified ratio instead. This is
useful for creating a "helium voice" effect and lots of other fun stuff.

Note that unless ratios of exactly 0.5 or 2.0 are used with the -s option,
non-standard sampling rates will probably result. Many programs will still
properly play these files, and audio editing programs will likely import
them correctly (by resampling), but it is possible that some applications
will barf on them. They can also be resampled to a standard rate using
an audio resampling tool I wrote that's also available here on GitHub:

https://github.com/dbry/audio-resampler

There's an option to cycle through the full possible ratio range in a
sinusoidal pattern, starting at 1.0, and either going up (-c) or down
(-cc) first. In this case any specified ratio is ignored (except if the
-s option is also specified to scale the sampling rate). The total period
is fixed at 2Ï€ seconds, at which point the output will again be exactly
aligned with the input.

                *** Version 0.4 Enhancements ***

For version 0.4 two useful features were added. First, the ability to
cascade two instances of the stretcher was added. This is enabled by
including the flag STRETCH_DUAL_FLAG when initializing the stretcher
and allows double the stretch ratio of the regular code (i.e., now 0.25X
to 4.00X). Note that the audio quality degrades some when slowed beyond
2X, and generally voice becomes unintelligible when sped faster than 2X,
however these values may still be useful for some applications, and
specifically the very high speed values are useful for silence gaps
(see the next feature).

The other feature added is the ability to detect silence gaps in the
audio and apply a different (likely lower) stretch ratio to these areas.
This is currently not performed in the library itself, but in the demo
command-line program where it is highly configurable, but it should be
relatively easy to copy the functionality into another application. If
I get requests for it, I will consider moving it into the library.

There is a script to build the demo app on Linux (build.sh), and this also
allows building the app to test for UB (undefined behavior) and ASAN (bad
addressing). Also, some artificial test signals (both mono and stereo) and
a script (test.sh) for running them at various ratios has been added.

The current "help" display from the demo app:

 AUDIO-STRETCH  Time Domain Harmonic Scaling Demo  Version 0.4
 Copyright (c) 2022 David Bryant. All Rights Reserved.

 Usage:     AUDIO-STRETCH [-options] infile.wav outfile.wav

 Options:  -r<n.n> = stretch ratio (0.25 to 4.0, default = 1.0)
           -g<n.n> = gap/silence stretch ratio (if different)
           -u<n>   = upper freq period limit (default = 333 Hz)
           -l<n>   = lower freq period limit (default = 55 Hz)
           -b<n>   = audio buffer/window length (ms, default = 25)
           -t<n>   = gap/silence threshold (dB re FS, default = -40)
           -c      = cycle through all ratios, starting higher
           -cc     = cycle through all ratios, starting lower
           -d      = force dual instance even for shallow ratios
           -s      = scale rate to preserve duration (not pitch)
           -f      = fast pitch detection (default >= 32 kHz)
           -n      = normal pitch detection (default < 32 kHz)
           -q      = quiet mode (display errors only)
           -v      = verbose (display lots of info)
           -y      = overwrite outfile if it exists

 Web:      Visit www.github.com/dbry/audio-stretch for latest version

Notes:

1. The program will handle only mono or stereo files in the WAV format. In
   case of stereo, the two channels shouldn't be independent. The
   audio must be 16-bit PCM and the acceptable sampling rates are from 8,000
   to 48,000 Hz. Any additional RIFF info in the WAV file will be discarded.
   The command-line program is only for little-endian architectures.

2. For stereo files, the pitch detection is done on a mono conversion of the
   audio, but the scaling transformation is done on the independent channels.
   If it is desired to have completely independent processing this can only
   be done with two mono files. Note that this is not a limitation of the
   library but of the demo utility (the library has no problem with multiple
   contexts).

3. This technique (TDHS) is ideal for speech signals, but can also be used
   for homophonic musical instruments. As the sound becomes increasingly
   polyphonic, however, the quality and effectiveness will decrease. Also,
   the period frequency limits provided by default are optimized for speech;
   adjusting these may be required for best quality with non-speech audio.

4. The vast majority of the time required for TDHS is in the pitch detection,
   and so this library implements two versions. The first is the standard
   one that includes every sample and pitch period, and the second is an
   optimized one that uses pairs of samples and only even pitch periods.
   This second version is about 4X faster than the standard version, but
   provides virtually the same quality. It is used by default for files with
   sample rates of 32 kHz or higher, but its use can be forced on or off
   from the command-line (see options above).

</document_content>
</document>

<document index="51">
<source>vendors/stretch/build.sh</source>
<document_content>
#!/bin/bash

if [ -z "$1" ] || [ "$1" = "rel" ]; then
  echo "building release .."
  gcc -Ofast main.c stretch.c -lm -o audio-stretch
elif [ "$1" = "dbg" ]; then
  echo "building debug .."
  gcc -O0 -g main.c stretch.c -lm -o audio-stretch
elif [ "$1" = "ubsan" ]; then
  echo "building debug with undefined behaviour sanitizer .."
  gcc -O0 -g main.c stretch.c -fsanitize=undefined -lm -o audio-stretch
elif [ "$1" = "asan" ]; then
  echo "building debug with address sanitizer .."
  gcc -O0 -g main.c stretch.c -fsanitize=address -lm -o audio-stretch
else
  echo "error: unknown option '$1'"
fi


</document_content>
</document>

<document index="52">
<source>vendors/stretch/license.txt</source>
<document_content>
                       Copyright (c) David Bryant
                          All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

    * Redistributions of source code must retain the above copyright notice,
      this list of conditions and the following disclaimer.
    * Redistributions in binary form must reproduce the above copyright notice,
      this list of conditions and the following disclaimer in the
      documentation and/or other materials provided with the distribution.
    * Neither the name of Conifer Software nor the names of its contributors
      may be used to endorse or promote products derived from this software
      without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

</document_content>
</document>

<document index="53">
<source>vendors/stretch/main.c</source>
<document_content>
////////////////////////////////////////////////////////////////////////////
//                        **** AUDIO-STRETCH ****                         //
//                      Time Domain Harmonic Scaler                       //
//                    Copyright (c) 2022 David Bryant                     //
//                          All Rights Reserved.                          //
//      Distributed under the BSD Software License (see license.txt)      //
////////////////////////////////////////////////////////////////////////////

// main.c

// This module provides a demo for the TDHS library using WAV files.

#include <stdlib.h>
#include <stdint.h>
#include <string.h>
#include <stdio.h>
#include <math.h>

#include "stretch.h"

#define SILENCE_THRESHOLD_DB    -40
#define AUDIO_WINDOW_MS         25

static const char *sign_on = "\n"
" AUDIO-STRETCH  Time Domain Harmonic Scaling Demo  Version 0.4\n"
" Copyright (c) 2022 David Bryant. All Rights Reserved.\n\n";

static const char *usage =
" Usage:     AUDIO-STRETCH [-options] infile.wav outfile.wav\n\n"
" Options:  -r<n.n> = stretch ratio (0.25 to 4.0, default = 1.0)\n"
"           -g<n.n> = gap/silence stretch ratio (if different)\n"
"           -u<n>   = upper freq period limit (default = 333 Hz)\n"
"           -l<n>   = lower freq period limit (default = 55 Hz)\n"
"           -b<n>   = audio buffer/window length (ms, default = 25)\n"
"           -t<n>   = gap/silence threshold (dB re FS, default = -40)\n"
"           -c      = cycle through all ratios, starting higher\n"
"           -cc     = cycle through all ratios, starting lower\n"
"           -d      = force dual instance even for shallow ratios\n"
"           -s      = scale rate to preserve duration (not pitch)\n"
"           -f      = fast pitch detection (default >= 32 kHz)\n"
"           -n      = normal pitch detection (default < 32 kHz)\n"
"           -q      = quiet mode (display errors only)\n"
"           -v      = verbose (display lots of info)\n"
"           -y      = overwrite outfile if it exists\n\n"
" Web:      Visit www.github.com/dbry/audio-stretch for latest version\n\n";

typedef struct {
    char ckID [4];
    uint32_t ckSize;
    char formType [4];
} RiffChunkHeader;

typedef struct {
    char ckID [4];
    uint32_t ckSize;
} ChunkHeader;

typedef struct {
    uint16_t FormatTag, NumChannels;
    uint32_t SampleRate, BytesPerSecond;
    uint16_t BlockAlign, BitsPerSample;
    uint16_t cbSize;
    union {
        uint16_t ValidBitsPerSample;
        uint16_t SamplesPerBlock;
        uint16_t Reserved;
    } Samples;
    int32_t ChannelMask;
    uint16_t SubFormat;
    char GUID [14];
} WaveHeader;

#define WAVE_FORMAT_PCM         0x1
#define WAVE_FORMAT_EXTENSIBLE  0xfffe

static int write_pcm_wav_header (FILE *outfile, uint32_t num_samples, int num_channels, int bytes_per_sample, uint32_t sample_rate);
double rms_level_dB (int16_t *audio, int samples, int channels);

static int verbose_mode, quiet_mode;

int main (argc, argv) int argc; char **argv;
{
    int asked_help = 0, overwrite = 0, scale_rate = 0, force_fast = 0, force_normal = 0, force_dual = 0, cycle_ratio = 0;
    float ratio = 1.0, silence_ratio = 0.0, silence_threshold_dB = SILENCE_THRESHOLD_DB;
    uint32_t samples_to_process, insamples = 0, outsamples = 0;
    int upper_frequency = 333, lower_frequency = 55;
    char *infilename = NULL, *outfilename = NULL;
    int audio_window_ms = AUDIO_WINDOW_MS;
    RiffChunkHeader riff_chunk_header;
    WaveHeader WaveHeader = { 0 };
    ChunkHeader chunk_header;
    StretchHandle stretcher;
    FILE *infile, *outfile;

    // loop through command-line arguments

    while (--argc) {
#ifdef _WIN32
        if ((**++argv == '-' || **argv == '/') && (*argv)[1])
#else
        if ((**++argv == '-') && (*argv)[1])
#endif
            while (*++*argv)
                switch (**argv) {

                    case 'U': case 'u':
                        upper_frequency = strtol (++*argv, argv, 10);

                        if (upper_frequency <= 40) {
                            fprintf (stderr, "\nupper frequency must be at least 40 Hz!\n");
                            return -1;
                        }

                        --*argv;
                        break;

                    case 'L': case 'l':
                        lower_frequency = strtol (++*argv, argv, 10);

                        if (lower_frequency < 20) {
                            fprintf (stderr, "\nlower frequency must be at least 20 Hz!\n");
                            return -1;
                        }

                        --*argv;
                        break;

                    case 'B': case 'b':
                        audio_window_ms = strtol (++*argv, argv, 10);

                        if (audio_window_ms < 1 || audio_window_ms > 100) {
                            fprintf (stderr, "\naudio window is from 1 to 100 ms!\n");
                            return -1;
                        }

                        --*argv;
                        break;

                    case 'R': case 'r':
                        ratio = strtod (++*argv, argv);

                        if (ratio < 0.25 || ratio > 4.0) {
                            fprintf (stderr, "\nratio must be from 0.25 to 4.0!\n");
                            return -1;
                        }

                        --*argv;
                        break;

                    case 'G': case 'g':
                        silence_ratio = strtod (++*argv, argv);

                        if (silence_ratio < 0.25 || silence_ratio > 4.0) {
                            fprintf (stderr, "\ngap/silence ratio must be from 0.25 to 4.0!\n");
                            return -1;
                        }

                        --*argv;
                        break;

                    case 'T': case 't':
                        silence_threshold_dB = strtod (++*argv, argv);

                        if (silence_threshold_dB < -70 || silence_threshold_dB > -10) {
                            fprintf (stderr, "\nsilence threshold must be from -10 to -70 dB!\n");
                            return -1;
                        }

                        --*argv;
                        break;

                    case 'S': case 's':
                        scale_rate = 1;
                        break;

                    case 'C': case 'c':
                        cycle_ratio++;
                        break;

                    case 'D': case 'd':
                        force_dual = 1;
                        break;

                    case 'F': case 'f':
                        force_fast = 1;
                        break;

                    case 'N': case 'n':
                        force_normal = 1;
                        break;

                    case 'H': case 'h':
                        asked_help = 1;
                        break;

                    case 'V': case 'v':
                        verbose_mode = 1;
                        break;

                    case 'Q': case 'q':
                        quiet_mode = 1;
                        break;

                    case 'Y': case 'y':
                        overwrite = 1;
                        break;

                    default:
                        fprintf (stderr, "\nillegal option: %c !\n", **argv);
                        return -1;
                }
        else if (!infilename)
            infilename = *argv;
        else if (!outfilename)
            outfilename = *argv;
        else {
            fprintf (stderr, "\nextra unknown argument: %s !\n", *argv);
            return -1;
        }
    }

    if (!quiet_mode)
        fprintf (stderr, "%s", sign_on);

    if (!outfilename || asked_help) {
        printf ("%s", usage);
        return 0;
    }

    if (!strcmp (infilename, outfilename)) {
        fprintf (stderr, "can't overwrite input file (specify different/new output file name)\n");
        return -1;
    }

    if (!overwrite && (outfile = fopen (outfilename, "r"))) {
        fclose (outfile);
        fprintf (stderr, "output file \"%s\" exists (use -y to overwrite)\n", outfilename);
        return -1;
    }

    if (!(infile = fopen (infilename, "rb"))) {
        fprintf (stderr, "can't open file \"%s\" for reading!\n", infilename);
        return 1;
    }

    // read initial RIFF form header

    if (!fread (&riff_chunk_header, sizeof (RiffChunkHeader), 1, infile) ||
        strncmp (riff_chunk_header.ckID, "RIFF", 4) ||
        strncmp (riff_chunk_header.formType, "WAVE", 4)) {
            fprintf (stderr, "\"%s\" is not a valid .WAV file!\n", infilename);
            return 1;
    }

    // loop through all elements of the RIFF wav header (until the data chuck)

    while (1) {
        if (!fread (&chunk_header, sizeof (ChunkHeader), 1, infile)) {
            fprintf (stderr, "\"%s\" is not a valid .WAV file!\n", infilename);
            return 1;
        }

        // if it's the format chunk, we want to get some info out of there and
        // make sure it's a .wav file we can handle

        if (!strncmp (chunk_header.ckID, "fmt ", 4)) {
            int format, bits_per_sample;

            if (chunk_header.ckSize < 16 || chunk_header.ckSize > sizeof (WaveHeader) ||
                !fread (&WaveHeader, chunk_header.ckSize, 1, infile)) {
                    fprintf (stderr, "\"%s\" is not a valid .WAV file!\n", infilename);
                    return 1;
            }

            format = (WaveHeader.FormatTag == WAVE_FORMAT_EXTENSIBLE && chunk_header.ckSize == 40) ?
                WaveHeader.SubFormat : WaveHeader.FormatTag;

            bits_per_sample = (chunk_header.ckSize == 40 && WaveHeader.Samples.ValidBitsPerSample) ?
                WaveHeader.Samples.ValidBitsPerSample : WaveHeader.BitsPerSample;

            if (bits_per_sample != 16) {
                fprintf (stderr, "\"%s\" is not a 16-bit .WAV file!\n", infilename);
                return 1;
            }

            if (WaveHeader.NumChannels < 1 || WaveHeader.NumChannels > 2) {
                fprintf (stderr, "\"%s\" is not a mono or stereo .WAV file!\n", infilename);
                return 1;
            }

            if (WaveHeader.BlockAlign != WaveHeader.NumChannels * 2) {
                fprintf (stderr, "\"%s\" is not a valid .WAV file!\n", infilename);
                return 1;
            }

            if (format == WAVE_FORMAT_PCM) {
                if (WaveHeader.SampleRate < 8000 || WaveHeader.SampleRate > 48000) {
                    fprintf (stderr, "\"%s\" sample rate is %lu, must be 8000 to 48000!\n", infilename, (unsigned long) WaveHeader.SampleRate);
                    return 1;
                }
            }
            else {
                fprintf (stderr, "\"%s\" is not a PCM .WAV file!\n", infilename);
                return 1;
            }
        }
        else if (!strncmp (chunk_header.ckID, "data", 4)) {

            // on the data chunk, get size and exit parsing loop

            if (!WaveHeader.SampleRate) {      // make sure we saw a "fmt" chunk...
                fprintf (stderr, "\"%s\" is not a valid .WAV file!\n", infilename);
                return 1;
            }

            if (!chunk_header.ckSize) {
                fprintf (stderr, "this .WAV file has no audio samples, probably is corrupt!\n");
                return 1;
            }

            if (chunk_header.ckSize % WaveHeader.BlockAlign) {
                fprintf (stderr, "\"%s\" is not a valid .WAV file!\n", infilename);
                return 1;
            }

            samples_to_process = chunk_header.ckSize / WaveHeader.BlockAlign;

            if (!samples_to_process) {
                fprintf (stderr, "this .WAV file has no audio samples, probably is corrupt!\n");
                return 1;
            }

            break;
        }
        else {          // just ignore unknown chunks
            uint32_t bytes_to_eat = (chunk_header.ckSize + 1) & ~1L;
            char dummy;

            while (bytes_to_eat--)
                if (!fread (&dummy, 1, 1, infile)) {
                    fprintf (stderr, "\"%s\" is not a valid .WAV file!\n", infilename);
                    return 1;
                }
        }
    }

    if (upper_frequency < lower_frequency * 2 || upper_frequency >= WaveHeader.SampleRate / 2) {
        fprintf (stderr, "invalid frequencies specified!\n");
        fclose (infile);
        return 1;
    }

    int flags = 0, silence_mode = silence_ratio && !cycle_ratio && silence_ratio != ratio;
    int buffer_samples = WaveHeader.SampleRate * (audio_window_ms / 1000.0);
    int min_period = WaveHeader.SampleRate / upper_frequency;
    int max_period = WaveHeader.SampleRate / lower_frequency;
    float max_ratio = ratio;

    if (force_dual || ratio < 0.5 || ratio > 2.0 ||
        (silence_mode && (silence_ratio < 0.5 || silence_ratio > 2.0)))
            flags |= STRETCH_DUAL_FLAG;

    if ((force_fast || WaveHeader.SampleRate >= 32000) && !force_normal)
        flags |= STRETCH_FAST_FLAG;

    if (verbose_mode) {
        fprintf (stderr, "file sample rate is %lu Hz (%s), buffer size is %d samples\n",
            (unsigned long) WaveHeader.SampleRate, WaveHeader.NumChannels == 2 ? "stereo" : "mono", buffer_samples);
        fprintf (stderr, "stretch period range = %d to %d, %d channels, %s, %s\n",
            min_period, max_period, WaveHeader.NumChannels, (flags & STRETCH_FAST_FLAG) ? "fast mode" : "normal mode",
            (flags & STRETCH_DUAL_FLAG) ? "dual instance" : "single instance");
    }

    if (!quiet_mode && ratio == 1.0 && !silence_mode && !cycle_ratio)
        fprintf (stderr, "warning: a ratio of 1.0 will do nothing but copy the WAV file!\n");

    if (!quiet_mode && ratio != 1.0 && cycle_ratio && !scale_rate)
        fprintf (stderr, "warning: specifying ratio with cycling doesn't do anything (unless scaling rate)\n");

    stretcher = stretch_init (min_period, max_period, WaveHeader.NumChannels, flags);

    if (!stretcher) {
        fprintf (stderr, "can't initialize stretcher\n");
        fclose (infile);
        return 1;
    }

    if (!(outfile = fopen (outfilename, "wb"))) {
        fprintf (stderr, "can't open file \"%s\" for writing!\n", outfilename);
        fclose (infile);
        return 1;
    }

    uint32_t scaled_rate = scale_rate ? (uint32_t)(WaveHeader.SampleRate * ratio + 0.5) : WaveHeader.SampleRate;
    write_pcm_wav_header (outfile, 0, WaveHeader.NumChannels, 2, scaled_rate);

    if (cycle_ratio)
        max_ratio = (flags & STRETCH_DUAL_FLAG) ? 4.0 : 2.0;
    else if (silence_mode && silence_ratio > max_ratio)
        max_ratio = silence_ratio;

    int max_expected_samples = stretch_output_capacity (stretcher, buffer_samples, max_ratio);
    int16_t *inbuffer = malloc (buffer_samples * WaveHeader.BlockAlign), *prebuffer = NULL;
    int16_t *outbuffer = malloc (max_expected_samples * WaveHeader.BlockAlign);
    int non_silence_frames = 0, silence_frames = 0, used_silence_frames = 0;
    int max_generated_stretch = 0, max_generated_flush = 0;
    int samples_to_stretch = 0, consecutive_silence_frames = 1;

    /* in the gap/silence mode we need an additional buffer to scan the "next" buffer for level */

    if (silence_mode)
        prebuffer = malloc (buffer_samples * WaveHeader.BlockAlign);

    if (!inbuffer || !outbuffer || (silence_mode && !prebuffer)) {
        fprintf (stderr, "can't allocate required memory!\n");
        fclose (infile);
        return 1;
    }

    /* read the entire file in frames and process with stretch */

    while (1) {
        int samples_read = fread (silence_mode ? prebuffer : inbuffer, WaveHeader.BlockAlign,
            samples_to_process >= buffer_samples ? buffer_samples : samples_to_process, infile);

        if (!silence_mode && !samples_read)
            break;

        insamples += samples_read;
        samples_to_process -= samples_read;

        /* this is where we scan the frame we just read to see if it's below the silence threshold */

        if (silence_mode) {
            if (samples_read) {
                double level = rms_level_dB (prebuffer, samples_read, WaveHeader.NumChannels);

                if (level > silence_threshold_dB) {
                    consecutive_silence_frames = 0;
                    non_silence_frames++;
                }
                else {
                    consecutive_silence_frames++;
                    silence_frames++;
                }
            }
        }
        else
            samples_to_stretch = samples_read;

        if (cycle_ratio) {
            if (flags & STRETCH_DUAL_FLAG)
                ratio = (sin ((double) outsamples / WaveHeader.SampleRate / 2.0) * (cycle_ratio & 1 ? 1.875 : -1.875)) + 2.125;
            else
                ratio = (sin ((double) outsamples / WaveHeader.SampleRate) * (cycle_ratio & 1 ? 0.75 : -0.75)) + 1.25;
        }

        if (samples_to_stretch) {
            int samples_generated;

            /* we use the gap/silence stretch ratio if the current frame, and the ones on either side, measure below the threshold */

            if (consecutive_silence_frames >= 3) {
                samples_generated = stretch_samples (stretcher, inbuffer, samples_to_stretch, outbuffer, silence_ratio);
                used_silence_frames++;
            }
            else
                samples_generated = stretch_samples (stretcher, inbuffer, samples_to_stretch, outbuffer, ratio);

            if (samples_generated) {
                if (samples_generated > max_generated_stretch)
                    max_generated_stretch = samples_generated;

                fwrite (outbuffer, WaveHeader.BlockAlign, samples_generated, outfile);
                outsamples += samples_generated;

                if (samples_generated > max_expected_samples) {
                    fprintf (stderr, "stretch: generated samples (%d) exceeded expected (%d)!\n", samples_generated, max_expected_samples);
                    fclose (infile);
                    return 1;
                }
            }
        }

        if (silence_mode) {
            if (samples_read) {
                memcpy (inbuffer, prebuffer, samples_read * WaveHeader.BlockAlign);
                samples_to_stretch = samples_read;
            }
            else
                break;
        }
    }

    /* next call the stretch flush function until it returns zero */

    while (1) {
        int samples_flushed = stretch_flush (stretcher, outbuffer);

        if (!samples_flushed)
            break;

        if (samples_flushed > max_generated_flush)
            max_generated_flush = samples_flushed;

        fwrite (outbuffer, WaveHeader.BlockAlign, samples_flushed, outfile);
        outsamples += samples_flushed;

        if (samples_flushed > max_expected_samples) {
            fprintf (stderr, "flush: generated samples (%d) exceeded expected (%d)!\n", samples_flushed, max_expected_samples);
            fclose (infile);
            return 1;
        }
    }

    free (inbuffer);
    free (outbuffer);
    free (prebuffer);
    stretch_deinit (stretcher);

    fclose (infile);

    rewind (outfile);
    write_pcm_wav_header (outfile, outsamples, WaveHeader.NumChannels, 2, scaled_rate);
    fclose (outfile);

    if (insamples && verbose_mode) {
        fprintf (stderr, "done, %lu samples --> %lu samples (ratio = %.3f)\n",
            (unsigned long) insamples, (unsigned long) outsamples, (float) outsamples / insamples);
        if (scale_rate)
            fprintf (stderr, "sample rate changed from %lu Hz to %lu Hz\n",
                (unsigned long) WaveHeader.SampleRate, (unsigned long) scaled_rate);
        fprintf (stderr, "max expected samples = %d, actually seen = %d stretch, %d flush\n",
            max_expected_samples, max_generated_stretch, max_generated_flush);
        if (silence_frames || non_silence_frames) {
            int total_frames = silence_frames + non_silence_frames;
            fprintf (stderr, "%d silence frames detected (%.2f%%), %d actually used (%.2f%%)\n",
                silence_frames, silence_frames * 100.0 / total_frames,
                used_silence_frames, used_silence_frames * 100.0 / total_frames); 
        }
    }

    return 0;
}

static int write_pcm_wav_header (FILE *outfile, uint32_t num_samples, int num_channels, int bytes_per_sample, uint32_t sample_rate)
{
    RiffChunkHeader riffhdr;
    ChunkHeader datahdr, fmthdr;
    WaveHeader wavhdr;

    int wavhdrsize = 16;
    uint32_t total_data_bytes = num_samples * bytes_per_sample * num_channels;

    memset (&wavhdr, 0, sizeof (wavhdr));

    wavhdr.FormatTag = WAVE_FORMAT_PCM;
    wavhdr.NumChannels = num_channels;
    wavhdr.SampleRate = sample_rate;
    wavhdr.BytesPerSecond = sample_rate * num_channels * bytes_per_sample;
    wavhdr.BlockAlign = bytes_per_sample * num_channels;
    wavhdr.BitsPerSample = bytes_per_sample * 8;

    memcpy (riffhdr.ckID, "RIFF", sizeof (riffhdr.ckID));
    memcpy (riffhdr.formType, "WAVE", sizeof (riffhdr.formType));
    riffhdr.ckSize = sizeof (riffhdr) + wavhdrsize + sizeof (datahdr) + total_data_bytes;
    memcpy (fmthdr.ckID, "fmt ", sizeof (fmthdr.ckID));
    fmthdr.ckSize = wavhdrsize;

    memcpy (datahdr.ckID, "data", sizeof (datahdr.ckID));
    datahdr.ckSize = total_data_bytes;

    return fwrite (&riffhdr, sizeof (riffhdr), 1, outfile) &&
        fwrite (&fmthdr, sizeof (fmthdr), 1, outfile) &&
        fwrite (&wavhdr, wavhdrsize, 1, outfile) &&
        fwrite (&datahdr, sizeof (datahdr), 1, outfile);
}

double rms_level_dB (int16_t *audio, int samples, int channels)
{
    double rms_sum = 0.0;
    int i;

    if (channels == 1)
        for (i = 0; i < samples; ++i)
            rms_sum += (double) audio [i] * audio [i];
    else
        for (i = 0; i < samples; ++i) {
            double average = (audio [i * 2] + audio [i * 2 + 1]) / 2.0;
            rms_sum += average * average;
        }

    return log10 (rms_sum / samples / (32768.0 * 32767.0 * 0.5)) * 10.0;
}

</document_content>
</document>

<document index="54">
<source>vendors/stretch/samples/README</source>
<document_content>
These are two, 60 second samples for exercising the stretch algorithms. They are
encoded with the WavPack lossless codec, so they'll need to be converted back to
Microsoft WAV files to be used. One is mono, and the other is a stereo version
of the first, but with one channel delayed 1/2 sample.

These are not speech samples, but are artificially generated test signals. They
consist of a warbling tone (between 75 and 1500 Hz) and varying levels of noise.
They are also generated at a high level (in some places clipping) to verify the
proper operation of the stretch code with edge-case values.


</document_content>
</document>

<document index="55">
<source>vendors/stretch/stretch.c</source>
<document_content>
////////////////////////////////////////////////////////////////////////////
//                        **** AUDIO-STRETCH ****                         //
//                      Time Domain Harmonic Scaler                       //
//                    Copyright (c) 2022 David Bryant                     //
//                          All Rights Reserved.                          //
//      Distributed under the BSD Software License (see license.txt)      //
////////////////////////////////////////////////////////////////////////////

// stretch.c

// Time Domain Harmonic Compression and Expansion
//
// This library performs time domain harmonic scaling with pitch detection
// to stretch the timing of a 16-bit PCM signal (either mono or stereo) from
// 1/2 to 2 times its original length. This is done without altering any of
// the tonal characteristics.
//
// Use stereo (num_chans = 2), when both channels are from same source
// and should contain approximately similar content.
// For independent channels, prefer using multiple StretchHandle-instances.
// see https://github.com/dbry/audio-stretch/issues/6


#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <string.h>
#include <math.h>

#include "stretch.h"

#define MIN_PERIOD  24          /* minimum allowable pitch period */
#define MAX_PERIOD  2400        /* maximum allowable pitch period */

#if INT_MAX == 32767
#define MERGE_OFFSET    32768L      /* promote to long before offset */
#define abs32           labs        /* use long abs to avoid UB */
#else
#define MERGE_OFFSET    32768
#define abs32           abs
#endif

#define MAX_CORR    UINT32_MAX  /* maximum value for correlation ratios */

struct stretch_cnxt {
    int num_chans, inbuff_samples, shortest, longest, tail, head, fast_mode;
    int16_t *inbuff, *calcbuff;
    float outsamples_error;
    uint32_t *results;

    struct stretch_cnxt *next;
    int16_t *intermediate;
};

static void merge_blocks (int16_t *output, int16_t *input1, int16_t *input2, int samples);
static int find_period_fast (struct stretch_cnxt *cnxt, int16_t *samples);
static int find_period (struct stretch_cnxt *cnxt, int16_t *samples);

/*
 * Initialize a context of the time stretching code. The shortest and longest periods
 * are specified here. The longest period determines the lowest fundamental frequency
 * that can be handled correctly. Note that higher frequencies can be handled than the
 * shortest period would suggest because multiple periods can be combined, and the
 * worst-case performance will suffer if too short a period is selected. The flags are:
 *
 * STRETCH_FAST_FLAG    0x1     Use the "fast" version of the period calculation
 *
 * STRETCH_DUAL_FLAG    0x2     Cascade two instances of the stretcher to expand
 *                              available ratios to 0.25X to 4.00X
 */

StretchHandle stretch_init (int shortest_period, int longest_period, int num_channels, int flags)
{
    struct stretch_cnxt *cnxt;
    int max_periods = 3;

    if (flags & STRETCH_FAST_FLAG) {
        longest_period = (longest_period + 1) & ~1;
        shortest_period &= ~1;
        max_periods = 4;
    }

    if (longest_period <= shortest_period || shortest_period < MIN_PERIOD || longest_period > MAX_PERIOD) {
        fprintf (stderr, "stretch_init(): invalid periods!\n");
        return NULL;
    }

    cnxt = (struct stretch_cnxt *) calloc (1, sizeof (struct stretch_cnxt));

    if (cnxt) {
        cnxt->inbuff_samples = longest_period * num_channels * max_periods;
        cnxt->inbuff = calloc (cnxt->inbuff_samples, sizeof (*cnxt->inbuff));

        if (num_channels == 2 || (flags & STRETCH_FAST_FLAG))
            cnxt->calcbuff = calloc (longest_period * num_channels, sizeof (*cnxt->calcbuff));

        if ((flags & STRETCH_FAST_FLAG))
            cnxt->results = calloc (longest_period, sizeof (*cnxt->results));
    }

    if (!cnxt || !cnxt->inbuff || (num_channels == 2 && (flags & STRETCH_FAST_FLAG) && !cnxt->calcbuff) || ((flags & STRETCH_FAST_FLAG) && !cnxt->results)) {
        fprintf (stderr, "stretch_init(): out of memory!\n");
        return NULL;
    }

    cnxt->head = cnxt->tail = cnxt->longest = longest_period * num_channels;
    cnxt->fast_mode = (flags & STRETCH_FAST_FLAG) ? 1 : 0;
    cnxt->shortest = shortest_period * num_channels;
    cnxt->num_chans = num_channels;

    if (flags & STRETCH_DUAL_FLAG) {
        cnxt->next = stretch_init (shortest_period, longest_period, num_channels, flags & ~STRETCH_DUAL_FLAG);
        cnxt->intermediate = calloc (longest_period * num_channels * max_periods, sizeof (*cnxt->intermediate));
    }

    return (StretchHandle) cnxt;
}

/*
 * Re-Initialize a context of the time stretching code - as if freshly created
 * with stretch_init(). This drops all internal state.
 */

void stretch_reset (StretchHandle handle)
{
    struct stretch_cnxt *cnxt = (struct stretch_cnxt *) handle;

    cnxt->head = cnxt->tail = cnxt->longest;
    memset (cnxt->inbuff, 0, cnxt->tail * sizeof (*cnxt->inbuff));

    if (cnxt->next)
        stretch_reset (cnxt->next);
}

/*
 * Determine how many samples (per channel) should be reserved in 'output'-array
 * for stretch_samples() and stretch_flush(). max_num_samples and max_ratio are the
 * maximum values that will be passed to stretch_samples().
 */

int stretch_output_capacity (StretchHandle handle, int max_num_samples, float max_ratio)
{
    struct stretch_cnxt *cnxt = (struct stretch_cnxt *) handle;
    int max_period = cnxt->longest / cnxt->num_chans;
    int max_expected_samples;
    float next_ratio;

    if (cnxt->next) {
        if (max_ratio < 0.5) {
            next_ratio = max_ratio / 0.5;
            max_ratio = 0.5;
        }
        else if (max_ratio > 2.0) {
            next_ratio = max_ratio / 2.0;
            max_ratio = 2.0;
        }
        else
            next_ratio = 1.0;
    }

    max_expected_samples = (int) ceil (max_num_samples * ceil (max_ratio * 2.0) / 2.0) +
        max_period * (cnxt->fast_mode ? 4 : 3);

    if (cnxt->next)
        max_expected_samples = stretch_output_capacity (cnxt->next, max_expected_samples, next_ratio);

    return max_expected_samples;
}

/*
 * Process the specified samples with the given ratio (which is normally clipped to
 * the range 0.5 to 2.0, or 0.25 to 4.00 for the "dual" mode). Note that in stereo
 * the number of samples refers to the samples for one channel (i.e., not the total
 * number of values passed) and can be as large as desired (samples are buffered here).
 * The ratio may change between calls, but there is some latency to consider because
 * audio is buffered here and a new ratio may be applied to previously sent samples.
 *
 * The exact number of samples output is not easy to determine in advance, so a function
 * is provided (stretch_output_capacity()) that calculates the maximum number of samples
 * that can be generated from a single call to this function (or stretch_flush()) given
 * a number of samples and maximum ratio. It is reccomended that that function be used
 * after initialization to allocate in advance the buffer size required. Be sure to
 * multiply the return value by the number channels!
 */

int stretch_samples (StretchHandle handle, const int16_t *samples, int num_samples, int16_t *output, float ratio)
{
    struct stretch_cnxt *cnxt = (struct stretch_cnxt *) handle;
    int out_samples = 0, next_samples = 0;
    int16_t *outbuf = output;
    float next_ratio;

    /* if there's a cascaded instance after this one, try to do as much of the ratio here and the rest in "next" */

    if (cnxt->next) {
        outbuf = cnxt->intermediate;

        if (ratio < 0.5) {
            next_ratio = ratio / 0.5;
            ratio = 0.5;
        }
        else if (ratio > 2.0) {
            next_ratio = ratio / 2.0;
            ratio = 2.0;
        }
        else
            next_ratio = 1.0;
    }

    num_samples *= cnxt->num_chans;

    /* this really should not happen, but a good idea to clamp in case */

    if (ratio < 0.5)
        ratio = 0.5;
    else if (ratio > 2.0)
        ratio = 2.0;

    /* while we have pending samples to read into our buffer */

    while (num_samples) {

        /* copy in as many samples as we have room for */

        int samples_to_copy = num_samples;

        if (samples_to_copy > cnxt->inbuff_samples - cnxt->head)
            samples_to_copy = cnxt->inbuff_samples - cnxt->head;

        memcpy (cnxt->inbuff + cnxt->head, samples, samples_to_copy * sizeof (cnxt->inbuff [0]));
        num_samples -= samples_to_copy;
        samples += samples_to_copy;
        cnxt->head += samples_to_copy;

        /* while there are enough samples to process (3 or 4 times the longest period), do so */

        while (cnxt->tail >= cnxt->longest && cnxt->head - cnxt->tail >= cnxt->longest * (cnxt->fast_mode ? 3 : 2)) {
            float process_ratio;
            int period;

            if (ratio != 1.0 || cnxt->outsamples_error)
                period = cnxt->fast_mode ? find_period_fast (cnxt, cnxt->inbuff + cnxt->tail) :
                    find_period (cnxt, cnxt->inbuff + cnxt->tail);
            else
                period = cnxt->longest;

            /*
             * Once we have calculated the best-match period, there are 4 possible transformations
             * available to convert the input samples to output samples. Obviously we can simply
             * copy the samples verbatim (1:1). Standard TDHS provides algorithms for 2:1 and
             * 1:2 scaling, and I have created an obvious extension for 2:3 scaling. To achieve
             * intermediate ratios we maintain a "error" term (in samples) and use that here to
             * calculate the actual transformation to apply.
             */

            if (cnxt->outsamples_error == 0.0)
                process_ratio = floor (ratio * 2.0 + 0.5) / 2.0;
            else if (cnxt->outsamples_error > 0.0)
                process_ratio = floor (ratio * 2.0) / 2.0;
            else
                process_ratio = ceil (ratio * 2.0) / 2.0;

            if (process_ratio == 0.5) {
                merge_blocks (outbuf + out_samples, cnxt->inbuff + cnxt->tail,
                    cnxt->inbuff + cnxt->tail + period, period);
                cnxt->outsamples_error += period - (period * 2.0 * ratio);
                out_samples += period;
                cnxt->tail += period * 2;
            }
            else if (process_ratio == 1.0) {
                memcpy (outbuf + out_samples, cnxt->inbuff + cnxt->tail, period * 2 * sizeof (cnxt->inbuff [0]));

                if (ratio != 1.0)
                    cnxt->outsamples_error += (period * 2.0) - (period * 2.0 * ratio);
                else
                    cnxt->outsamples_error = 0; /* if the ratio is 1.0, we can never cancel the error, so just do it now */

                out_samples += period * 2;
                cnxt->tail += period * 2;
            }
            else if (process_ratio == 1.5) {
                memcpy (outbuf + out_samples, cnxt->inbuff + cnxt->tail, period * sizeof (cnxt->inbuff [0]));
                merge_blocks (outbuf + out_samples + period, cnxt->inbuff + cnxt->tail + period,
                    cnxt->inbuff + cnxt->tail, period);
                memcpy (outbuf + out_samples + period * 2, cnxt->inbuff + cnxt->tail + period, period * sizeof (cnxt->inbuff [0]));
                cnxt->outsamples_error += (period * 3.0) - (period * 2.0 * ratio);
                out_samples += period * 3;
                cnxt->tail += period * 2;
            }
            else if (process_ratio == 2.0) {
                merge_blocks (outbuf + out_samples, cnxt->inbuff + cnxt->tail,
                    cnxt->inbuff + cnxt->tail - period, period * 2);

                cnxt->outsamples_error += (period * 2.0) - (period * ratio);
                out_samples += period * 2;
                cnxt->tail += period;

                if (cnxt->fast_mode) {
                    merge_blocks (outbuf + out_samples, cnxt->inbuff + cnxt->tail,
                        cnxt->inbuff + cnxt->tail - period, period * 2);

                    cnxt->outsamples_error += (period * 2.0) - (period * ratio);
                    out_samples += period * 2;
                    cnxt->tail += period;
                }
            }
            else
                fprintf (stderr, "stretch_samples: fatal programming error: process_ratio == %g\n", process_ratio);

            /* if there's another cascaded instance after this, pass the just stretched samples into that */

            if (cnxt->next) {
                next_samples += stretch_samples (cnxt->next, outbuf, out_samples / cnxt->num_chans, output + next_samples * cnxt->num_chans, next_ratio);
                out_samples = 0;
            }

            /* finally, left-justify the samples in the buffer leaving one longest period of history */

            int samples_to_move = cnxt->inbuff_samples - cnxt->tail + cnxt->longest;

            memmove (cnxt->inbuff, cnxt->inbuff + cnxt->tail - cnxt->longest,
                samples_to_move * sizeof (cnxt->inbuff [0]));

            cnxt->head -= cnxt->tail - cnxt->longest;
            cnxt->tail = cnxt->longest;
        }
    }

    /*
     * This code is not strictly required, but will reduce latency, especially in the dual-instance case, by
     * always flushing all pending samples if no actual stretching is desired (i.e., ratio is 1.0 and there's
     * no error to compensate for). This case is more common now than previously because of the gap detection
     * and cascaded instances.
     */

    if (ratio == 1.0 && !cnxt->outsamples_error && cnxt->head != cnxt->tail) {
        int samples_leftover = cnxt->head - cnxt->tail;

        if (cnxt->next)
            next_samples += stretch_samples (cnxt->next, cnxt->inbuff + cnxt->tail, samples_leftover / cnxt->num_chans,
                output + next_samples * cnxt->num_chans, next_ratio);
        else {
            memcpy (outbuf + out_samples, cnxt->inbuff + cnxt->tail, samples_leftover * sizeof (*output));
            out_samples += samples_leftover;
        }

        memmove (cnxt->inbuff, cnxt->inbuff + cnxt->head - cnxt->longest, cnxt->longest * sizeof (cnxt->inbuff [0]));
        cnxt->head = cnxt->tail = cnxt->longest;
    }

    return cnxt->next ? next_samples : out_samples / cnxt->num_chans;
}  

/*
 * Flush any leftover samples out at normal speed. For cascaded dual instances this must be called
 * twice to completely flush, or simply call it until it returns zero samples. The maximum number
 * of samples that can be returned from each call of this function can be determined in advance with
 * stretch_output_capacity().
 */

int stretch_flush (StretchHandle handle, int16_t *output)
{
    struct stretch_cnxt *cnxt = (struct stretch_cnxt *) handle;
    int samples_leftover = cnxt->head - cnxt->tail;
    int samples_flushed = 0;

    if (cnxt->next) {
        if (samples_leftover)
            samples_flushed = stretch_samples (cnxt->next, cnxt->inbuff + cnxt->tail, samples_leftover / cnxt->num_chans, output, 1.0);

        if (!samples_flushed)
            samples_flushed = stretch_flush (cnxt->next, output);
    }
    else {
        memcpy (output, cnxt->inbuff + cnxt->tail, samples_leftover * sizeof (*output));
        samples_flushed = samples_leftover / cnxt->num_chans;
    }

    cnxt->tail = cnxt->head;
    memset (cnxt->inbuff, 0, cnxt->tail * sizeof (*cnxt->inbuff));

    return samples_flushed;
}

/* free handle */

void stretch_deinit (StretchHandle handle)
{
    struct stretch_cnxt *cnxt = (struct stretch_cnxt *) handle;

    free (cnxt->calcbuff);
    free (cnxt->results);
    free (cnxt->inbuff);

    if (cnxt->next) {
        stretch_deinit (cnxt->next);
        free (cnxt->intermediate);
    }

    free (cnxt);
}

/*
 * The pitch detection is done by finding the period that produces the
 * maximum value for the following correlation formula applied to two
 * consecutive blocks of the given period length:
 *
 *         sum of the absolute values of each sample in both blocks
 *   ---------------------------------------------------------------------
 *   sum of the absolute differences of each corresponding pair of samples
 *
 * This formula was chosen for two reasons.  First, it produces output values
 * that can directly compared regardless of the pitch period.  Second, the
 * numerator can be accumulated for successive periods, and only the
 * denominator need be completely recalculated.
 */

static int find_period (struct stretch_cnxt *cnxt, int16_t *samples)
{
    uint32_t sum, diff, factor, scaler, best_factor = 0;
    int16_t *calcbuff = samples;
    int period, best_period;
    int i, j;

    period = best_period = cnxt->shortest / cnxt->num_chans;

    // convert stereo to mono, and accumulate sum for longest period

    if (cnxt->num_chans == 2) {
        calcbuff = cnxt->calcbuff;

        for (sum = i = j = 0; i < cnxt->longest * 2; i += 2)
            sum += abs32 (calcbuff [j++] = ((int32_t) samples [i] + samples [i+1]) >> 1);
    }
    else
        for (sum = i = 0; i < cnxt->longest; ++i)
            sum += abs32 (calcbuff [i]) + abs32 (calcbuff [i+cnxt->longest]);

    // if silence return longest period, else calculate scaler based on largest sum

    if (sum)
        scaler = (MAX_CORR - 1) / sum;
    else
        return cnxt->longest;

    /* accumulate sum for shortest period size */

    for (sum = i = 0; i < period; ++i)
        sum += abs32 (calcbuff [i]) + abs32 (calcbuff [i+period]);

    /* this loop actually cycles through all period lengths */

    while (1) {
        int16_t *comp = calcbuff + period * 2;
        int16_t *ref = calcbuff + period;

        /* compute sum of absolute differences */

        diff = 0;

        while (ref != calcbuff)
            diff += abs32 ((int32_t) *--ref - *--comp);

        /*
         * Here we calculate and store the resulting correlation
         * factor.  Note that we must watch for a difference of
         * zero, meaning a perfect match.  Also, for increased
         * precision using integer math, we scale the sum.
         */

        factor = diff ? (sum * scaler) / diff : MAX_CORR;

        if (factor >= best_factor) {
            best_factor = factor;
            best_period = period;
        }

        /* see if we're done */

        if (period * cnxt->num_chans == cnxt->longest)
            break;

        /* update accumulating sum and current period */

        sum += abs32 (calcbuff [period * 2]) + abs32 (calcbuff [period * 2 + 1]);
        period++;
    }

    return best_period * cnxt->num_chans;
}

/*
 * This pitch detection function is similar to find_period() above, except that it
 * is optimized for speed. The audio data corresponding to two maximum periods is
 * averaged 2:1 into the calculation buffer, and then the calulations are done
 * for every other period length. Because the time is essentially proportional to
 * both the number of samples and the number of period lengths to try, this scheme
 * can reduce the time by a factor approaching 4x. The correlation results on either
 * side of the peak are compared to calculate a more accurate center of the period.
 */

static int find_period_fast (struct stretch_cnxt *cnxt, int16_t *samples)
{
    uint32_t sum, diff, scaler, best_factor = 0;
    int period, best_period;
    int i, j;

    best_period = period = cnxt->shortest / (cnxt->num_chans * 2);

    /* first step is compressing data 2:1 into calcbuff, and calculating maximum sum */

    if (cnxt->num_chans == 2)
        for (sum = i = j = 0; i < cnxt->longest * 2; i += 4)
            sum += abs32 (cnxt->calcbuff [j++] = ((int32_t) samples [i] + samples [i+1] + samples [i+2] + samples [i+3]) >> 2);
    else
        for (sum = i = j = 0; i < cnxt->longest * 2; i += 2)
            sum += abs32 (cnxt->calcbuff [j++] = ((int32_t) samples [i] + samples [i+1]) >> 1);

    // if silence return longest period, else calculate scaler based on largest sum

    if (sum)
        scaler = (MAX_CORR - 1) / sum;
    else
        return cnxt->longest;

    /* accumulate sum for shortest period */

    for (sum = i = 0; i < period; ++i)
        sum += abs32 (cnxt->calcbuff [i]) + abs32 (cnxt->calcbuff [i+period]);

    /* this loop actually cycles through all period lengths */

    while (1) {
        int16_t *comp = cnxt->calcbuff + period * 2;
        int16_t *ref = cnxt->calcbuff + period;

        /* compute sum of absolute differences */

        diff = 0;

        while (ref != cnxt->calcbuff)
            diff += abs32 ((int32_t) *--ref - *--comp);

        /*
         * Here we calculate and store the resulting correlation
         * factor.  Note that we must watch for a difference of
         * zero, meaning a perfect match.  Also, for increased
         * precision using integer math, we scale the sum.
         */

        cnxt->results [period] = diff ? (sum * scaler) / diff : MAX_CORR;

        if (cnxt->results [period] >= best_factor) {    /* check if best yet */
            best_factor = cnxt->results [period];
            best_period = period;
        }

        /* see if we're done */

        if (period * cnxt->num_chans * 2 == cnxt->longest)
            break;

        /* update accumulating sum and current period */

        sum += abs32 (cnxt->calcbuff [period * 2]) + abs32 (cnxt->calcbuff [period * 2 + 1]);
        period++;
    }

    if (best_period * cnxt->num_chans * 2 != cnxt->shortest && best_period * cnxt->num_chans * 2 != cnxt->longest) {
        uint32_t high_side_diff = cnxt->results [best_period] - cnxt->results [best_period+1];
        uint32_t low_side_diff = cnxt->results [best_period] - cnxt->results [best_period-1];

        if ((low_side_diff + 1) / 2 > high_side_diff)
            best_period = best_period * 2 + 1;
        else if ((high_side_diff + 1) / 2 > low_side_diff)
            best_period = best_period * 2 - 1;
        else
            best_period *= 2;
    }
    else
        best_period *= 2;           /* shortest or longest use as is */

    return best_period * cnxt->num_chans;
}

/*
 * To combine the two periods into one, each corresponding pair of samples
 * are averaged with a linearly sliding scale.  At the beginning of the period
 * the first sample dominates, and at the end the second sample dominates.  In
 * this way the resulting block blends with the previous and next blocks.
 *
 * The signed values are offset to unsigned for the calculation and then offset
 * back to signed.  This is done to avoid the compression around zero that occurs
 * with calculations of this type on C implementations that round division toward
 * zero.
 *
 * The maximum period handled here without overflow possibility is 65535 samples.
 * This corresponds to a maximum calculated period of 16383 samples (2x for stereo
 * and 2x for the "2.0" version of the stretch algorithm). Since the maximum
 * calculated period is currently set for 2400 samples, we have plenty of margin.
 */

static void merge_blocks (int16_t *output, int16_t *input1, int16_t *input2, int samples)
{
    int i;

    for (i = 0; i < samples; ++i)
        output [i] = (int32_t)(((uint32_t)(input1 [i] + MERGE_OFFSET) * (samples - i) +
            (uint32_t)(input2 [i] + MERGE_OFFSET) * i) / samples) - MERGE_OFFSET;
}

</document_content>
</document>

<document index="56">
<source>vendors/stretch/stretch.h</source>
<document_content>
////////////////////////////////////////////////////////////////////////////
//                        **** AUDIO-STRETCH ****                         //
//                      Time Domain Harmonic Scaler                       //
//                    Copyright (c) 2022 David Bryant                     //
//                          All Rights Reserved.                          //
//      Distributed under the BSD Software License (see license.txt)      //
////////////////////////////////////////////////////////////////////////////

// stretch.h

// Time Domain Harmonic Compression and Expansion
//
// This library performs time domain harmonic scaling with pitch detection
// to stretch the timing of a 16-bit PCM signal (either mono or stereo) from
// 1/2 to 2 times its original length. This is done without altering any of
// its tonal characteristics.
//
// Use stereo (num_chans = 2), when both channels are from same source
// and should contain approximately similar content.
// For independent channels, prefer using multiple StretchHandle-instances.
// see https://github.com/dbry/audio-stretch/issues/6

#ifndef STRETCH_H
#define STRETCH_H

#include <stdint.h>

#define STRETCH_FAST_FLAG    0x1    // use "fast" version of period determination code
#define STRETCH_DUAL_FLAG    0x2    // cascade two instances (doubles usable ratio range)

#ifdef __cplusplus
extern "C" {
#endif

typedef void *StretchHandle;

StretchHandle stretch_init (int shortest_period, int longest_period, int num_chans, int flags);
int stretch_output_capacity (StretchHandle handle, int max_num_samples, float max_ratio);
int stretch_samples (StretchHandle handle, const int16_t *samples, int num_samples, int16_t *output, float ratio);
int stretch_flush (StretchHandle handle, int16_t *output);
void stretch_reset (StretchHandle handle);
void stretch_deinit (StretchHandle handle);

#ifdef __cplusplus
}
#endif

#endif


</document_content>
</document>

<document index="57">
<source>vendors/stretch/test.sh</source>
<document_content>
#!/bin/bash

if [ ! -d output ]; then
  echo "creating directory output"
  mkdir output
fi

if [ ! -f samples/mono.wav ] || [ ! -f samples/stereo.wav ]; then
  WVUNPACK=$(which wvunpack)
  if [ -z "$WVUNPACK" ]; then
    echo "please build/install WavPack with wvunpack to convert .wv samples to .wav"
    exit 1
  fi
  $WVUNPACK samples/mono.wv
  $WVUNPACK samples/stereo.wv
fi

STARTER=""
if [ "$1" = "gdb" ]; then
  STARTER="gdb -q -ex run -ex quit --args"
  shift
fi

EXAMPLE="mono"
if [ "$1" = "mono" ]; then
  EXAMPLE="$1"
  shift
fi
if [ "$1" = "stereo" ]; then
  EXAMPLE="$1"
  shift
fi


if [ -z "$1" ] && [ -z "$2" ]; then
  echo "usage: $0 [mono|stereo] [f|n] [s|x]"
  echo "  'f': fast pitch detection"
  echo "  'n': normal pitch detection"
  echo "  's': simple range for ratio: 0.5 .. 2.0"
  echo "  'x': extended range for ratio: 0.25 .. 4.0"
  echo ""
fi

if [ -z "$1" ] || [ "$1" = "f" ]; then
  echo "testing with fast pitch detection"
  FO="-f"
  FN="f"
else
  echo "testing with normal pitch detection"
  FO="-n"
  FN="n"
fi


if [ -z "$2" ] || [ "$2" = "s" ]; then
  echo ""
  echo "testing normal range 0.5 .. 2.0"
  echo "x2.0"
  $STARTER ./audio-stretch -q -y $FO -r0.5   samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r050_x200.wav
  echo "x1.75"
  $STARTER ./audio-stretch -q -y $FO -r0.571 samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r057_x175.wav
  echo "x1.5"
  $STARTER ./audio-stretch -q -y $FO -r0.666 samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r066_x150.wav
  echo "x1.25"
  $STARTER ./audio-stretch -q -y $FO -r0.8   samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r080_x125.wav
  echo "x1.0"
  $STARTER ./audio-stretch -q -y $FO -r1.0   samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r100_x100.wav
  echo "x0.75"
  $STARTER ./audio-stretch -q -y $FO -r1.333 samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r133_x075.wav
  echo "x0.5"
  $STARTER ./audio-stretch -q -y $FO -r2.0   samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r200_x050.wav
fi
if [ -z "$2" ] || [ "$2" = "x" ]; then
  echo ""
  echo "testing extended range 0.25 .. 0.5 and 2.0 .. 4.0"
  echo "x4.0"
  $STARTER ./audio-stretch -q -y $FO -r0.25  samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r025_x400.wav
  echo "x3.5"
  $STARTER ./audio-stretch -q -y $FO -r0.285 samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r028_x350.wav
  echo "x3.0"
  $STARTER ./audio-stretch -q -y $FO -r0.333 samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r033_x300.wav
  echo "x2.5"
  $STARTER ./audio-stretch -q -y $FO -r0.4   samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r040_x250.wav
  echo "x0.4"
  $STARTER ./audio-stretch -q -y $FO -r2.5   samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r250_x040.wav
  echo "x0.333"
  $STARTER ./audio-stretch -q -y $FO -r3.0   samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r300_x033.wav
  echo "x0.285"
  $STARTER ./audio-stretch -q -y $FO -r3.5   samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r350_x028.wav
  echo "x0.25"
  $STARTER ./audio-stretch -q -y $FO -r4.0   samples/${EXAMPLE}.wav output/out_${EXAMPLE}_${FN}_r400_x025.wav
fi


</document_content>
</document>

</documents>